{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import clip\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from pathlib import Path \n",
    "if Path.cwd().name != \"Generation\":\n",
    "    os.chdir(\"Generation\")\n",
    "\n",
    "\n",
    "train = False\n",
    "classes = None\n",
    "pictures= None\n",
    "\n",
    "data_dir = \"../data/things-eeg2\"\n",
    "images_dir = os.path.join(data_dir, \"images_set\")\n",
    "\n",
    "def load_data():\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    texts = []\n",
    "    images = []\n",
    "    \n",
    "    text_directory = os.path.join(images_dir, \"training_images\" if train else \"test_images\")\n",
    "\n",
    "    dirnames = [d for d in os.listdir(text_directory) if os.path.isdir(os.path.join(text_directory, d))]\n",
    "    dirnames.sort()\n",
    "    \n",
    "    if classes is not None:\n",
    "        dirnames = [dirnames[i] for i in classes]\n",
    "\n",
    "    for dir in dirnames:\n",
    "\n",
    "        try:\n",
    "            idx = dir.index('_')\n",
    "            description = dir[idx+1:]\n",
    "        except ValueError:\n",
    "            print(f\"Skipped: {dir} due to no '_' found.\")\n",
    "            continue\n",
    "            \n",
    "        new_description = f\"{description}\"\n",
    "        texts.append(new_description)\n",
    "\n",
    "    img_directory = os.path.join(images_dir, \"training_images\" if train else \"test_images\")\n",
    "    \n",
    "    all_folders = [d for d in os.listdir(img_directory) if os.path.isdir(os.path.join(img_directory, d))]\n",
    "    all_folders.sort()\n",
    "\n",
    "    if classes is not None and pictures is not None:\n",
    "        images = []\n",
    "        for i in range(len(classes)):\n",
    "            class_idx = classes[i]\n",
    "            pic_idx = pictures[i]\n",
    "            if class_idx < len(all_folders):\n",
    "                folder = all_folders[class_idx]\n",
    "                folder_path = os.path.join(img_directory, folder)\n",
    "                all_images = [img for img in os.listdir(folder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                all_images.sort()\n",
    "                if pic_idx < len(all_images):\n",
    "                    images.append(os.path.join(folder_path, all_images[pic_idx]))\n",
    "    elif classes is not None and pictures is None:\n",
    "        images = []\n",
    "        for i in range(len(classes)):\n",
    "            class_idx = classes[i]\n",
    "            if class_idx < len(all_folders):\n",
    "                folder = all_folders[class_idx]\n",
    "                folder_path = os.path.join(img_directory, folder)\n",
    "                all_images = [img for img in os.listdir(folder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "                all_images.sort()\n",
    "                images.extend(os.path.join(folder_path, img) for img in all_images)\n",
    "    elif classes is None:\n",
    "        images = []\n",
    "        for folder in all_folders:\n",
    "            folder_path = os.path.join(img_directory, folder)\n",
    "            all_images = [img for img in os.listdir(folder_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            all_images.sort()  \n",
    "            images.extend(os.path.join(folder_path, img) for img in all_images)\n",
    "    else:\n",
    "\n",
    "        print(\"Error\")\n",
    "    return texts, images\n",
    "texts, images = load_data()\n",
    "# images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logit_scale': tensor(2.6593, device='cuda:0'),\n",
       " 'encoder.enc_embedding.mask_token': tensor([[ 2.2306, -0.9360,  1.1844, -0.1838, -0.7417, -0.0082, -0.7323, -1.5703,\n",
       "          -1.2247, -0.2256,  0.7120, -0.2930, -1.3499, -0.7811,  2.0082,  0.2195,\n",
       "           0.1900,  1.6415,  0.6813,  1.5418, -0.3729,  0.3405,  0.3456,  0.7908,\n",
       "          -0.8161, -0.6407, -0.9849,  1.4446,  1.4823, -0.3092, -0.1817, -0.2195,\n",
       "           2.1306, -1.0182, -1.6034, -0.5203,  0.6887,  0.5736, -0.1914, -0.6463,\n",
       "          -0.1167,  0.1107,  0.0192, -0.7261,  1.7299, -0.1015,  2.2164, -0.0829,\n",
       "          -2.4172,  1.6279, -0.4375,  0.4521, -1.1272, -0.8642, -1.7898, -0.3008,\n",
       "           0.7152,  0.8044,  0.9450,  0.8063, -1.2306, -1.9720, -0.4365,  0.7008,\n",
       "          -0.9247, -0.7822, -0.9294, -3.0381, -0.7363,  1.3152,  0.7837, -0.5545,\n",
       "          -1.1406, -1.6900, -0.0358,  0.1347, -0.0904, -0.5850,  0.4202,  0.9815,\n",
       "          -0.8171, -0.9121,  1.0215,  0.6442, -1.9638, -1.0784,  0.8102, -0.0064,\n",
       "          -0.9712, -0.2268, -0.2458,  0.1935, -0.6630, -1.0787,  0.4688, -0.7480,\n",
       "           0.6675,  0.6911, -0.2719, -1.2827, -0.0185,  0.7929, -0.4210,  0.7513,\n",
       "           2.2180,  0.2535,  2.4472,  0.6295,  0.0571,  0.1902,  0.5349,  0.5639,\n",
       "          -0.1731, -0.5581,  0.4427,  0.0697, -0.0833, -0.1143,  0.3393, -1.3411,\n",
       "           0.3325, -0.0031, -1.2141,  2.4787,  0.1798, -1.2610,  0.1927, -1.5235,\n",
       "           0.6352,  1.5839,  0.9392, -0.7171, -1.0296, -1.3894,  1.9031, -1.2784,\n",
       "           1.4934,  0.6435,  0.0155, -0.6922,  0.2274,  0.7098, -0.1282,  0.8734,\n",
       "           0.4296,  0.8009, -0.6297, -0.6785, -0.3037, -1.1774,  0.6037, -0.5540,\n",
       "          -1.1638, -2.6167, -0.3398,  2.7311, -1.0811, -0.0216, -0.7314,  0.2641,\n",
       "           0.0540,  0.3105,  1.4550,  0.7475,  1.0040, -0.4513, -0.7068, -0.2822,\n",
       "           1.5296,  2.2412,  0.0842, -1.4612,  0.0625,  2.3427,  2.3048, -1.0969,\n",
       "          -0.1198, -0.9818, -0.8444, -0.0754, -0.3319, -0.7944, -0.8743, -0.6454,\n",
       "           1.7993,  0.2193,  0.8757,  0.3087,  1.7858,  0.1699, -0.3619, -1.0599,\n",
       "          -2.1806, -2.3428, -0.5291, -0.0745,  0.0226,  0.6012,  1.9298,  0.0538,\n",
       "          -0.8183,  0.6390, -0.4656,  0.4623, -0.3512,  1.0038,  0.5490, -0.4268,\n",
       "           0.3705,  0.4215, -0.1447, -1.1075, -0.1259,  1.8472, -0.3361,  1.2847,\n",
       "          -0.7687,  0.6261, -1.1627,  0.0152,  0.1481,  0.0713, -1.2198, -1.3981,\n",
       "           1.2391,  0.1993, -1.3724,  0.4290,  0.6805,  1.0739, -0.7124, -0.5534,\n",
       "          -0.7683,  0.9882,  1.2294,  1.0751,  0.6616, -0.4877, -0.5843,  0.4086,\n",
       "          -0.1905, -0.2656,  0.6559,  0.2633,  0.4474,  0.9705,  0.2222, -0.6914,\n",
       "          -0.6840, -0.3898]], device='cuda:0'),\n",
       " 'encoder.enc_embedding.value_embedding.weight': tensor([[-0.0611,  0.0074, -0.0326,  ..., -0.0319,  0.0415,  0.0017],\n",
       "         [-0.0497, -0.0254, -0.0256,  ...,  0.0128,  0.0070,  0.0580],\n",
       "         [ 0.0226, -0.0493,  0.0302,  ...,  0.0328,  0.0447, -0.0141],\n",
       "         ...,\n",
       "         [-0.0617, -0.0179, -0.0296,  ...,  0.0222,  0.0721,  0.0620],\n",
       "         [-0.0450, -0.0629, -0.0112,  ..., -0.0077,  0.0114, -0.0270],\n",
       "         [ 0.0031,  0.0038,  0.0050,  ..., -0.0031,  0.0715, -0.0284]],\n",
       "        device='cuda:0'),\n",
       " 'encoder.enc_embedding.value_embedding.bias': tensor([-0.0630, -0.0072, -0.0840, -0.0333, -0.0251,  0.0088,  0.0101, -0.0389,\n",
       "         -0.0632, -0.0317, -0.0421,  0.0476,  0.0205, -0.0180, -0.0011,  0.0544,\n",
       "         -0.0609, -0.0252,  0.0173, -0.0730,  0.0074,  0.0353,  0.0023,  0.0122,\n",
       "          0.0244, -0.0344, -0.0478, -0.0531,  0.0624,  0.0212, -0.0718,  0.0411,\n",
       "          0.0209, -0.0069,  0.0349,  0.0167,  0.0596,  0.0427, -0.0020, -0.0344,\n",
       "          0.0028, -0.0206,  0.0034,  0.0128,  0.0165,  0.0042,  0.0595,  0.0506,\n",
       "          0.0449, -0.0269,  0.0167,  0.0408, -0.0405,  0.0454,  0.0265, -0.0506,\n",
       "          0.0483, -0.0425,  0.0050, -0.0117, -0.0371, -0.0225,  0.0452,  0.0137,\n",
       "          0.0275, -0.0045, -0.0356, -0.0012,  0.0088, -0.0230, -0.0398, -0.0242,\n",
       "          0.0185,  0.0464, -0.0171,  0.0151, -0.0254, -0.0422,  0.0094, -0.0110,\n",
       "         -0.0071,  0.0149,  0.0467, -0.0066, -0.0557, -0.0214, -0.0370,  0.0534,\n",
       "         -0.0270, -0.0003, -0.0073, -0.0035, -0.0485, -0.0399,  0.0371,  0.0136,\n",
       "         -0.0421, -0.0305,  0.0321, -0.0128,  0.0322, -0.0225,  0.0468,  0.0162,\n",
       "         -0.0453, -0.0069, -0.0414, -0.0584,  0.0073, -0.0368, -0.0412,  0.0514,\n",
       "         -0.0184, -0.0311,  0.0179, -0.0243, -0.0035,  0.0484, -0.0193,  0.0105,\n",
       "          0.0547, -0.0474, -0.0003, -0.0264,  0.0601,  0.0347,  0.0035, -0.0240,\n",
       "          0.0199,  0.0640, -0.0178,  0.0095, -0.0019,  0.0175, -0.0090, -0.0128,\n",
       "         -0.0292, -0.0240,  0.0609, -0.0398,  0.0567,  0.0001, -0.0149,  0.0498,\n",
       "          0.0562, -0.0207,  0.0536,  0.0082,  0.0387,  0.0160,  0.0326,  0.0201,\n",
       "          0.0106, -0.0229,  0.0413,  0.0303,  0.0127, -0.0071, -0.0432, -0.0035,\n",
       "         -0.0081,  0.0059,  0.0330,  0.0442, -0.0363, -0.0034,  0.0159, -0.0211,\n",
       "          0.0396, -0.0484, -0.0251, -0.0687,  0.0133,  0.0244,  0.0217, -0.0026,\n",
       "         -0.0501, -0.0503,  0.0194, -0.0477, -0.0615, -0.0490, -0.0318, -0.0408,\n",
       "          0.0212, -0.0513,  0.0299, -0.0134,  0.0358,  0.0016, -0.0595, -0.0119,\n",
       "         -0.0608,  0.0122, -0.0228,  0.0217, -0.0342, -0.0153, -0.0387,  0.0120,\n",
       "          0.0084, -0.0290, -0.0543,  0.0354,  0.0187,  0.0496, -0.0028, -0.0570,\n",
       "          0.0129,  0.0409, -0.0010,  0.0313, -0.0250, -0.0288,  0.0507,  0.0383,\n",
       "          0.0382,  0.0438, -0.0283, -0.0464,  0.0361, -0.0177, -0.0292,  0.0429,\n",
       "         -0.0144, -0.0179, -0.0112, -0.0163, -0.0299, -0.0002,  0.0582, -0.0061,\n",
       "         -0.0400, -0.0284, -0.0818,  0.0062,  0.0536, -0.0148, -0.0648, -0.0121,\n",
       "          0.0488, -0.0264, -0.0108,  0.0119, -0.0475,  0.0404, -0.0094, -0.0677,\n",
       "          0.0083, -0.0249], device='cuda:0'),\n",
       " 'encoder.enc_embedding.position_embedding.pe': tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
       "            0.0000e+00,  1.0000e+00],\n",
       "          [ 8.4147e-01,  5.4030e-01,  8.0100e-01,  ...,  1.0000e+00,\n",
       "            1.0765e-04,  1.0000e+00],\n",
       "          [ 9.0930e-01, -4.1615e-01,  9.5906e-01,  ...,  1.0000e+00,\n",
       "            2.1529e-04,  1.0000e+00],\n",
       "          ...,\n",
       "          [ 9.5625e-01, -2.9254e-01, -9.4216e-01,  ...,  8.3699e-01,\n",
       "            5.1234e-01,  8.5878e-01],\n",
       "          [ 2.7050e-01, -9.6272e-01, -2.9535e-01,  ...,  8.3692e-01,\n",
       "            5.1243e-01,  8.5873e-01],\n",
       "          [-6.6395e-01, -7.4778e-01,  5.8825e-01,  ...,  8.3686e-01,\n",
       "            5.1253e-01,  8.5867e-01]]], device='cuda:0'),\n",
       " 'encoder.enc_embedding.temporal_embedding.embed.weight': tensor([[ 0.1971, -0.0906,  0.4239,  0.1926],\n",
       "         [-0.4478, -0.3834,  0.0201,  0.0907],\n",
       "         [ 0.1267, -0.1137,  0.4389,  0.2439],\n",
       "         [ 0.4242, -0.2260, -0.2074,  0.0606],\n",
       "         [ 0.1716, -0.4403,  0.0967, -0.2307],\n",
       "         [ 0.2778,  0.4456,  0.1503,  0.0135],\n",
       "         [-0.3150, -0.0237,  0.0457, -0.1587],\n",
       "         [ 0.1375,  0.4811,  0.2693, -0.1484],\n",
       "         [ 0.3136,  0.2885,  0.2167,  0.4839],\n",
       "         [-0.3356,  0.3184, -0.1452,  0.1804],\n",
       "         [ 0.0179, -0.0086,  0.1392,  0.3208],\n",
       "         [ 0.0635, -0.0077, -0.2551,  0.2190],\n",
       "         [ 0.4771,  0.3152,  0.4574,  0.1069],\n",
       "         [ 0.3143,  0.0049, -0.1292, -0.1435],\n",
       "         [-0.1929,  0.4340,  0.2321,  0.1538],\n",
       "         [-0.4560,  0.1836, -0.2991,  0.2963],\n",
       "         [-0.1501, -0.3067,  0.3397,  0.3618],\n",
       "         [ 0.0633,  0.2992,  0.3562, -0.2393],\n",
       "         [ 0.2254, -0.1977,  0.1933, -0.3239],\n",
       "         [ 0.0538, -0.2441,  0.3714,  0.3555],\n",
       "         [ 0.4238, -0.2203, -0.1167, -0.2036],\n",
       "         [-0.1410, -0.1700,  0.2422,  0.1702],\n",
       "         [ 0.3023,  0.4836,  0.2770, -0.4107],\n",
       "         [-0.0373, -0.4773, -0.1907, -0.3874],\n",
       "         [ 0.4919,  0.0740,  0.2900,  0.0147],\n",
       "         [ 0.3090, -0.0720,  0.2518, -0.2375],\n",
       "         [-0.2575,  0.2656,  0.3081,  0.1571],\n",
       "         [ 0.3459, -0.4280, -0.3833, -0.1196],\n",
       "         [ 0.4929,  0.2561,  0.3517,  0.4492],\n",
       "         [ 0.4179,  0.0636, -0.4916, -0.1170],\n",
       "         [-0.3112,  0.0180, -0.3188,  0.1106],\n",
       "         [ 0.3650,  0.2342,  0.0812,  0.3303],\n",
       "         [ 0.2279, -0.0920,  0.2577, -0.3735],\n",
       "         [-0.3365, -0.4346, -0.0184, -0.3587],\n",
       "         [ 0.3344, -0.2666, -0.4445, -0.0896],\n",
       "         [-0.1825,  0.1762, -0.3446, -0.2809],\n",
       "         [-0.3365,  0.0160, -0.0897, -0.3016],\n",
       "         [-0.1706, -0.4650, -0.1600,  0.1705],\n",
       "         [ 0.3320, -0.1068, -0.1264, -0.3744],\n",
       "         [ 0.4125, -0.1265, -0.1785, -0.1197],\n",
       "         [-0.0459, -0.0829, -0.2993,  0.3292],\n",
       "         [ 0.2857, -0.1259,  0.3462, -0.0224],\n",
       "         [ 0.1385, -0.4707, -0.0717,  0.2724],\n",
       "         [-0.2220,  0.0992, -0.3845,  0.3228],\n",
       "         [ 0.2605,  0.3204, -0.1460,  0.4051],\n",
       "         [ 0.0845,  0.0107,  0.0942,  0.1321],\n",
       "         [-0.0420, -0.2178, -0.1293, -0.3541],\n",
       "         [ 0.2583,  0.4859, -0.3783,  0.4419],\n",
       "         [-0.0196, -0.3388,  0.3299,  0.2511],\n",
       "         [-0.1336,  0.3340,  0.2400, -0.3294],\n",
       "         [-0.2494, -0.0439,  0.0970, -0.2442],\n",
       "         [-0.0339, -0.1470, -0.1042, -0.0392],\n",
       "         [-0.2987, -0.1005, -0.2798,  0.4397],\n",
       "         [ 0.1459,  0.0756, -0.0181, -0.2507],\n",
       "         [ 0.4375, -0.0186, -0.2081,  0.3866],\n",
       "         [ 0.1585,  0.2284,  0.4807,  0.4915],\n",
       "         [-0.1725,  0.0412, -0.1093, -0.0117],\n",
       "         [-0.1933,  0.1695, -0.2906, -0.4945],\n",
       "         [ 0.3086,  0.2801, -0.0780,  0.3542],\n",
       "         [-0.0988,  0.4411,  0.1219, -0.0799],\n",
       "         [ 0.3451,  0.4237, -0.4006, -0.4347],\n",
       "         [ 0.3921, -0.2499, -0.2899, -0.1862],\n",
       "         [ 0.4874,  0.0706,  0.0229, -0.0888],\n",
       "         [-0.4884, -0.3654, -0.3470,  0.2796],\n",
       "         [ 0.2804,  0.0137,  0.2607,  0.1180],\n",
       "         [-0.2071, -0.0396,  0.0998, -0.2967],\n",
       "         [ 0.2106,  0.3171,  0.4523, -0.0641],\n",
       "         [-0.1323, -0.3505,  0.3160, -0.2469],\n",
       "         [ 0.3471, -0.2464,  0.2445,  0.1706],\n",
       "         [ 0.4383, -0.0784, -0.1369,  0.1043],\n",
       "         [-0.1831,  0.4208,  0.2607,  0.1614],\n",
       "         [ 0.0558, -0.0968,  0.3827, -0.3581],\n",
       "         [ 0.1274, -0.4717,  0.1028,  0.4046],\n",
       "         [-0.4981,  0.4200, -0.3543, -0.4727],\n",
       "         [ 0.0696,  0.1231,  0.0073,  0.0937],\n",
       "         [ 0.3599,  0.1672, -0.1146,  0.3488],\n",
       "         [-0.1401, -0.4179,  0.0296,  0.0078],\n",
       "         [ 0.3603, -0.4204,  0.0417, -0.2893],\n",
       "         [-0.4954, -0.1966,  0.1742,  0.4878],\n",
       "         [-0.3792,  0.2125, -0.2551, -0.4960],\n",
       "         [-0.2289, -0.1742,  0.2330,  0.2235],\n",
       "         [-0.2515, -0.3054, -0.0252, -0.4199],\n",
       "         [-0.2123,  0.3575,  0.1777, -0.3262],\n",
       "         [ 0.0829,  0.3920,  0.4164, -0.1716],\n",
       "         [ 0.2187,  0.2162, -0.0826, -0.3162],\n",
       "         [ 0.1902, -0.3422,  0.1122,  0.3637],\n",
       "         [ 0.1449, -0.0995, -0.4960,  0.2501],\n",
       "         [-0.3911, -0.0845,  0.0628, -0.3937],\n",
       "         [ 0.0358,  0.1019, -0.3033,  0.4272],\n",
       "         [-0.2545,  0.0515, -0.2585, -0.0225],\n",
       "         [ 0.2170,  0.2424, -0.1837,  0.0265],\n",
       "         [ 0.0262,  0.4853,  0.0647, -0.2340],\n",
       "         [-0.0207,  0.4766, -0.0271, -0.1615],\n",
       "         [-0.2963,  0.1470,  0.2419,  0.1814],\n",
       "         [-0.2800, -0.0836,  0.3177,  0.2321],\n",
       "         [-0.1197,  0.1484,  0.3608, -0.4903],\n",
       "         [ 0.2405,  0.4677, -0.0685, -0.2985],\n",
       "         [ 0.3983,  0.4252, -0.1399,  0.2192],\n",
       "         [ 0.2194, -0.0920,  0.1763,  0.3635],\n",
       "         [ 0.4473,  0.3519, -0.2938,  0.1115],\n",
       "         [ 0.1382, -0.1357,  0.3520,  0.1036],\n",
       "         [ 0.0394,  0.3511,  0.1129, -0.4614],\n",
       "         [-0.2489, -0.4052,  0.3794, -0.1879],\n",
       "         [ 0.1533, -0.2359, -0.1667, -0.0659],\n",
       "         [ 0.3926, -0.2884,  0.1820,  0.1875],\n",
       "         [-0.0906, -0.1813, -0.2481, -0.0758],\n",
       "         [-0.4073,  0.2610, -0.4386,  0.4466],\n",
       "         [ 0.0365, -0.0412,  0.2636,  0.2754],\n",
       "         [ 0.1756, -0.1337,  0.2200,  0.1964],\n",
       "         [-0.1585,  0.4763,  0.1547, -0.3839],\n",
       "         [ 0.4535, -0.4613,  0.2440, -0.4732],\n",
       "         [-0.4279, -0.4553,  0.3416,  0.0097],\n",
       "         [-0.0972,  0.2463,  0.0291,  0.4128],\n",
       "         [ 0.0706, -0.4137, -0.4693,  0.4840],\n",
       "         [ 0.0924, -0.3781,  0.3745,  0.2847],\n",
       "         [-0.3563, -0.4920, -0.3957,  0.0478],\n",
       "         [ 0.1167,  0.0447,  0.1954,  0.3199],\n",
       "         [ 0.2454, -0.1746,  0.4925,  0.2901],\n",
       "         [ 0.4328, -0.0353,  0.3313, -0.0442],\n",
       "         [ 0.0052,  0.2083,  0.0349, -0.1880],\n",
       "         [ 0.3153,  0.2475, -0.4190, -0.1402],\n",
       "         [-0.0568,  0.2564,  0.3184, -0.3903],\n",
       "         [-0.4012,  0.0784, -0.4315, -0.1209],\n",
       "         [-0.1064,  0.2360,  0.3000, -0.4669],\n",
       "         [-0.1723,  0.2046,  0.3947, -0.1610],\n",
       "         [ 0.2470,  0.4589, -0.1979,  0.2844],\n",
       "         [ 0.1063, -0.2423, -0.3816,  0.1420],\n",
       "         [-0.3897, -0.2901,  0.4689, -0.1918],\n",
       "         [-0.1467, -0.4156, -0.3843,  0.4173],\n",
       "         [ 0.4950,  0.1706,  0.2567,  0.1798],\n",
       "         [-0.3784, -0.2820, -0.2720, -0.1948],\n",
       "         [ 0.3321, -0.4283,  0.3694, -0.3241],\n",
       "         [-0.3692, -0.1095, -0.0639,  0.2379],\n",
       "         [-0.4799, -0.0728,  0.2687,  0.3024],\n",
       "         [-0.4955,  0.0229,  0.3799, -0.0177],\n",
       "         [ 0.1984, -0.3326, -0.0837, -0.2265],\n",
       "         [-0.4252,  0.4895,  0.0315,  0.1643],\n",
       "         [-0.0387,  0.1897,  0.1008, -0.1502],\n",
       "         [-0.3151, -0.4289, -0.3844, -0.4753],\n",
       "         [ 0.1146,  0.3992, -0.3643, -0.0188],\n",
       "         [ 0.3860, -0.2378,  0.1545, -0.0196],\n",
       "         [ 0.0749,  0.1430,  0.2923,  0.0223],\n",
       "         [ 0.4060,  0.3823,  0.3548, -0.0104],\n",
       "         [-0.1491, -0.2948, -0.4147, -0.1096],\n",
       "         [ 0.3210,  0.3507,  0.4671, -0.2990],\n",
       "         [-0.1665, -0.1241, -0.4220, -0.0006],\n",
       "         [-0.2473,  0.3855, -0.3970,  0.2312],\n",
       "         [ 0.3522,  0.2471,  0.4198,  0.2217],\n",
       "         [ 0.0125,  0.0137,  0.1965,  0.0927],\n",
       "         [ 0.2336,  0.4663,  0.2619,  0.4558],\n",
       "         [-0.0910,  0.0809,  0.1887,  0.0457],\n",
       "         [-0.3382, -0.4882, -0.2733, -0.2317],\n",
       "         [-0.3248, -0.2557, -0.1447, -0.0905],\n",
       "         [ 0.2491,  0.0137, -0.0139, -0.1678],\n",
       "         [-0.2510,  0.2766, -0.4186, -0.2714],\n",
       "         [ 0.2440,  0.3544, -0.3356,  0.4685],\n",
       "         [ 0.0953, -0.0840,  0.2751,  0.3849],\n",
       "         [-0.1629, -0.4705,  0.4479, -0.4927],\n",
       "         [-0.2858, -0.3561,  0.1552, -0.3719],\n",
       "         [ 0.0066,  0.2610, -0.3832, -0.1083],\n",
       "         [ 0.0996, -0.1092,  0.0260,  0.3810],\n",
       "         [ 0.1251, -0.2427,  0.0701,  0.1923],\n",
       "         [-0.4391,  0.4704, -0.3207, -0.2010],\n",
       "         [ 0.1639,  0.4196, -0.3215,  0.1668],\n",
       "         [-0.0252,  0.2455, -0.3298, -0.0252],\n",
       "         [-0.0935,  0.1919,  0.3346, -0.4937],\n",
       "         [ 0.3542, -0.0253, -0.3123,  0.4259],\n",
       "         [ 0.0005, -0.0223, -0.2261,  0.4009],\n",
       "         [-0.0234, -0.4246,  0.0633, -0.2128],\n",
       "         [ 0.1618, -0.3648, -0.4984, -0.2287],\n",
       "         [ 0.3529, -0.3250,  0.4243, -0.4783],\n",
       "         [ 0.3060,  0.4605,  0.3851, -0.0663],\n",
       "         [-0.2177, -0.3881, -0.4300,  0.3909],\n",
       "         [ 0.2942, -0.1590,  0.3876, -0.3474],\n",
       "         [-0.2572,  0.0279,  0.0324, -0.4111],\n",
       "         [ 0.2939, -0.4442,  0.4920, -0.0266],\n",
       "         [-0.1381,  0.2495,  0.2402, -0.4923],\n",
       "         [ 0.2082, -0.4829,  0.3234,  0.3055],\n",
       "         [ 0.1588, -0.2125,  0.0791, -0.2804],\n",
       "         [ 0.4465, -0.4754, -0.3993,  0.2643],\n",
       "         [-0.3168, -0.3830, -0.1281, -0.3001],\n",
       "         [-0.2698, -0.1851, -0.1993, -0.2571],\n",
       "         [-0.0727, -0.2373, -0.2991, -0.0722],\n",
       "         [-0.1100,  0.2786, -0.0335, -0.2592],\n",
       "         [-0.4951, -0.1743, -0.0114, -0.0359],\n",
       "         [-0.2772,  0.3349, -0.2485, -0.2464],\n",
       "         [ 0.4483, -0.4024, -0.0315, -0.3099],\n",
       "         [ 0.3017,  0.2002, -0.1776, -0.1769],\n",
       "         [-0.2668,  0.1953,  0.0262,  0.3239],\n",
       "         [-0.4377,  0.0325, -0.0880,  0.2295],\n",
       "         [-0.2241, -0.0351, -0.2102,  0.0777],\n",
       "         [-0.2334, -0.0075, -0.3560,  0.1212],\n",
       "         [ 0.2998, -0.0857,  0.3270, -0.0647],\n",
       "         [-0.3789,  0.4133, -0.2250, -0.2057],\n",
       "         [ 0.2851, -0.0582,  0.0182, -0.3608],\n",
       "         [-0.1864, -0.4801,  0.0124, -0.0761],\n",
       "         [ 0.0512,  0.0945,  0.2583,  0.0140],\n",
       "         [-0.3680,  0.0243,  0.3399, -0.4930],\n",
       "         [-0.3504,  0.3221,  0.1999, -0.2154],\n",
       "         [-0.4368, -0.0307,  0.4232,  0.3479],\n",
       "         [-0.3900,  0.4848,  0.2213,  0.4061],\n",
       "         [-0.4429,  0.3927, -0.2165,  0.4585],\n",
       "         [-0.4357, -0.4145, -0.1619,  0.0661],\n",
       "         [ 0.3808, -0.3989,  0.1982,  0.0535],\n",
       "         [ 0.2897,  0.2696,  0.1114,  0.4704],\n",
       "         [-0.1364,  0.0318,  0.2727, -0.4957],\n",
       "         [ 0.1617, -0.3430,  0.1981, -0.2288],\n",
       "         [-0.1444, -0.4631,  0.3484,  0.1669],\n",
       "         [ 0.2353,  0.0567,  0.0676,  0.0980],\n",
       "         [ 0.2236,  0.3575, -0.4556,  0.3119],\n",
       "         [ 0.1796, -0.2561,  0.2223,  0.0802],\n",
       "         [-0.3396,  0.3038,  0.1418,  0.4735],\n",
       "         [ 0.3578, -0.3436, -0.2052, -0.4442],\n",
       "         [ 0.3118, -0.0254,  0.0693, -0.1213],\n",
       "         [-0.3370,  0.0712, -0.2624,  0.2954],\n",
       "         [-0.3382,  0.3214,  0.3918, -0.2276],\n",
       "         [-0.4798,  0.0582, -0.1632, -0.2153],\n",
       "         [ 0.4853, -0.0881,  0.0085, -0.1914],\n",
       "         [ 0.4529,  0.3777, -0.3185,  0.1658],\n",
       "         [ 0.4515,  0.0716, -0.4000,  0.4342],\n",
       "         [ 0.0315, -0.1635,  0.1284, -0.1639],\n",
       "         [ 0.1955,  0.0491, -0.1111,  0.1229],\n",
       "         [-0.2968, -0.0388,  0.2293,  0.4279],\n",
       "         [ 0.4378,  0.2199, -0.3005, -0.3595],\n",
       "         [ 0.1707, -0.0614, -0.1244,  0.0328],\n",
       "         [ 0.0468,  0.4413,  0.2717,  0.1614],\n",
       "         [ 0.2748, -0.4757, -0.2670, -0.0741],\n",
       "         [-0.2656, -0.0145, -0.1342, -0.2749],\n",
       "         [ 0.0711,  0.2880,  0.4491, -0.1416],\n",
       "         [-0.2364, -0.1791,  0.3249,  0.2191],\n",
       "         [-0.4529,  0.2238,  0.2127, -0.3740],\n",
       "         [ 0.4898,  0.1454,  0.4751, -0.4276],\n",
       "         [-0.2952,  0.2364, -0.0020,  0.2372],\n",
       "         [-0.0758, -0.3476, -0.4781,  0.3721],\n",
       "         [-0.0860,  0.3697,  0.3338, -0.0047],\n",
       "         [-0.4385,  0.2538, -0.2838, -0.4415],\n",
       "         [-0.4420, -0.4859, -0.1041,  0.1846],\n",
       "         [ 0.1740,  0.4473,  0.0900, -0.0571],\n",
       "         [-0.1346, -0.1017,  0.1808, -0.1639],\n",
       "         [-0.1859, -0.0251,  0.1815,  0.4019],\n",
       "         [ 0.3441, -0.4628, -0.2226, -0.3251],\n",
       "         [-0.3709,  0.4013,  0.3913,  0.1395],\n",
       "         [ 0.0286, -0.0144,  0.3251, -0.3762],\n",
       "         [-0.1462,  0.0764, -0.3628, -0.4929],\n",
       "         [-0.2683, -0.1071,  0.1760, -0.1147],\n",
       "         [ 0.4268, -0.0830, -0.0325,  0.1087],\n",
       "         [ 0.0744,  0.0100, -0.2209,  0.3705],\n",
       "         [-0.0576, -0.0273, -0.2963, -0.3704],\n",
       "         [-0.1880,  0.3186,  0.2098, -0.1565],\n",
       "         [ 0.1556,  0.0884, -0.2676,  0.0211]], device='cuda:0'),\n",
       " 'encoder.enc_embedding.subject_embedding.shared_embedding': tensor([[-0.2095,  2.8839, -0.6589,  0.6250,  0.9502,  0.0176,  0.5346, -0.6710,\n",
       "          -0.2373, -0.2830, -0.0859, -0.7096,  0.6398,  0.1939, -1.2372,  0.0110,\n",
       "          -0.6194,  0.7231,  0.5839,  0.8870, -1.3951, -0.5874,  1.7687,  0.1053,\n",
       "           0.5976,  0.0504, -0.4170, -0.0140, -0.3457, -1.0081, -1.0003,  1.0555,\n",
       "           0.3185,  0.1343,  0.5341,  1.6630, -1.3375,  1.1626,  0.7224,  2.0934,\n",
       "          -1.5761, -0.0868,  1.2222,  0.6115, -0.8547, -1.5065,  2.1195,  0.6266,\n",
       "           0.7575,  0.1941, -0.4697,  0.3014,  0.9823, -1.7628, -0.3737, -1.6144,\n",
       "          -0.0112,  0.3582,  0.0468,  1.1647,  1.8392, -2.1939, -0.4564,  0.1780,\n",
       "          -1.0334, -1.5201,  0.2790, -1.4066,  0.1209, -1.0732, -1.1609,  0.6952,\n",
       "           2.2348,  0.9122,  0.0527, -1.4629,  0.7931, -0.6246, -0.0436, -1.3746,\n",
       "           0.5822,  0.9748,  0.9392,  2.6003,  1.1114, -0.4833,  1.3991,  0.1710,\n",
       "           1.9672, -1.0411,  1.7005, -0.7808,  0.8127, -0.2157, -0.6601, -0.2611,\n",
       "           0.4162, -0.3531,  0.4541, -1.0023, -0.1658, -1.5706,  0.0291,  0.1407,\n",
       "          -1.0248, -0.5824,  1.1478, -0.3689,  1.2141, -0.0663, -0.9207,  0.2298,\n",
       "           0.1943, -0.2344,  1.7708, -0.3540, -0.1719, -0.5618,  0.1029,  1.6511,\n",
       "          -0.8456, -0.2675,  0.6972,  0.6727, -1.9480,  0.4211,  1.1309,  0.4178,\n",
       "           0.6034, -1.1162,  1.5663, -1.2953,  1.7965,  0.0521, -0.4287,  0.6297,\n",
       "           1.8053,  0.4466, -1.1830, -0.2591,  0.8659, -1.0766, -0.6364, -0.7517,\n",
       "          -1.7505,  1.6456,  1.7258,  0.0994, -0.2731, -1.2660, -0.7151,  2.2044,\n",
       "           0.5962, -0.2936,  0.7251, -1.3081,  1.7090, -1.2529, -1.4936,  2.7881,\n",
       "           1.9170, -0.1500, -0.4622,  0.9874, -0.1896,  1.1344, -0.1191,  0.0238,\n",
       "          -0.8165,  0.7004,  0.2058,  1.6875,  0.9942, -0.3157, -0.8802,  0.5156,\n",
       "          -2.3465, -0.4406, -0.4853,  1.1043, -0.1685,  2.4787, -0.5721,  0.8365,\n",
       "           0.4465,  0.9073,  0.0777,  0.7637, -1.3622, -0.9080, -1.6008,  0.5854,\n",
       "           0.1973,  0.9295, -1.1026, -0.2299, -2.5660,  0.5042,  0.2267, -0.0366,\n",
       "           1.6898,  0.7684, -1.2287,  1.9979, -0.1796, -1.2442, -0.1036,  0.1201,\n",
       "           0.2277,  1.1965, -2.0316, -0.5801, -0.4946, -0.7709, -1.3138,  1.9170,\n",
       "           0.8553,  0.5845,  0.8439,  2.7024, -0.7841,  0.2202,  1.6002,  0.2627,\n",
       "          -0.8615,  1.0024, -1.3144,  0.4322,  0.8321, -1.7434, -0.9365,  0.2879,\n",
       "          -0.9195,  0.7459,  1.8211, -0.7050,  1.1205,  1.1816, -0.4888, -1.3427,\n",
       "          -1.1532,  0.0794,  1.2603, -0.2392,  0.2026,  0.4129, -0.4826,  1.4028,\n",
       "           0.5107, -0.3760]], device='cuda:0'),\n",
       " 'encoder.enc_embedding.subject_embedding.mask_embedding': tensor([[-8.9725e-01,  1.5476e-01, -1.2427e+00, -1.6325e+00,  5.5676e-01,\n",
       "           7.6314e-01,  1.8922e+00, -1.7912e+00,  4.5173e-01, -1.0567e+00,\n",
       "          -1.9578e-01,  7.2180e-01,  1.3557e-01, -2.3708e+00,  1.1228e+00,\n",
       "          -1.2127e+00, -1.1497e+00,  4.6546e-01,  1.6997e+00, -1.0511e+00,\n",
       "          -3.2648e-02, -3.8369e-01, -4.1697e-01, -1.6784e-01, -1.1909e+00,\n",
       "           5.4978e-01,  1.0211e-01, -4.5857e-01,  5.8849e-01,  7.6856e-02,\n",
       "           2.1747e-01,  7.5080e-01, -6.8590e-01,  3.0219e-02, -2.2437e-01,\n",
       "           3.7953e-01, -1.1215e+00,  8.6773e-01,  2.5669e-01,  1.9742e+00,\n",
       "           4.9848e-01,  1.2667e-01,  5.4087e-01,  1.7384e+00, -1.0439e+00,\n",
       "          -2.6616e-01,  2.4513e-03,  3.7440e-01, -3.3225e-01,  8.0862e-01,\n",
       "          -8.2438e-01,  3.3253e-01, -6.4328e-01, -7.9594e-01,  5.0979e-01,\n",
       "          -4.0620e-01,  9.6155e-01, -7.8225e-01, -4.3385e-01, -2.3534e-01,\n",
       "          -5.9867e-01,  6.4280e-01, -3.9772e-01, -1.6720e+00, -1.0040e+00,\n",
       "          -6.5207e-01,  8.6085e-01,  5.7035e-01, -6.2839e-01, -2.5906e-02,\n",
       "           1.7860e+00, -9.1740e-02,  6.2407e-01, -2.1964e-01, -1.5574e+00,\n",
       "          -3.1967e-01, -6.9713e-01,  4.2977e-01, -8.0510e-01,  2.2291e+00,\n",
       "           3.2646e+00,  2.5225e-01, -1.4483e+00,  3.2900e+00, -1.5438e-01,\n",
       "          -1.0116e+00,  1.2554e+00,  9.1735e-01,  5.4770e-01,  1.9340e+00,\n",
       "          -1.8385e+00,  1.7153e+00,  6.1711e-01,  7.4485e-01, -9.9193e-01,\n",
       "          -5.6608e-01,  3.9653e-02,  1.0163e+00,  2.5718e-01, -1.0483e+00,\n",
       "           5.9991e-01, -6.2240e-02, -1.0316e+00, -1.4625e-01,  1.4732e+00,\n",
       "           7.9663e-01,  2.0362e+00,  9.7471e-03, -2.1996e-01,  6.0550e-01,\n",
       "          -4.4651e-02,  3.4914e-01,  2.3974e-02, -2.4137e-01,  1.8790e-01,\n",
       "           1.4898e+00, -1.0700e+00, -1.3140e-01,  1.4120e+00, -1.7350e+00,\n",
       "          -2.8402e-01, -1.3640e+00, -1.3247e+00,  7.8872e-01, -1.2678e+00,\n",
       "          -1.2540e+00, -2.6129e+00,  1.5196e+00,  1.3814e+00,  5.2305e-02,\n",
       "           6.6976e-01,  2.0128e+00,  1.2693e+00, -1.4345e+00, -4.3711e-02,\n",
       "          -1.0948e+00,  1.7361e+00,  5.1892e-01, -5.7779e-02,  2.8469e-01,\n",
       "          -5.2202e-01, -1.0717e+00, -9.8624e-01, -1.3164e+00, -7.8635e-01,\n",
       "           1.1756e-01,  7.3141e-01,  1.0701e+00, -1.0004e-01,  1.9391e+00,\n",
       "           5.8294e-01, -5.2483e-01,  3.9448e-01,  5.0604e-01,  9.9440e-01,\n",
       "          -1.0018e+00,  2.2444e-01, -8.1200e-02,  3.2220e-01, -1.0120e-01,\n",
       "           3.8289e-01, -1.0558e+00,  9.8539e-02,  3.9372e-01, -1.1877e+00,\n",
       "           8.9352e-01,  7.2515e-01, -1.2554e+00,  7.3385e-01, -9.2122e-01,\n",
       "          -5.5521e-01, -2.4372e-01,  6.8406e-01, -1.7404e+00, -2.0766e+00,\n",
       "           6.7880e-01, -5.7555e-01, -1.9182e-01, -1.2277e+00,  3.3639e-01,\n",
       "           7.6717e-01, -1.6820e+00,  4.3756e-01,  5.5841e-02, -3.7213e-02,\n",
       "           1.8238e+00,  1.8232e+00, -3.9331e-01,  1.3238e+00, -1.6516e+00,\n",
       "           4.4045e-01,  2.5085e+00,  1.1344e+00, -8.8424e-01,  1.8084e+00,\n",
       "           5.8319e-01,  8.0624e-02,  8.3624e-01,  1.0390e+00,  6.3234e-02,\n",
       "          -2.5377e-01,  4.8491e-02, -4.2063e-01, -5.6754e-02, -1.9191e+00,\n",
       "           1.0686e-01, -5.9364e-01,  2.9826e-02, -6.7336e-01, -1.4132e+00,\n",
       "           1.6717e+00,  1.2268e+00, -8.3785e-01, -2.3227e-01, -1.3693e+00,\n",
       "          -3.7314e-01,  1.6341e+00, -5.0067e-02, -6.5000e-01,  3.6409e-01,\n",
       "          -2.8582e+00, -2.4474e-01, -1.5949e+00,  2.2787e-01,  3.8906e-01,\n",
       "           9.4690e-01,  1.3447e+00,  8.5679e-01, -6.0165e-01, -2.3871e-01,\n",
       "           1.5359e+00,  3.1523e-01,  5.0249e-02, -4.9388e-01,  1.0159e+00,\n",
       "          -1.4281e-01, -1.4561e+00,  1.3797e+00, -7.5297e-02,  1.4260e+00,\n",
       "          -9.9034e-02,  8.2266e-01, -1.1319e+00, -2.1231e+00, -1.0912e+00,\n",
       "          -5.6748e-01,  1.4232e+00, -1.3660e+00,  9.3064e-01,  3.4471e-02]],\n",
       "        device='cuda:0'),\n",
       " 'encoder.enc_embedding.subject_embedding.subject_embedding.weight': tensor([[-1.7275, -1.4512,  0.9194,  ..., -0.7875,  0.0997, -0.4918],\n",
       "         [-0.7991, -0.0371,  0.5722,  ..., -1.2741, -0.7179, -1.0775],\n",
       "         [-0.1400,  1.4309, -0.9754,  ...,  0.7347,  1.7138,  1.0709],\n",
       "         ...,\n",
       "         [-1.0050, -0.3398, -0.1203,  ...,  0.3422,  0.6260,  1.8815],\n",
       "         [-0.8281, -1.4054, -1.5963,  ..., -1.8386,  1.2230, -0.7554],\n",
       "         [-0.2835,  0.6656, -0.8073,  ..., -1.4145, -1.3546,  1.2696]],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.attention.query_projection.weight': tensor([[ 0.0324,  0.0547,  0.0268,  ..., -0.0369, -0.0387,  0.0238],\n",
       "         [-0.0085, -0.0555,  0.0136,  ...,  0.0150,  0.0303,  0.0212],\n",
       "         [ 0.0618,  0.0028,  0.0248,  ..., -0.0012, -0.0035, -0.0232],\n",
       "         ...,\n",
       "         [ 0.0623,  0.0072,  0.0297,  ..., -0.0172, -0.0691, -0.0220],\n",
       "         [-0.0267,  0.0287, -0.0378,  ...,  0.0031, -0.0210,  0.0222],\n",
       "         [ 0.0241,  0.0066, -0.0107,  ..., -0.0955,  0.0157, -0.0294]],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.attention.query_projection.bias': tensor([-0.0882,  0.0772,  0.0244,  0.0057, -0.0354, -0.0697, -0.0613,  0.0515,\n",
       "         -0.0476,  0.0410,  0.0114,  0.0356,  0.0430,  0.0942, -0.0139,  0.0612,\n",
       "          0.0073,  0.0215,  0.0845, -0.0984, -0.0030, -0.0381,  0.0100,  0.0136,\n",
       "         -0.1133,  0.0590, -0.0300,  0.0930, -0.0453, -0.0252, -0.0076,  0.1144,\n",
       "          0.0368, -0.0751,  0.0544, -0.0178, -0.0425,  0.0500,  0.0209, -0.0340,\n",
       "         -0.0389,  0.1180, -0.0275,  0.0649,  0.0240,  0.0491,  0.0395,  0.0767,\n",
       "          0.0304, -0.0286, -0.0623, -0.0892,  0.0786,  0.0133, -0.0733,  0.0698,\n",
       "         -0.0050,  0.0663, -0.0107, -0.0354,  0.0352,  0.0143, -0.0159,  0.0812,\n",
       "          0.0095, -0.0458, -0.0512,  0.0358, -0.0004,  0.0292, -0.1086,  0.0607,\n",
       "         -0.0731,  0.0093,  0.0464, -0.1321,  0.0301, -0.0068, -0.0332, -0.0110,\n",
       "         -0.0314,  0.0220,  0.0516, -0.0969,  0.0301,  0.0710, -0.0095, -0.0310,\n",
       "          0.0542,  0.1257, -0.0364,  0.0205,  0.0237, -0.0621, -0.0611,  0.0590,\n",
       "         -0.0695, -0.0383,  0.0004, -0.0271, -0.0215,  0.0635,  0.0281, -0.0650,\n",
       "          0.0577,  0.0353, -0.0135, -0.0860, -0.0729, -0.0224, -0.0482, -0.0288,\n",
       "         -0.0981,  0.0983,  0.0400, -0.0415,  0.1086,  0.0596,  0.0605,  0.0298,\n",
       "          0.0283, -0.0871, -0.1099, -0.0324, -0.0868,  0.0285, -0.0153, -0.0448,\n",
       "         -0.0412,  0.0861, -0.0329, -0.1076, -0.0573,  0.0901,  0.0483, -0.0494,\n",
       "          0.0017,  0.1324, -0.1321, -0.0639,  0.0357,  0.1013, -0.0717, -0.0095,\n",
       "         -0.0188, -0.1013,  0.0126,  0.0813,  0.0802,  0.0567, -0.0606,  0.0158,\n",
       "          0.0969,  0.0496, -0.0492,  0.0113, -0.0822, -0.1012,  0.0018,  0.0122,\n",
       "          0.0520,  0.0697, -0.0581, -0.0277, -0.1097,  0.0230,  0.0206,  0.0740,\n",
       "         -0.1002, -0.0285, -0.0166,  0.1058,  0.0294, -0.0344,  0.0331,  0.0585,\n",
       "          0.0449, -0.0421, -0.0348, -0.1198, -0.0896,  0.1199, -0.0459,  0.0291,\n",
       "          0.0233, -0.0455, -0.0315,  0.0535, -0.0126,  0.0409, -0.0797, -0.0389,\n",
       "          0.0320, -0.0971, -0.0542, -0.0517,  0.0440,  0.0144, -0.0775, -0.0679,\n",
       "          0.0332, -0.1294, -0.0545, -0.0810,  0.0684, -0.0852,  0.0605,  0.0538,\n",
       "         -0.0623, -0.0477, -0.0100,  0.0447, -0.0353, -0.0229, -0.0968,  0.1165,\n",
       "          0.0354,  0.0533,  0.0449,  0.0081,  0.0661,  0.0813,  0.0651, -0.0126,\n",
       "          0.0490, -0.0857,  0.0567,  0.0291, -0.1345, -0.0340, -0.0221,  0.0325,\n",
       "         -0.0422,  0.0578, -0.1239,  0.0073,  0.0068,  0.0682,  0.0067, -0.0858,\n",
       "          0.0231,  0.0266,  0.0109, -0.1274, -0.0607, -0.0716, -0.0426, -0.0163],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.attention.key_projection.weight': tensor([[-0.0118, -0.0723, -0.0057,  ..., -0.0142,  0.0268,  0.0468],\n",
       "         [ 0.0103, -0.0320,  0.0414,  ..., -0.0224, -0.0615,  0.0059],\n",
       "         [-0.0310, -0.0776, -0.0195,  ...,  0.0279, -0.0397, -0.0014],\n",
       "         ...,\n",
       "         [ 0.0608, -0.0585, -0.0332,  ..., -0.0047, -0.0009, -0.0282],\n",
       "         [ 0.0588, -0.0309, -0.0657,  ..., -0.0478, -0.0208,  0.0386],\n",
       "         [-0.0214, -0.0469, -0.0400,  ...,  0.0506, -0.0344,  0.0756]],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.attention.key_projection.bias': tensor([ 1.0205e-02, -5.9465e-02,  1.7742e-02, -4.9124e-02,  3.1311e-02,\n",
       "         -5.6868e-02,  3.8677e-02,  2.9435e-02,  2.7026e-02,  4.7317e-03,\n",
       "          1.5633e-02, -5.4884e-02,  1.7330e-02,  2.0776e-02,  6.8162e-03,\n",
       "          3.5315e-02,  4.3814e-03,  3.2458e-02, -4.0993e-02, -2.8093e-02,\n",
       "         -3.2548e-03,  4.9041e-02, -2.4423e-02, -2.7493e-03,  7.2659e-03,\n",
       "          2.1487e-02,  4.3414e-02,  1.0417e-02, -1.0417e-02, -4.3016e-02,\n",
       "          2.8063e-02, -3.6802e-02,  5.2141e-02,  5.0737e-02, -3.3313e-02,\n",
       "          1.9847e-02,  1.5265e-02, -3.9371e-02,  4.9914e-02, -1.8244e-02,\n",
       "         -2.3411e-03, -5.3931e-02,  4.6018e-02,  7.4871e-03,  4.9422e-03,\n",
       "         -1.8458e-02, -3.6411e-03, -5.5637e-02, -1.6201e-02, -5.2431e-02,\n",
       "          1.8840e-02,  2.0017e-02, -2.1998e-03,  2.6394e-02, -3.3525e-03,\n",
       "          3.5835e-02, -4.4795e-02, -1.4694e-02, -2.1821e-02, -6.2160e-02,\n",
       "         -5.3529e-02, -4.0637e-02, -3.9929e-02, -2.7448e-02, -4.0398e-02,\n",
       "          6.7271e-03, -1.4527e-02,  5.1809e-02,  4.2215e-02, -3.2935e-02,\n",
       "          9.8264e-03, -8.9444e-03,  5.6353e-03,  2.1330e-02,  5.1948e-02,\n",
       "          5.8814e-02, -5.9032e-02,  3.9548e-02, -3.4908e-02, -3.9925e-02,\n",
       "          2.6656e-02, -3.0627e-03, -5.1844e-02,  1.5691e-03,  9.5506e-03,\n",
       "         -6.7145e-04,  1.6249e-02,  4.5505e-02, -1.9779e-02, -3.2998e-02,\n",
       "         -4.9026e-03,  6.2163e-02,  2.5630e-02, -2.7001e-02, -1.2849e-03,\n",
       "          4.7978e-02,  2.8739e-02, -5.8397e-02, -5.2455e-02,  2.4648e-02,\n",
       "         -3.9059e-03, -4.9536e-02, -2.5314e-02, -1.6332e-02, -2.9218e-02,\n",
       "          3.7423e-02, -2.1357e-02,  2.8327e-02,  1.6241e-02, -5.6747e-02,\n",
       "          3.7712e-02,  5.2927e-02,  1.4948e-02,  1.5416e-02,  4.1864e-02,\n",
       "          5.5141e-02,  2.9183e-02,  7.3173e-03,  4.1935e-02,  4.9326e-02,\n",
       "          4.6938e-02,  4.5631e-02, -4.2867e-02, -1.8806e-02, -5.8294e-02,\n",
       "          4.5554e-02,  5.1048e-05,  6.0375e-02,  6.0585e-03,  5.3917e-02,\n",
       "         -2.3876e-02, -4.3622e-02, -4.1684e-02,  5.0877e-02, -3.9461e-02,\n",
       "          1.0754e-02, -4.7452e-02,  8.8579e-03, -2.1943e-02,  1.8242e-02,\n",
       "         -3.4771e-02,  4.2636e-02, -6.2227e-02,  4.3353e-02,  1.0601e-02,\n",
       "         -5.2981e-02, -1.3298e-02, -1.6732e-02, -3.3078e-03,  3.9454e-02,\n",
       "         -1.8968e-02,  2.0659e-02,  3.8404e-02,  2.4376e-03, -1.1304e-02,\n",
       "         -2.5469e-02, -4.3295e-02, -5.7330e-02,  4.6722e-02, -3.8194e-03,\n",
       "          3.0288e-02, -4.9647e-02, -2.3093e-02, -4.2864e-03,  5.8138e-03,\n",
       "         -1.8480e-02, -5.7879e-03, -5.1090e-02, -2.1904e-02,  1.1985e-02,\n",
       "         -3.0865e-02, -2.7526e-02, -1.5228e-02, -1.5328e-02,  3.3173e-02,\n",
       "         -5.8564e-02, -2.3984e-02,  1.9574e-02,  5.3881e-02,  1.8128e-02,\n",
       "          5.7113e-02, -1.2719e-02,  2.8359e-02,  1.0501e-02,  2.2084e-03,\n",
       "          4.9678e-02,  4.4290e-02,  5.4228e-02,  5.0500e-04, -3.8501e-02,\n",
       "         -2.3563e-02,  6.3195e-02,  2.9966e-02,  5.2129e-02, -3.3385e-02,\n",
       "          2.8968e-02,  4.5249e-02, -8.1093e-04,  2.2524e-03,  4.1432e-02,\n",
       "          5.6306e-03, -5.0081e-02,  3.4860e-02, -5.2826e-02,  6.0631e-02,\n",
       "         -6.0932e-03,  4.9746e-02, -1.9574e-02, -5.9364e-02,  4.4839e-02,\n",
       "         -4.6095e-02, -5.6038e-02, -6.0896e-02,  9.2138e-03, -5.3770e-02,\n",
       "         -4.1529e-02,  1.7597e-03, -1.2658e-02, -1.3074e-02, -6.1319e-02,\n",
       "          1.0455e-02, -4.9377e-02, -5.9339e-02,  2.5064e-02,  3.8339e-02,\n",
       "         -4.6817e-02, -1.9229e-02, -2.8486e-02, -6.2080e-02,  4.7019e-02,\n",
       "          3.0949e-02, -2.1324e-02, -2.3685e-02,  1.9475e-02,  5.5589e-02,\n",
       "          6.2253e-02,  1.9811e-02, -2.9261e-02,  5.5828e-03,  1.3113e-02,\n",
       "         -1.3792e-02, -4.8484e-02,  3.6920e-03, -2.8323e-02,  1.8503e-02,\n",
       "          8.2159e-03,  4.8951e-02, -3.3942e-02], device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.attention.value_projection.weight': tensor([[ 0.0151, -0.0307,  0.0051,  ..., -0.0087, -0.0416, -0.0274],\n",
       "         [ 0.0445, -0.0254,  0.0103,  ..., -0.0136, -0.0351, -0.0258],\n",
       "         [-0.0546,  0.0665, -0.0120,  ...,  0.0417, -0.0490, -0.0270],\n",
       "         ...,\n",
       "         [-0.0668,  0.0278, -0.0035,  ...,  0.0544, -0.0233, -0.0192],\n",
       "         [-0.0397, -0.0203, -0.0549,  ..., -0.0449, -0.0016, -0.0343],\n",
       "         [-0.0050, -0.0274, -0.0021,  ...,  0.0369, -0.0158, -0.0208]],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.attention.value_projection.bias': tensor([ 0.0143, -0.0200,  0.0529, -0.0470, -0.0186, -0.0086, -0.0399, -0.0134,\n",
       "         -0.0053, -0.0097,  0.0317,  0.0437,  0.0320, -0.0074, -0.0439,  0.0165,\n",
       "         -0.0083, -0.0344, -0.0066,  0.0231, -0.0370, -0.0540, -0.0191, -0.0018,\n",
       "          0.0267, -0.0245,  0.0588, -0.0167, -0.0539, -0.0127,  0.0427,  0.0261,\n",
       "         -0.0117, -0.0330, -0.0277,  0.0320, -0.0452,  0.0121,  0.0593,  0.0183,\n",
       "          0.0389, -0.0217, -0.0375,  0.0295, -0.0539, -0.0290,  0.0147, -0.0182,\n",
       "          0.0316, -0.0446, -0.0409, -0.0305, -0.0055,  0.0417, -0.0354, -0.0281,\n",
       "          0.0041,  0.0182, -0.0321,  0.0233, -0.0359,  0.0244,  0.0390, -0.0417,\n",
       "         -0.0405, -0.0071, -0.0202, -0.0303,  0.0213,  0.0414, -0.0607, -0.0356,\n",
       "         -0.0189, -0.0336,  0.0316,  0.0508,  0.0023, -0.0232, -0.0432,  0.0008,\n",
       "         -0.0235, -0.0358, -0.0013, -0.0197,  0.0327, -0.0395,  0.0460,  0.0144,\n",
       "         -0.0092,  0.0553, -0.0448, -0.0503,  0.0445,  0.0122, -0.0445,  0.0216,\n",
       "         -0.0473,  0.0151,  0.0406,  0.0479, -0.0158, -0.0551, -0.0257, -0.0081,\n",
       "         -0.0131, -0.0210,  0.0634, -0.0547,  0.0069,  0.0340, -0.0390, -0.0170,\n",
       "          0.0101,  0.0564, -0.0603,  0.0152,  0.0360,  0.0480, -0.0177, -0.0221,\n",
       "          0.0015,  0.0393,  0.0170,  0.0407, -0.0143, -0.0360,  0.0086,  0.0319,\n",
       "         -0.0278,  0.0004, -0.0114,  0.0252,  0.0558, -0.0113,  0.0669,  0.0501,\n",
       "         -0.0252, -0.0036, -0.0498,  0.0542, -0.0480,  0.0129,  0.0047,  0.0538,\n",
       "         -0.0133,  0.0418, -0.0590,  0.0443, -0.0496, -0.0005,  0.0532, -0.0403,\n",
       "          0.0644,  0.0079, -0.0226,  0.0301,  0.0295, -0.0467, -0.0096, -0.0163,\n",
       "         -0.0064,  0.0016, -0.0071, -0.0448,  0.0312, -0.0330, -0.0174, -0.0483,\n",
       "          0.0472, -0.0043, -0.0401,  0.0067, -0.0474,  0.0519, -0.0171,  0.0586,\n",
       "         -0.0251,  0.0296,  0.0011,  0.0079,  0.0121, -0.0297,  0.0408, -0.0394,\n",
       "         -0.0193, -0.0472, -0.0242,  0.0515, -0.0257, -0.0135, -0.0099, -0.0136,\n",
       "         -0.0487, -0.0111,  0.0367, -0.0442,  0.0036,  0.0340, -0.0432,  0.0179,\n",
       "          0.0573,  0.0531,  0.0137, -0.0529,  0.0292,  0.0336, -0.0140,  0.0478,\n",
       "         -0.0021, -0.0256, -0.0095,  0.0423,  0.0521,  0.0082, -0.0190,  0.0324,\n",
       "          0.0208, -0.0550,  0.0409,  0.0253, -0.0428, -0.0639, -0.0217, -0.0526,\n",
       "         -0.0114, -0.0332,  0.0150,  0.0063,  0.0215, -0.0056,  0.0101, -0.0134,\n",
       "          0.0569,  0.0452,  0.0410, -0.0002,  0.0340, -0.0437,  0.0346,  0.0311,\n",
       "         -0.0342, -0.0368, -0.0388, -0.0061,  0.0170,  0.0173,  0.0286, -0.0130],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.attention.out_projection.weight': tensor([[-0.0645,  0.0688, -0.0018,  ...,  0.0223,  0.0297,  0.0462],\n",
       "         [ 0.0418,  0.0488,  0.0502,  ...,  0.0573, -0.0356, -0.0241],\n",
       "         [ 0.0606,  0.0330, -0.0388,  ..., -0.0501,  0.0050,  0.0353],\n",
       "         ...,\n",
       "         [-0.0738, -0.0108, -0.0575,  ...,  0.0389,  0.0154,  0.0491],\n",
       "         [ 0.0237, -0.0321, -0.0603,  ...,  0.0142,  0.0554, -0.0110],\n",
       "         [-0.0471, -0.0665,  0.0706,  ...,  0.0522, -0.0186,  0.0181]],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.attention.out_projection.bias': tensor([-0.0206,  0.0630,  0.0046, -0.0498, -0.0303, -0.0390,  0.0213, -0.0612,\n",
       "         -0.0033,  0.0192, -0.0462, -0.0190,  0.0338, -0.0374,  0.0513,  0.0511,\n",
       "          0.0270, -0.0463, -0.0298, -0.0107, -0.0217, -0.0275, -0.0396, -0.0251,\n",
       "         -0.0437, -0.0543, -0.0299, -0.0594, -0.0249,  0.0325, -0.0206,  0.0519,\n",
       "         -0.0226,  0.0302, -0.0293, -0.0180,  0.0175, -0.0510,  0.0141, -0.0148,\n",
       "         -0.0159,  0.0679,  0.0058, -0.0557,  0.0198, -0.0077,  0.0227, -0.0262,\n",
       "          0.0370, -0.0462, -0.0440,  0.0316,  0.0481,  0.0316,  0.0499,  0.0177,\n",
       "          0.0078,  0.0373,  0.0490, -0.0160,  0.0426, -0.0441, -0.0362, -0.0180,\n",
       "         -0.0103, -0.0256, -0.0389,  0.0562,  0.0478, -0.0074,  0.0309, -0.0266,\n",
       "          0.0052, -0.0075, -0.0187,  0.0353, -0.0083, -0.0592, -0.0289, -0.0383,\n",
       "          0.0133,  0.0462,  0.0557, -0.0233,  0.0362, -0.0250,  0.0348, -0.0035,\n",
       "         -0.0246, -0.0547, -0.0026,  0.0041, -0.0268,  0.0187,  0.0536,  0.0040,\n",
       "         -0.0394,  0.0335, -0.0096,  0.0161,  0.0327,  0.0496, -0.0003,  0.0428,\n",
       "          0.0534, -0.0474, -0.0464,  0.0057,  0.0574, -0.0347, -0.0136,  0.0369,\n",
       "          0.0099,  0.0151,  0.0263,  0.0404, -0.0074,  0.0277, -0.0367,  0.0083,\n",
       "          0.0023, -0.0137, -0.0073,  0.0307,  0.0402,  0.0212,  0.0450, -0.0051,\n",
       "         -0.0373,  0.0578, -0.0090, -0.0099,  0.0515,  0.0247,  0.0561, -0.0396,\n",
       "         -0.0256, -0.0224, -0.0318, -0.0118,  0.0655, -0.0440,  0.0134,  0.0275,\n",
       "          0.0532,  0.0524, -0.0088,  0.0359,  0.0373, -0.0042,  0.0007, -0.0362,\n",
       "          0.0413, -0.0510, -0.0504,  0.0269, -0.0215, -0.0429, -0.0299, -0.0296,\n",
       "          0.0293, -0.0294,  0.0080,  0.0618,  0.0138, -0.0171,  0.0396, -0.0391,\n",
       "          0.0252, -0.0526,  0.0197, -0.0175,  0.0231,  0.0172,  0.0470, -0.0091,\n",
       "         -0.0379,  0.0125,  0.0274, -0.0177, -0.0505, -0.0381,  0.0260, -0.0528,\n",
       "          0.0454, -0.0369, -0.0274,  0.0233, -0.0396,  0.0130,  0.0050, -0.0580,\n",
       "         -0.0021,  0.0454, -0.0592, -0.0488,  0.0415, -0.0649,  0.0116, -0.0278,\n",
       "          0.0181, -0.0624,  0.0114, -0.0272,  0.0095,  0.0412, -0.0347,  0.0217,\n",
       "          0.0414, -0.0078,  0.0080, -0.0380, -0.0185, -0.0287,  0.0364,  0.0503,\n",
       "          0.0319,  0.0277, -0.0162, -0.0547,  0.0445, -0.0002, -0.0504, -0.0237,\n",
       "         -0.0309, -0.0500, -0.0605, -0.0018,  0.0385,  0.0472,  0.0052,  0.0213,\n",
       "         -0.0487,  0.0194, -0.0116,  0.0188,  0.0250,  0.0220,  0.0295, -0.0271,\n",
       "          0.0620, -0.0719, -0.0107,  0.0162,  0.0022, -0.0248, -0.0040, -0.0227,\n",
       "          0.0234, -0.0596], device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.conv1.weight': tensor([[[-0.0208],\n",
       "          [ 0.0526],\n",
       "          [-0.0020],\n",
       "          ...,\n",
       "          [ 0.0082],\n",
       "          [ 0.0045],\n",
       "          [ 0.0412]],\n",
       " \n",
       "         [[ 0.0101],\n",
       "          [-0.0196],\n",
       "          [ 0.0421],\n",
       "          ...,\n",
       "          [ 0.0137],\n",
       "          [-0.0120],\n",
       "          [-0.0348]],\n",
       " \n",
       "         [[-0.0355],\n",
       "          [ 0.0430],\n",
       "          [-0.0127],\n",
       "          ...,\n",
       "          [-0.0257],\n",
       "          [ 0.0099],\n",
       "          [-0.0046]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0354],\n",
       "          [ 0.0188],\n",
       "          [ 0.0644],\n",
       "          ...,\n",
       "          [-0.0168],\n",
       "          [ 0.0442],\n",
       "          [-0.0524]],\n",
       " \n",
       "         [[ 0.0384],\n",
       "          [-0.0296],\n",
       "          [ 0.0766],\n",
       "          ...,\n",
       "          [-0.0281],\n",
       "          [-0.0143],\n",
       "          [-0.0444]],\n",
       " \n",
       "         [[ 0.0591],\n",
       "          [-0.0345],\n",
       "          [ 0.0634],\n",
       "          ...,\n",
       "          [-0.0336],\n",
       "          [ 0.0383],\n",
       "          [-0.0214]]], device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.conv1.bias': tensor([-0.0936,  0.0374, -0.0189, -0.0339, -0.0845, -0.0201,  0.0357, -0.0737,\n",
       "          0.0477, -0.0013, -0.0048,  0.0256,  0.0003, -0.0140, -0.0176,  0.0158,\n",
       "         -0.0335,  0.0448,  0.0190, -0.0058,  0.0363, -0.0758, -0.0009, -0.0483,\n",
       "          0.0362, -0.0141,  0.0049,  0.0312, -0.0382, -0.0103,  0.0287,  0.0259,\n",
       "         -0.0233,  0.0102, -0.0476, -0.0699, -0.0251, -0.0522, -0.0255,  0.0084,\n",
       "         -0.0519, -0.0913, -0.0091,  0.0199, -0.0811, -0.0094, -0.0398, -0.0366,\n",
       "         -0.0578, -0.0744, -0.0394, -0.0411,  0.0265, -0.0431, -0.0693, -0.0087,\n",
       "         -0.0742,  0.0327, -0.0138,  0.0283, -0.0242, -0.0659,  0.0063, -0.0496,\n",
       "          0.0297,  0.0057, -0.0452,  0.0160,  0.0009,  0.0032,  0.0168, -0.0076,\n",
       "         -0.0619,  0.0299, -0.0656, -0.0488,  0.0017, -0.0366, -0.0012,  0.0168,\n",
       "          0.0324, -0.0118,  0.0333, -0.0356,  0.0096,  0.0225, -0.0266,  0.0483,\n",
       "          0.0119, -0.0427, -0.0441, -0.0782, -0.0169, -0.0186,  0.0203, -0.0643,\n",
       "         -0.0514, -0.0860, -0.0015,  0.0089, -0.0768, -0.0742, -0.0236,  0.0029,\n",
       "          0.0161, -0.0095,  0.0348, -0.0153, -0.0743,  0.0366,  0.0067, -0.0366,\n",
       "         -0.0082, -0.0144, -0.0485, -0.0760, -0.0393, -0.0851, -0.0037, -0.0486,\n",
       "         -0.0857, -0.0111, -0.0398, -0.0674, -0.0108, -0.0655, -0.0667, -0.0482,\n",
       "          0.0517,  0.0060, -0.0563, -0.0425, -0.0902,  0.0075,  0.0013, -0.0226,\n",
       "          0.0026, -0.0417,  0.0051,  0.0454,  0.0189, -0.0429,  0.0091, -0.0610,\n",
       "         -0.0838,  0.0212, -0.0605, -0.0339,  0.0059,  0.0326, -0.0428,  0.0196,\n",
       "         -0.0484, -0.0502, -0.0009, -0.0397,  0.0217, -0.0498, -0.0469, -0.0452,\n",
       "         -0.0641, -0.0158, -0.0081,  0.0041,  0.0308, -0.0540, -0.0384, -0.0292,\n",
       "         -0.0727,  0.0171, -0.0514, -0.0592, -0.0733, -0.0513,  0.0070,  0.0082,\n",
       "         -0.0659, -0.0099, -0.0108,  0.0373, -0.0704, -0.0312,  0.0336,  0.0408,\n",
       "          0.0429, -0.0622,  0.0185,  0.0022, -0.0634, -0.0392, -0.0593, -0.0208,\n",
       "         -0.0115, -0.0230, -0.0873,  0.0253,  0.0297, -0.0111, -0.0154,  0.0011,\n",
       "          0.0274, -0.0821, -0.0733,  0.0582, -0.0660,  0.0084, -0.0360,  0.0311,\n",
       "         -0.0610,  0.0258,  0.0442, -0.0853, -0.0376, -0.0305, -0.0231, -0.0719,\n",
       "          0.0150,  0.0121, -0.0183, -0.0571, -0.0498, -0.0803, -0.0706, -0.0630,\n",
       "         -0.0438, -0.0710, -0.0623,  0.0106, -0.0614, -0.0394,  0.0093, -0.0031,\n",
       "          0.0019,  0.0121,  0.0091, -0.0512, -0.0567, -0.0347, -0.0453, -0.0354,\n",
       "         -0.0344, -0.0425, -0.0105, -0.0329, -0.0673, -0.0381, -0.0496,  0.0314,\n",
       "         -0.0519,  0.0402, -0.0059, -0.0173,  0.0103, -0.0512, -0.0474,  0.0101],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.conv2.weight': tensor([[[-0.0563],\n",
       "          [ 0.0183],\n",
       "          [ 0.0500],\n",
       "          ...,\n",
       "          [ 0.0402],\n",
       "          [-0.0351],\n",
       "          [-0.0382]],\n",
       " \n",
       "         [[ 0.0038],\n",
       "          [ 0.0278],\n",
       "          [ 0.0293],\n",
       "          ...,\n",
       "          [-0.0021],\n",
       "          [ 0.0177],\n",
       "          [ 0.0536]],\n",
       " \n",
       "         [[ 0.0027],\n",
       "          [ 0.0254],\n",
       "          [-0.0698],\n",
       "          ...,\n",
       "          [ 0.0217],\n",
       "          [-0.0048],\n",
       "          [ 0.0243]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.0131],\n",
       "          [-0.0261],\n",
       "          [ 0.0500],\n",
       "          ...,\n",
       "          [ 0.0298],\n",
       "          [-0.0504],\n",
       "          [ 0.0036]],\n",
       " \n",
       "         [[ 0.0585],\n",
       "          [ 0.0072],\n",
       "          [-0.0414],\n",
       "          ...,\n",
       "          [ 0.0282],\n",
       "          [ 0.0162],\n",
       "          [-0.0555]],\n",
       " \n",
       "         [[-0.0558],\n",
       "          [ 0.0225],\n",
       "          [-0.0069],\n",
       "          ...,\n",
       "          [-0.0279],\n",
       "          [ 0.0441],\n",
       "          [ 0.0362]]], device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.conv2.bias': tensor([ 1.5025e-02,  4.9740e-02,  6.2825e-03, -5.4715e-02,  2.7873e-02,\n",
       "         -2.1508e-02, -3.2457e-02,  4.6786e-02,  3.8126e-02, -3.8838e-02,\n",
       "          4.5829e-02,  2.1951e-02, -2.2490e-02,  1.1961e-03,  3.3061e-02,\n",
       "         -4.6105e-03, -2.6785e-02, -3.8692e-02, -6.0436e-02, -2.3506e-02,\n",
       "         -1.5924e-03,  2.8821e-02,  4.3649e-02, -6.9875e-02,  4.0655e-02,\n",
       "         -1.1460e-02, -2.7374e-02, -2.7268e-03,  5.2642e-02, -3.8229e-04,\n",
       "         -3.1330e-02, -3.9162e-02, -2.9267e-02,  7.3735e-03, -1.5879e-02,\n",
       "          2.6544e-02,  6.4470e-03,  2.0400e-02,  1.3133e-02,  4.3604e-02,\n",
       "         -4.5771e-02,  9.9552e-03, -1.0685e-02, -1.7683e-02,  2.2589e-02,\n",
       "         -3.7950e-02, -4.5329e-02,  1.3336e-02, -5.1132e-02,  8.7867e-03,\n",
       "          4.3837e-02,  2.0721e-02, -4.0469e-02,  3.6577e-02,  2.2782e-02,\n",
       "         -2.2741e-02,  3.4711e-03,  4.2468e-02, -4.2777e-02,  5.4838e-03,\n",
       "          9.9160e-03,  1.6636e-02, -4.8764e-03,  2.3960e-02,  3.7824e-02,\n",
       "         -1.5857e-02,  1.4858e-02,  4.4840e-03, -4.6272e-02,  4.5909e-02,\n",
       "          1.0988e-02, -2.1871e-02, -1.9354e-02, -5.6479e-02,  8.2882e-03,\n",
       "          2.1114e-02, -1.8345e-02, -6.3295e-02,  4.1055e-02, -4.0314e-02,\n",
       "         -8.7887e-03,  4.2812e-03, -4.1832e-02, -5.8232e-03, -1.2254e-02,\n",
       "          8.9988e-03,  4.4419e-02,  1.3793e-02,  4.0344e-02, -2.2778e-02,\n",
       "          3.6980e-02,  3.5572e-02, -4.6000e-02,  5.5828e-02,  1.4695e-02,\n",
       "          3.2911e-02, -2.4360e-02,  3.3807e-02,  3.3192e-02,  4.7488e-03,\n",
       "         -1.3886e-02, -5.1245e-02,  4.7381e-02, -3.0793e-02,  1.9007e-02,\n",
       "         -2.5037e-02,  9.3668e-03,  3.8560e-02,  6.7149e-02,  2.0954e-02,\n",
       "         -4.0728e-02, -9.4768e-03, -1.1052e-02,  2.3740e-02,  2.4170e-03,\n",
       "          4.0866e-02, -2.5682e-02,  6.3746e-02, -1.8143e-02, -7.5934e-03,\n",
       "          2.9724e-06,  3.7261e-02, -5.6490e-02,  1.6389e-02,  4.4000e-02,\n",
       "          1.0488e-02, -5.7386e-02, -1.5625e-02, -6.3495e-02, -2.9051e-02,\n",
       "         -2.1188e-03, -1.8223e-02,  3.2088e-02,  8.1140e-03,  6.5660e-02,\n",
       "          1.1028e-02, -3.2684e-02, -2.9095e-02, -3.4953e-02, -5.0452e-02,\n",
       "          2.2837e-03, -4.3275e-02,  4.0613e-02,  5.2530e-02, -2.5440e-02,\n",
       "         -2.8222e-02,  5.8380e-03, -1.8982e-02, -3.3640e-02,  1.8017e-02,\n",
       "         -4.4411e-02, -3.5873e-02, -4.4858e-02, -6.1981e-03, -1.3738e-02,\n",
       "          3.6286e-02,  4.6400e-02, -4.0564e-02,  4.9079e-02,  3.6027e-03,\n",
       "          1.3318e-02,  2.3122e-02, -2.0282e-02, -3.3265e-02, -4.2243e-02,\n",
       "          5.6272e-02,  5.2800e-02,  3.5075e-02, -1.3200e-02,  5.5743e-02,\n",
       "          1.2167e-02, -1.5229e-02, -1.7907e-02, -3.2384e-02,  2.1517e-02,\n",
       "         -6.0453e-02,  2.2610e-02,  2.6968e-02,  6.2274e-02,  2.2457e-02,\n",
       "         -2.8399e-02,  2.8292e-02,  2.2352e-02, -4.0474e-02,  4.8797e-02,\n",
       "         -2.6691e-02, -4.5931e-02, -5.0351e-02, -1.3603e-02, -5.9364e-02,\n",
       "         -5.3980e-02,  4.3982e-02, -5.7180e-02, -5.6316e-03,  1.2644e-02,\n",
       "          6.4948e-03,  4.4859e-02, -2.4500e-02, -2.5740e-02, -4.8780e-02,\n",
       "          1.7399e-02, -3.0597e-02,  3.9231e-02, -4.5018e-02, -3.9311e-02,\n",
       "          2.8296e-03, -3.1758e-03, -1.6756e-02,  4.0523e-02,  2.0776e-02,\n",
       "          1.3658e-02, -3.4628e-02, -1.5871e-02,  3.7280e-02,  8.2384e-03,\n",
       "         -2.4192e-02, -1.3732e-02,  3.2297e-02, -5.6734e-02,  3.1017e-02,\n",
       "          1.4179e-02,  4.4429e-02,  2.3195e-02, -5.4553e-02,  1.1377e-04,\n",
       "          3.1138e-02, -6.3097e-02,  1.1570e-02,  4.1590e-02,  3.1143e-02,\n",
       "          3.4627e-02,  3.5677e-02, -3.4025e-02, -1.6825e-02, -1.0638e-02,\n",
       "          4.4196e-02, -5.1158e-02, -1.8210e-02, -4.8300e-02,  1.2104e-02,\n",
       "          3.2489e-02,  3.5678e-02, -4.8906e-02,  6.9848e-03, -4.1417e-02,\n",
       "          3.1775e-02, -3.8686e-02, -5.2052e-02, -2.0610e-02,  3.2015e-02],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.norm1.weight': tensor([1.0265, 1.0063, 1.0153, 1.0215, 1.0538, 1.0168, 1.0238, 1.0317, 1.0231,\n",
       "         1.0229, 1.0157, 1.0388, 1.0387, 1.0119, 1.0131, 1.0359, 0.9989, 1.0070,\n",
       "         1.0238, 1.0283, 1.0156, 1.0167, 1.0264, 1.0161, 1.0234, 0.9833, 1.0137,\n",
       "         0.9933, 1.0347, 0.9998, 1.0098, 0.9960, 0.9912, 0.9963, 1.0051, 1.0049,\n",
       "         1.0053, 1.0050, 1.0035, 1.0051, 1.0129, 1.0006, 1.0129, 0.9766, 0.9906,\n",
       "         1.0060, 1.0041, 1.0171, 1.0037, 0.9818, 0.9891, 0.9878, 0.9866, 0.9896,\n",
       "         0.9886, 0.9822, 0.9922, 1.0026, 1.0105, 1.0085, 0.9735, 0.9987, 0.9995,\n",
       "         0.9839, 0.9902, 0.9874, 1.0064, 1.0182, 0.9788, 0.9975, 0.9728, 0.9822,\n",
       "         0.9983, 0.9995, 0.9982, 0.9970, 1.0074, 0.9846, 0.9895, 0.9892, 0.9928,\n",
       "         0.9953, 0.9892, 0.9961, 0.9865, 0.9699, 0.9866, 0.9994, 0.9648, 0.9914,\n",
       "         1.0054, 1.0025, 0.9946, 0.9928, 0.9933, 0.9699, 0.9853, 1.0022, 0.9792,\n",
       "         0.9842, 1.0020, 0.9741, 1.0037, 0.9846, 1.0099, 0.9807, 0.9880, 0.9759,\n",
       "         0.9890, 1.0074, 1.0015, 1.0210, 0.9907, 1.0039, 0.9930, 0.9924, 1.0180,\n",
       "         1.0018, 0.9975, 0.9903, 1.0091, 1.0055, 0.9877, 1.0057, 1.0082, 1.0043,\n",
       "         1.0113, 1.0205, 1.0060, 1.0148, 0.9979, 0.9999, 1.0136, 1.0023, 1.0013,\n",
       "         1.0001, 0.9925, 0.9924, 1.0124, 1.0267, 0.9844, 1.0011, 0.9858, 0.9929,\n",
       "         1.0042, 1.0001, 0.9943, 1.0069, 0.9880, 0.9836, 1.0021, 0.9755, 0.9851,\n",
       "         1.0109, 0.9850, 0.9896, 1.0054, 0.9775, 0.9904, 0.9873, 1.0049, 0.9882,\n",
       "         0.9941, 0.9952, 0.9875, 0.9828, 0.9819, 0.9802, 0.9851, 0.9992, 0.9945,\n",
       "         0.9978, 0.9885, 0.9694, 0.9793, 0.9856, 1.0161, 1.0113, 1.0283, 0.9990,\n",
       "         1.0058, 1.0100, 0.9936, 1.0021, 1.0208, 1.0039, 1.0092, 0.9907, 1.0143,\n",
       "         1.0100, 1.0147, 1.0152, 0.9994, 1.0006, 0.9852, 1.0157, 0.9931, 1.0113,\n",
       "         0.9939, 1.0310, 0.9994, 1.0056, 0.9971, 0.9902, 1.0024, 0.9854, 0.9979,\n",
       "         1.0086, 1.0111, 1.0047, 1.0204, 1.0099, 1.0102, 1.0058, 0.9945, 1.0154,\n",
       "         1.0241, 1.0060, 1.0109, 1.0145, 1.0090, 1.0087, 1.0140, 1.0000, 1.0216,\n",
       "         1.0357, 1.0165, 1.0007, 1.0045, 1.0448, 1.0090, 1.0205, 1.0143, 0.9903,\n",
       "         1.0409, 1.0153, 1.0407, 1.0030, 1.0149, 1.0224, 1.0345, 1.0423, 1.0298,\n",
       "         1.0379, 1.0210, 1.0450, 1.0087, 1.0205, 1.0486, 1.0110],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.norm1.bias': tensor([-1.8551e-02,  1.1457e-02, -3.3220e-02, -1.5818e-02, -7.7394e-03,\n",
       "          5.5857e-03,  2.1478e-02, -4.8887e-02, -4.7901e-02,  1.8570e-03,\n",
       "         -3.4115e-02,  2.2422e-02,  8.0174e-03, -2.4904e-02, -4.3117e-03,\n",
       "          4.0268e-02, -1.3696e-02, -3.2697e-02,  1.9013e-03, -3.6969e-02,\n",
       "          4.4893e-04,  3.1265e-02, -1.9082e-02, -2.0377e-02,  5.3584e-03,\n",
       "         -3.0340e-02, -2.5624e-02, -3.0545e-02,  2.8029e-02,  1.6307e-02,\n",
       "         -3.0345e-02,  1.3271e-02, -1.2436e-02, -3.5252e-02, -2.6049e-02,\n",
       "         -3.3975e-02,  1.4226e-02, -4.8679e-03, -1.4410e-02, -2.6816e-02,\n",
       "         -3.3722e-03,  2.8327e-02, -3.7956e-03, -2.2085e-02,  8.8434e-03,\n",
       "          4.6452e-03,  4.6136e-03,  2.9566e-03,  8.5487e-03, -6.5062e-03,\n",
       "          1.6770e-03,  1.0091e-02, -8.7925e-03, -8.6113e-03, -1.6579e-02,\n",
       "         -3.0097e-02, -6.3340e-05, -1.0003e-02,  1.1393e-02,  2.6359e-03,\n",
       "         -1.4687e-02, -2.3910e-03, -1.3375e-03,  2.6715e-03,  2.4475e-03,\n",
       "         -1.4854e-02, -1.9170e-02, -9.1028e-03,  3.4943e-03, -9.2694e-03,\n",
       "         -6.2307e-03, -6.0065e-03, -4.0936e-03,  8.0332e-03, -4.1832e-03,\n",
       "          1.4198e-02, -2.0723e-03, -7.4004e-03, -1.3999e-03, -9.5482e-03,\n",
       "         -3.0980e-03,  1.7386e-02,  3.3496e-02, -3.9151e-03, -1.3636e-02,\n",
       "          6.4394e-03,  8.0403e-03,  2.9935e-02, -3.9752e-03, -1.6209e-02,\n",
       "          9.9180e-03, -2.7175e-02,  6.1649e-03,  1.1697e-02,  2.0043e-02,\n",
       "          6.4492e-03,  4.4557e-03,  5.4897e-03,  2.0298e-02, -4.1499e-03,\n",
       "          1.2092e-02,  1.7818e-03,  1.7116e-02,  8.8397e-03,  1.1896e-02,\n",
       "          1.0161e-02,  4.1084e-03,  2.0694e-03,  2.8330e-02,  9.4747e-03,\n",
       "         -8.5346e-04,  1.4799e-02,  3.9810e-03,  1.5103e-02,  2.5959e-02,\n",
       "          1.2706e-02,  2.4734e-02,  2.5023e-02,  1.2009e-02,  9.3351e-03,\n",
       "          3.0378e-02, -1.5507e-03,  6.1889e-03,  5.6530e-03,  1.3725e-02,\n",
       "          2.1970e-02,  8.2626e-03,  4.8622e-03, -1.2589e-02,  2.3295e-02,\n",
       "          1.8854e-03, -5.1728e-04,  1.7680e-02,  2.1030e-02,  1.4359e-02,\n",
       "          1.2613e-02, -6.6808e-04,  1.4383e-02,  2.5113e-02, -1.0656e-03,\n",
       "          2.9505e-02,  3.1143e-03, -8.2503e-03,  1.0567e-02,  1.6313e-03,\n",
       "         -3.2079e-03,  8.6155e-03, -7.8417e-03,  9.4209e-03, -1.0487e-02,\n",
       "          8.7252e-03,  9.3554e-03,  1.2731e-02, -5.0887e-03, -3.1698e-03,\n",
       "          3.5091e-02,  1.8065e-03,  8.3695e-03, -1.7134e-03, -2.2809e-02,\n",
       "         -1.8500e-02, -3.0441e-04,  5.8546e-03,  8.7754e-03, -7.0377e-03,\n",
       "         -6.8700e-03, -1.0769e-03, -9.4428e-03,  4.0244e-03, -1.2706e-02,\n",
       "         -4.7755e-03, -2.0560e-02, -1.2082e-02, -1.0272e-02, -3.0953e-03,\n",
       "         -1.4147e-02, -2.0005e-02, -2.0816e-02,  2.1070e-02,  6.9964e-03,\n",
       "         -1.0428e-02, -5.3907e-03,  5.4919e-03, -7.9914e-03,  1.6241e-02,\n",
       "         -7.2129e-03,  2.4442e-03, -1.0776e-03,  6.2776e-03, -1.7666e-02,\n",
       "         -1.6486e-02, -7.1479e-03, -1.1835e-02, -2.1307e-03, -1.0195e-03,\n",
       "         -4.1071e-03,  1.4710e-02, -1.4139e-02,  1.4630e-02,  5.6228e-03,\n",
       "          2.4615e-03, -1.3602e-02, -1.3897e-02, -8.6036e-03,  4.9750e-03,\n",
       "          1.6148e-02,  4.5749e-03, -2.3940e-02, -5.8566e-03, -7.7110e-03,\n",
       "         -6.5230e-03, -6.1909e-03, -6.2558e-03, -2.3436e-02, -6.2482e-03,\n",
       "         -7.3495e-03,  7.8169e-03,  1.1756e-02, -6.0291e-03, -3.1265e-02,\n",
       "         -3.0789e-03, -3.2954e-02, -2.5172e-02,  3.0379e-03, -8.0913e-03,\n",
       "          3.8499e-03, -1.2237e-02, -1.4904e-02, -9.8963e-03,  7.6971e-03,\n",
       "          1.3852e-02,  1.2890e-02, -1.8235e-02,  1.7332e-03, -3.7676e-02,\n",
       "         -9.8009e-03,  2.3886e-02, -3.9145e-03, -5.1420e-03,  1.6082e-02,\n",
       "          1.5894e-02, -6.7131e-02,  9.1772e-03, -3.0883e-02, -7.2898e-03,\n",
       "          2.0129e-02, -4.9853e-02, -3.8027e-02,  1.8145e-02, -2.3744e-03],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.norm2.weight': tensor([1.0534, 1.0294, 1.0558, 1.0640, 1.0731, 1.0365, 1.0264, 1.0420, 1.0323,\n",
       "         1.0330, 1.0364, 1.0598, 1.0597, 1.0265, 1.0347, 1.0351, 1.0138, 1.0258,\n",
       "         1.0395, 1.0287, 1.0310, 1.0264, 1.0338, 1.0113, 1.0279, 0.9915, 1.0094,\n",
       "         1.0075, 1.0275, 1.0001, 0.9974, 0.9944, 1.0025, 1.0041, 1.0093, 1.0111,\n",
       "         0.9886, 0.9987, 1.0147, 1.0010, 1.0211, 1.0105, 1.0215, 0.9937, 1.0009,\n",
       "         1.0153, 1.0123, 1.0196, 1.0171, 0.9955, 0.9940, 0.9900, 0.9969, 0.9874,\n",
       "         0.9985, 0.9779, 0.9874, 0.9999, 0.9987, 1.0029, 0.9645, 0.9931, 0.9921,\n",
       "         0.9736, 0.9696, 0.9796, 0.9973, 1.0135, 0.9667, 0.9857, 0.9669, 0.9771,\n",
       "         1.0001, 0.9901, 1.0112, 0.9844, 1.0070, 0.9759, 0.9873, 0.9916, 0.9801,\n",
       "         1.0045, 0.9790, 0.9897, 0.9830, 0.9748, 0.9846, 0.9872, 0.9618, 0.9981,\n",
       "         0.9925, 1.0027, 0.9897, 0.9972, 0.9836, 0.9622, 0.9807, 1.0005, 0.9769,\n",
       "         0.9853, 0.9919, 0.9789, 0.9846, 0.9905, 1.0004, 0.9926, 0.9874, 0.9795,\n",
       "         0.9878, 0.9987, 1.0073, 1.0153, 0.9879, 0.9962, 0.9909, 0.9929, 1.0331,\n",
       "         0.9898, 0.9907, 0.9881, 1.0022, 0.9973, 0.9797, 1.0059, 0.9950, 0.9934,\n",
       "         1.0203, 1.0131, 0.9981, 0.9962, 0.9988, 0.9886, 1.0075, 0.9943, 0.9965,\n",
       "         1.0006, 0.9738, 0.9808, 1.0062, 1.0087, 0.9843, 0.9952, 0.9827, 0.9963,\n",
       "         0.9909, 0.9851, 1.0038, 1.0003, 0.9871, 0.9872, 1.0067, 0.9714, 0.9754,\n",
       "         1.0013, 0.9855, 0.9837, 0.9918, 0.9760, 0.9809, 0.9812, 1.0003, 0.9905,\n",
       "         0.9931, 0.9904, 0.9907, 0.9793, 0.9766, 0.9798, 0.9787, 0.9901, 0.9951,\n",
       "         0.9978, 0.9874, 0.9706, 0.9866, 0.9883, 1.0081, 1.0003, 1.0245, 0.9911,\n",
       "         0.9880, 1.0030, 0.9812, 0.9891, 1.0128, 1.0118, 1.0182, 0.9920, 1.0052,\n",
       "         1.0075, 1.0105, 1.0105, 1.0088, 0.9898, 0.9910, 1.0073, 0.9991, 0.9971,\n",
       "         0.9931, 1.0171, 1.0005, 1.0201, 0.9983, 0.9805, 0.9989, 0.9790, 1.0093,\n",
       "         1.0038, 1.0084, 1.0062, 1.0222, 1.0267, 1.0145, 1.0104, 1.0038, 1.0251,\n",
       "         1.0277, 1.0123, 1.0201, 1.0120, 1.0160, 1.0080, 1.0125, 0.9993, 1.0173,\n",
       "         1.0360, 1.0151, 0.9922, 1.0137, 1.0433, 1.0193, 1.0297, 1.0287, 1.0008,\n",
       "         1.0444, 1.0329, 1.0513, 1.0124, 1.0426, 1.0324, 1.0521, 1.0467, 1.0473,\n",
       "         1.0387, 1.0294, 1.0537, 1.0196, 1.0401, 1.0511, 1.0522],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.attn_layers.0.norm2.bias': tensor([ 5.8720e-03,  6.4767e-03, -5.2209e-02, -7.1229e-03,  1.4477e-04,\n",
       "         -2.9009e-03,  1.6356e-02, -1.9629e-02, -2.7523e-02,  8.3292e-03,\n",
       "         -1.1276e-03,  7.1703e-03, -8.3775e-03, -2.2502e-02, -5.7603e-03,\n",
       "          1.3307e-03, -1.4284e-02, -1.3364e-02, -4.4897e-03, -3.1942e-03,\n",
       "          1.9056e-02,  1.9325e-02,  7.5932e-03, -8.1969e-03,  5.4688e-04,\n",
       "         -7.7417e-03, -1.2261e-02, -1.3600e-02,  1.5154e-02, -3.4504e-03,\n",
       "         -6.6343e-03, -1.0593e-02, -1.0615e-02, -9.5826e-03, -1.4873e-02,\n",
       "         -1.5790e-02, -7.3179e-03, -1.4255e-02, -7.7384e-03, -2.2867e-03,\n",
       "         -2.9594e-03,  8.0194e-03,  9.8285e-04, -1.6049e-02, -8.1468e-03,\n",
       "         -7.7795e-03, -6.8466e-03, -5.3608e-03, -3.1732e-03, -3.4760e-03,\n",
       "          3.3091e-03,  1.8129e-03, -6.5954e-03, -9.5442e-03, -1.2854e-02,\n",
       "         -1.6534e-02, -9.1464e-03, -1.2478e-02, -8.9060e-03, -1.3052e-02,\n",
       "         -1.1971e-02, -1.2410e-02, -9.9052e-04, -7.8473e-03, -1.6556e-03,\n",
       "         -1.2747e-02, -1.8037e-02, -1.6772e-02, -8.5114e-03, -1.2347e-02,\n",
       "         -2.6679e-02, -1.1466e-02, -3.0483e-03, -9.8492e-04, -5.7103e-03,\n",
       "         -2.6598e-03, -1.2451e-03, -7.3566e-03, -1.0136e-03, -1.0707e-02,\n",
       "         -2.3877e-03, -1.1806e-02,  7.9366e-03, -9.1266e-03, -2.7086e-03,\n",
       "         -9.3231e-04,  5.5548e-03,  1.2624e-02,  5.6654e-03, -4.5505e-03,\n",
       "         -1.0045e-02, -1.3144e-02, -6.8477e-03,  3.8286e-03,  9.8765e-03,\n",
       "         -1.0078e-03,  8.3108e-04, -8.0017e-05,  1.2735e-02, -1.1022e-04,\n",
       "         -7.7597e-03, -1.3984e-02, -7.2007e-03, -1.4079e-03,  5.5079e-03,\n",
       "          9.0355e-03,  8.9017e-03,  1.5178e-02,  2.2807e-02,  1.6306e-02,\n",
       "          1.6104e-02,  2.2747e-02,  1.2308e-02,  1.8797e-02,  2.3469e-02,\n",
       "          1.6164e-02,  1.5175e-02,  2.0333e-02,  1.2784e-02,  1.0783e-02,\n",
       "          1.6904e-02,  1.1508e-02,  7.2662e-03,  8.2577e-03,  1.5118e-02,\n",
       "          1.3634e-02,  8.1016e-03, -5.0794e-03, -5.1304e-03,  3.3776e-03,\n",
       "         -1.1026e-03,  3.3494e-05, -4.0684e-04,  1.0728e-02,  1.4135e-02,\n",
       "          1.1644e-02,  1.6382e-02,  1.6714e-02,  1.2248e-02,  6.7709e-03,\n",
       "          6.6205e-03,  1.0919e-02, -1.9805e-03, -7.5492e-03, -7.4424e-03,\n",
       "         -1.0146e-02,  1.6621e-02, -5.5825e-03,  3.3434e-03, -2.6966e-03,\n",
       "          7.9742e-03,  1.1459e-02,  1.3224e-02,  3.4100e-04, -6.1447e-03,\n",
       "          2.4350e-03,  6.4979e-03,  1.2949e-02, -2.9256e-03, -1.2241e-02,\n",
       "         -5.4712e-03, -2.0623e-03,  2.8001e-03,  4.0403e-03, -9.2127e-03,\n",
       "          6.8633e-03, -1.0299e-03,  1.0215e-02,  9.0131e-03, -4.2710e-04,\n",
       "          6.2617e-03, -5.5231e-03, -3.1239e-04, -1.2534e-02, -9.2490e-03,\n",
       "         -4.2244e-04, -1.4329e-02, -4.9629e-03,  1.4840e-02,  1.4657e-02,\n",
       "          1.2307e-02,  4.1395e-03,  6.8409e-03,  4.4897e-03,  5.6666e-03,\n",
       "          8.5608e-04,  4.9695e-03, -7.8743e-03, -2.6209e-03, -6.9618e-03,\n",
       "         -7.5116e-03,  2.9842e-05, -2.1111e-03,  2.5236e-03,  5.6475e-03,\n",
       "          1.0198e-03,  7.4537e-03, -9.4862e-04,  9.3034e-03,  8.2384e-03,\n",
       "          4.5684e-03, -3.3078e-03, -4.5292e-03, -1.7054e-03,  8.5609e-03,\n",
       "          1.2013e-02,  8.8694e-04, -7.6784e-03, -2.3686e-03, -2.9237e-03,\n",
       "         -1.0364e-03, -7.6927e-03, -6.5636e-03, -1.4988e-02, -6.0728e-03,\n",
       "         -5.9691e-03, -1.3014e-02,  5.5685e-03, -1.4396e-02, -1.6917e-02,\n",
       "         -3.2197e-03, -6.0953e-03, -5.6484e-03,  8.0990e-03,  3.9553e-03,\n",
       "          8.2494e-03, -6.4541e-03, -5.7981e-03, -1.1204e-02, -9.0502e-03,\n",
       "         -9.0369e-03, -8.6908e-03, -1.9183e-02, -1.5850e-02, -2.9335e-02,\n",
       "         -8.8828e-03,  5.8289e-03, -2.1412e-02, -1.5974e-02, -4.9134e-03,\n",
       "          1.2977e-02, -3.4714e-02,  6.0173e-03,  5.2806e-03,  8.5521e-03,\n",
       "          2.9360e-02, -1.5500e-02, -5.9520e-02, -1.1489e-02, -2.4086e-02],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.norm.weight': tensor([0.9996, 1.0137, 0.9808, 0.9903, 0.9962, 1.0220, 1.0185, 0.9918, 1.0286,\n",
       "         0.9937, 1.0383, 1.0345, 1.0100, 1.0278, 1.0273, 1.0196, 1.0336, 1.0266,\n",
       "         1.0031, 1.0001, 1.0002, 1.0197, 1.0173, 1.0226, 1.0116, 0.9757, 1.0073,\n",
       "         1.0179, 1.0113, 0.9930, 0.9935, 0.9740, 1.0022, 1.0039, 0.9944, 1.0020,\n",
       "         0.9755, 0.9922, 1.0007, 1.0250, 1.0299, 1.0303, 1.0250, 1.0228, 1.0351,\n",
       "         1.0464, 1.0345, 1.0109, 1.0206, 1.0366, 1.0115, 1.0101, 1.0089, 0.9920,\n",
       "         1.0079, 0.9758, 1.0078, 1.0078, 1.0039, 1.0037, 0.9706, 0.9850, 0.9792,\n",
       "         0.9704, 0.9646, 0.9863, 0.9973, 1.0234, 0.9813, 0.9970, 0.9834, 0.9823,\n",
       "         1.0010, 0.9996, 1.0144, 0.9914, 1.0119, 0.9813, 0.9791, 0.9939, 0.9840,\n",
       "         0.9899, 0.9814, 0.9979, 0.9978, 0.9854, 0.9932, 0.9862, 0.9726, 0.9981,\n",
       "         0.9985, 0.9985, 0.9811, 0.9994, 1.0010, 0.9655, 0.9813, 1.0018, 0.9847,\n",
       "         0.9920, 0.9861, 0.9716, 0.9917, 1.0191, 1.0114, 0.9884, 0.9926, 0.9897,\n",
       "         1.0077, 0.9917, 1.0103, 1.0164, 0.9993, 1.0069, 1.0124, 0.9934, 1.0347,\n",
       "         0.9808, 1.0048, 1.0087, 0.9905, 1.0034, 0.9916, 1.0001, 0.9969, 0.9892,\n",
       "         1.0160, 1.0089, 1.0096, 0.9897, 1.0014, 0.9976, 1.0159, 0.9901, 1.0075,\n",
       "         0.9991, 0.9744, 0.9865, 1.0071, 1.0163, 0.9821, 1.0024, 0.9940, 0.9912,\n",
       "         0.9960, 0.9926, 1.0021, 1.0152, 0.9773, 1.0015, 1.0215, 0.9813, 0.9835,\n",
       "         1.0064, 0.9915, 0.9781, 0.9808, 0.9845, 0.9761, 0.9753, 0.9958, 0.9990,\n",
       "         0.9905, 0.9880, 1.0072, 0.9847, 0.9919, 1.0007, 0.9732, 1.0045, 0.9898,\n",
       "         0.9933, 0.9754, 0.9681, 0.9762, 0.9786, 1.0030, 0.9733, 1.0221, 0.9844,\n",
       "         0.9855, 1.0044, 0.9894, 1.0004, 0.9941, 1.0036, 1.0336, 0.9874, 1.0054,\n",
       "         1.0264, 1.0269, 1.0227, 1.0018, 1.0138, 0.9921, 1.0105, 1.0083, 0.9989,\n",
       "         0.9903, 1.0443, 1.0186, 1.0120, 1.0038, 0.9977, 0.9883, 0.9793, 0.9924,\n",
       "         1.0028, 1.0208, 1.0359, 1.0437, 1.0197, 1.0071, 1.0109, 1.0227, 1.0128,\n",
       "         1.0448, 1.0246, 1.0239, 1.0034, 1.0142, 1.0093, 0.9983, 0.9860, 0.9820,\n",
       "         1.0180, 1.0102, 0.9896, 1.0147, 1.0190, 0.9941, 1.0111, 1.0110, 0.9930,\n",
       "         1.0112, 1.0379, 1.0220, 1.0390, 1.0467, 1.0253, 0.9934, 1.0125, 0.9863,\n",
       "         1.0211, 0.9988, 0.9854, 0.9826, 0.9990, 0.9857, 1.0201],\n",
       "        device='cuda:0'),\n",
       " 'encoder.encoder.norm.bias': tensor([ 2.6608e-02,  2.0360e-02,  6.7330e-03,  1.1948e-02,  5.2406e-03,\n",
       "          1.2758e-02, -3.8956e-03, -9.6614e-03, -8.2446e-03, -5.0232e-03,\n",
       "         -4.5879e-03, -1.9420e-02, -2.6535e-02, -3.1226e-02, -3.0482e-02,\n",
       "         -1.8271e-02, -1.2640e-02, -9.7982e-03, -1.9750e-02,  6.7047e-03,\n",
       "          5.3312e-03,  6.3267e-03, -1.5399e-03, -7.1531e-03, -1.1518e-02,\n",
       "         -7.6682e-03, -1.1279e-02, -7.1933e-03, -2.0519e-03, -9.5037e-03,\n",
       "         -3.1073e-04, -2.0322e-02, -1.9956e-02, -1.5196e-02, -2.0522e-02,\n",
       "         -1.9344e-02, -1.7994e-02, -1.7794e-02, -7.4897e-03, -7.5945e-05,\n",
       "         -1.7158e-03, -6.6184e-04, -8.0365e-03, -1.6948e-02, -2.0504e-02,\n",
       "         -2.0140e-02, -1.6977e-02, -1.8614e-02, -1.5401e-02, -4.3257e-03,\n",
       "          7.7003e-04, -7.3254e-03, -8.0225e-03, -1.8124e-02, -2.3282e-02,\n",
       "         -2.0573e-02, -1.8082e-02, -1.3942e-02, -1.2431e-02, -1.0109e-02,\n",
       "         -5.6481e-03, -2.5347e-03, -6.5194e-03, -4.0414e-03, -5.9383e-03,\n",
       "         -5.0264e-03, -9.8310e-03, -1.1319e-02, -7.2199e-03, -1.5426e-03,\n",
       "         -1.9705e-02, -7.1622e-03, -2.0814e-03, -7.3594e-04,  6.2692e-03,\n",
       "          1.0733e-03,  2.2247e-03,  4.9623e-03, -3.1049e-03, -2.0475e-03,\n",
       "         -2.2273e-03, -1.1986e-02,  3.1977e-03, -4.6563e-04,  4.0145e-03,\n",
       "          7.8989e-03,  8.0726e-03,  1.0618e-02,  7.7312e-03,  1.0282e-03,\n",
       "         -1.0147e-02, -7.8487e-03,  3.3982e-03,  1.1856e-02,  1.4481e-02,\n",
       "          1.6453e-03,  5.2459e-03,  7.7709e-03,  1.5141e-02,  7.8971e-03,\n",
       "         -8.0217e-03, -1.1717e-02, -5.5286e-03,  3.8948e-03,  1.0699e-02,\n",
       "          1.3950e-02,  9.6843e-03,  1.8832e-02,  2.7085e-02,  2.4174e-02,\n",
       "          2.0249e-02,  1.5600e-02,  1.4704e-02,  2.1648e-02,  2.0448e-02,\n",
       "          1.9020e-02,  1.6125e-02,  1.5122e-02,  1.6076e-02,  1.0689e-02,\n",
       "          7.2706e-03,  1.3797e-02,  1.1091e-02,  5.2590e-03,  8.0288e-03,\n",
       "          5.0897e-03,  4.8311e-03, -5.2229e-03, -5.6326e-03, -1.8502e-03,\n",
       "         -6.8659e-04,  2.3483e-03,  4.2015e-03,  8.8604e-03,  1.5739e-02,\n",
       "          1.1154e-02,  1.8537e-02,  1.7297e-02,  1.2055e-02,  1.1930e-02,\n",
       "          1.4723e-05,  7.9744e-03, -1.0121e-03, -1.1113e-02, -1.2341e-02,\n",
       "         -9.7119e-03,  7.4544e-03, -4.4801e-04, -7.6602e-03, -6.7236e-03,\n",
       "          1.8618e-03,  1.2496e-02,  1.1032e-02,  1.3263e-03, -5.5982e-03,\n",
       "         -3.5483e-03,  3.7814e-03,  1.0539e-02, -4.6736e-03, -2.0348e-02,\n",
       "         -7.5446e-03, -6.4300e-03, -2.8746e-03, -4.4389e-03, -5.4007e-03,\n",
       "         -6.5155e-04, -2.0828e-03,  9.3939e-03,  6.7980e-03,  3.6168e-03,\n",
       "          5.0433e-03,  9.5181e-04, -5.2131e-03, -1.0989e-02, -1.8167e-02,\n",
       "         -5.6000e-03, -5.9158e-03,  2.0521e-03,  1.5661e-02,  1.9231e-02,\n",
       "          1.7974e-02,  1.0285e-02,  1.0567e-02,  8.0389e-03,  1.9357e-03,\n",
       "          4.0992e-03,  2.8810e-03, -1.0708e-02, -9.5407e-03, -9.0502e-03,\n",
       "         -4.2725e-03,  5.1685e-03,  4.8682e-04,  6.2878e-03,  7.8464e-03,\n",
       "          6.9762e-03,  1.0872e-02,  8.1001e-03,  1.0768e-02,  1.1294e-02,\n",
       "          5.0570e-03,  1.3328e-03,  1.2133e-04,  2.3332e-04,  7.1328e-03,\n",
       "          5.8195e-03,  6.1473e-03, -2.4713e-04, -3.3760e-03, -4.1417e-03,\n",
       "          6.2821e-04, -7.5947e-03, -7.3181e-03, -9.6450e-03, -9.4102e-03,\n",
       "         -7.2153e-03, -9.2092e-03, -3.0038e-03, -1.0985e-02, -9.0074e-03,\n",
       "         -7.2413e-03, -7.7481e-03,  1.0554e-03,  2.4483e-03,  8.8469e-04,\n",
       "          1.0549e-02, -4.1239e-03, -4.1225e-03, -4.5808e-03, -1.2560e-02,\n",
       "         -2.0449e-02, -2.0368e-02, -1.6260e-02, -1.4786e-02, -8.4697e-03,\n",
       "         -9.3015e-03, -2.4593e-02, -2.5111e-02, -5.7241e-03, -9.7244e-03,\n",
       "         -3.2406e-03, -1.1115e-02, -3.9768e-03,  3.7357e-03,  8.1878e-03,\n",
       "          3.7630e-03, -3.1124e-03, -2.4577e-02, -2.6514e-02, -2.7680e-02],\n",
       "        device='cuda:0'),\n",
       " 'subject_wise_linear.0.weight': tensor([[-0.0479, -0.0626,  0.0219,  ..., -0.0213,  0.0139, -0.0538],\n",
       "         [ 0.0418,  0.0266,  0.0598,  ...,  0.0007,  0.0370,  0.0190],\n",
       "         [-0.0034, -0.0269, -0.0604,  ..., -0.0538, -0.0401,  0.0317],\n",
       "         ...,\n",
       "         [-0.0211,  0.0229,  0.0410,  ..., -0.0211,  0.0524, -0.0256],\n",
       "         [-0.0473,  0.0493, -0.0448,  ...,  0.0570,  0.0202, -0.0002],\n",
       "         [ 0.0591, -0.0082, -0.0548,  ...,  0.0021, -0.0458, -0.0440]],\n",
       "        device='cuda:0'),\n",
       " 'subject_wise_linear.0.bias': tensor([ 0.0117,  0.0448,  0.0004,  0.0169,  0.0529,  0.0077,  0.0444, -0.0078,\n",
       "          0.0037, -0.0459, -0.0419,  0.0061, -0.0063,  0.0411, -0.0515,  0.0395,\n",
       "          0.0230,  0.0468, -0.0593,  0.0267,  0.0238, -0.0359, -0.0207, -0.0131,\n",
       "         -0.0269, -0.0426,  0.0084, -0.0630,  0.0275, -0.0188,  0.0407, -0.0353,\n",
       "          0.0590,  0.0128,  0.0574, -0.0382,  0.0304, -0.0070,  0.0326, -0.0195,\n",
       "         -0.0375,  0.0605, -0.0580, -0.0380,  0.0462,  0.0061, -0.0202, -0.0368,\n",
       "          0.0629,  0.0254, -0.0157,  0.0296,  0.0452,  0.0058,  0.0067,  0.0356,\n",
       "         -0.0075,  0.0434, -0.0154, -0.0492,  0.0025,  0.0120,  0.0324, -0.0245,\n",
       "          0.0082, -0.0059, -0.0311, -0.0332, -0.0238, -0.0333,  0.0357, -0.0336,\n",
       "         -0.0423,  0.0483,  0.0573, -0.0209, -0.0037,  0.0036,  0.0142,  0.0112,\n",
       "         -0.0046,  0.0533, -0.0180, -0.0242, -0.0513, -0.0225, -0.0050, -0.0163,\n",
       "          0.0532,  0.0127,  0.0283, -0.0185, -0.0515,  0.0154,  0.0349, -0.0250,\n",
       "          0.0311,  0.0282,  0.0487,  0.0469,  0.0072, -0.0459, -0.0522,  0.0339,\n",
       "         -0.0372,  0.0455, -0.0438, -0.0504,  0.0577, -0.0585,  0.0507,  0.0507,\n",
       "         -0.0300,  0.0360,  0.0073, -0.0002, -0.0124,  0.0017,  0.0406, -0.0002,\n",
       "          0.0057,  0.0600, -0.0268, -0.0369,  0.0563, -0.0201, -0.0584,  0.0434,\n",
       "          0.0007,  0.0537, -0.0199, -0.0557,  0.0017,  0.0601,  0.0518,  0.0222,\n",
       "          0.0046, -0.0221, -0.0286,  0.0074, -0.0084,  0.0080, -0.0594, -0.0342,\n",
       "          0.0583,  0.0420, -0.0148,  0.0320, -0.0332,  0.0159,  0.0102,  0.0316,\n",
       "         -0.0115,  0.0379,  0.0198, -0.0004,  0.0009, -0.0061, -0.0465, -0.0625,\n",
       "         -0.0258, -0.0527,  0.0016, -0.0597,  0.0483, -0.0252, -0.0259, -0.0567,\n",
       "         -0.0573,  0.0048, -0.0494,  0.0178, -0.0265,  0.0623, -0.0153, -0.0629,\n",
       "          0.0540, -0.0181, -0.0310, -0.0202, -0.0137,  0.0465,  0.0285,  0.0243,\n",
       "         -0.0571, -0.0338,  0.0285, -0.0514, -0.0554, -0.0009, -0.0136,  0.0623,\n",
       "          0.0091,  0.0274, -0.0134, -0.0371, -0.0564, -0.0142, -0.0550,  0.0534,\n",
       "         -0.0604, -0.0183,  0.0477,  0.0432, -0.0008,  0.0189, -0.0331, -0.0292,\n",
       "          0.0148, -0.0043, -0.0569,  0.0421,  0.0116, -0.0377,  0.0283, -0.0238,\n",
       "         -0.0614,  0.0002,  0.0546, -0.0588, -0.0180, -0.0574, -0.0585,  0.0613,\n",
       "          0.0437,  0.0196, -0.0209,  0.0395, -0.0133, -0.0435, -0.0239,  0.0201,\n",
       "         -0.0278,  0.0388,  0.0050,  0.0210,  0.0518,  0.0155, -0.0055, -0.0589,\n",
       "          0.0562, -0.0176, -0.0162,  0.0158,  0.0240,  0.0426, -0.0235, -0.0592,\n",
       "          0.0215,  0.0028], device='cuda:0'),\n",
       " 'subject_wise_linear.1.weight': tensor([[ 0.0321, -0.0356,  0.0332,  ...,  0.0105,  0.0610, -0.0163],\n",
       "         [ 0.0298, -0.0128, -0.0497,  ..., -0.0586,  0.0194, -0.0515],\n",
       "         [ 0.0006,  0.0325,  0.0309,  ...,  0.0378,  0.0288,  0.0581],\n",
       "         ...,\n",
       "         [-0.0108, -0.0600,  0.0528,  ...,  0.0246,  0.0556,  0.0017],\n",
       "         [-0.0076, -0.0377, -0.0362,  ..., -0.0077, -0.0045,  0.0297],\n",
       "         [ 0.0192, -0.0190, -0.0019,  ..., -0.0136,  0.0307,  0.0503]],\n",
       "        device='cuda:0'),\n",
       " 'subject_wise_linear.1.bias': tensor([-0.0350, -0.0120,  0.0628,  0.0196,  0.0471, -0.0431,  0.0325, -0.0353,\n",
       "         -0.0329,  0.0581,  0.0149,  0.0467,  0.0114, -0.0573,  0.0515,  0.0520,\n",
       "         -0.0248, -0.0235,  0.0240, -0.0157,  0.0508,  0.0541, -0.0054, -0.0171,\n",
       "         -0.0465,  0.0420, -0.0043, -0.0198, -0.0195,  0.0341,  0.0188, -0.0550,\n",
       "         -0.0482,  0.0114, -0.0347, -0.0331, -0.0531, -0.0616,  0.0482,  0.0589,\n",
       "         -0.0584, -0.0224, -0.0002, -0.0600, -0.0395,  0.0419, -0.0314, -0.0631,\n",
       "          0.0318, -0.0410,  0.0097,  0.0208, -0.0346, -0.0142, -0.0590, -0.0174,\n",
       "         -0.0600, -0.0036, -0.0014, -0.0609, -0.0479,  0.0266, -0.0017,  0.0283,\n",
       "          0.0222,  0.0024, -0.0298,  0.0408, -0.0627, -0.0054,  0.0200,  0.0309,\n",
       "          0.0312, -0.0503, -0.0308, -0.0093, -0.0105,  0.0248,  0.0154,  0.0360,\n",
       "          0.0035, -0.0296, -0.0238, -0.0131, -0.0281, -0.0461, -0.0042, -0.0444,\n",
       "         -0.0470, -0.0318,  0.0131, -0.0222,  0.0515,  0.0577, -0.0386,  0.0335,\n",
       "         -0.0441,  0.0384, -0.0177,  0.0232,  0.0456,  0.0480, -0.0070, -0.0061,\n",
       "          0.0590,  0.0219,  0.0571,  0.0513, -0.0464,  0.0515,  0.0445, -0.0538,\n",
       "         -0.0452, -0.0109,  0.0001, -0.0083, -0.0333,  0.0131,  0.0186, -0.0087,\n",
       "          0.0448,  0.0493,  0.0243,  0.0435, -0.0371,  0.0305,  0.0016,  0.0587,\n",
       "          0.0069, -0.0149, -0.0230, -0.0405, -0.0208,  0.0148, -0.0202,  0.0070,\n",
       "          0.0389,  0.0413,  0.0367, -0.0055, -0.0527,  0.0192, -0.0437,  0.0546,\n",
       "         -0.0437,  0.0007,  0.0057, -0.0403, -0.0091,  0.0456,  0.0271,  0.0585,\n",
       "         -0.0096,  0.0379, -0.0041, -0.0610,  0.0556, -0.0593,  0.0230,  0.0198,\n",
       "         -0.0564, -0.0392, -0.0611, -0.0491,  0.0134, -0.0297, -0.0129,  0.0470,\n",
       "         -0.0074,  0.0627, -0.0357, -0.0396,  0.0306, -0.0628, -0.0116,  0.0597,\n",
       "         -0.0017, -0.0123, -0.0233, -0.0278,  0.0423, -0.0613, -0.0475,  0.0186,\n",
       "          0.0423,  0.0353,  0.0276, -0.0329, -0.0409, -0.0186,  0.0579, -0.0138,\n",
       "          0.0031, -0.0194,  0.0209, -0.0222,  0.0450,  0.0155, -0.0245, -0.0110,\n",
       "          0.0109,  0.0461,  0.0490, -0.0599, -0.0577,  0.0497, -0.0425, -0.0249,\n",
       "          0.0557, -0.0242, -0.0264, -0.0015,  0.0242,  0.0124, -0.0523, -0.0513,\n",
       "          0.0547,  0.0600, -0.0142, -0.0137, -0.0305,  0.0426,  0.0078,  0.0187,\n",
       "          0.0511,  0.0060, -0.0621, -0.0046, -0.0512, -0.0162, -0.0142,  0.0426,\n",
       "         -0.0202,  0.0098, -0.0127,  0.0283,  0.0239, -0.0494,  0.0474,  0.0616,\n",
       "          0.0258, -0.0068, -0.0292,  0.0041, -0.0162, -0.0274,  0.0416,  0.0593,\n",
       "         -0.0521, -0.0606], device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.0.weight': tensor([[[[-9.5892e-02,  2.7543e-02,  1.2125e-01, -1.4718e-01, -2.6272e-02,\n",
       "            -9.9692e-02,  1.2839e-01, -1.0852e-01, -1.2400e-01,  3.0888e-02,\n",
       "             1.2047e-01,  9.5456e-02, -2.8202e-02,  2.6848e-02,  4.8562e-02,\n",
       "            -3.0498e-02,  5.5500e-02, -2.7333e-02, -1.6970e-01, -9.8343e-04,\n",
       "             9.9481e-02, -9.4357e-02,  1.2355e-01, -3.1618e-02,  9.0111e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.5104e-01, -7.6656e-04,  7.9391e-02, -5.1253e-03,  1.0866e-01,\n",
       "             1.9835e-01,  1.4095e-01, -2.0178e-01, -6.3853e-02,  4.0270e-02,\n",
       "             7.7469e-02, -1.7073e-01,  6.8474e-02, -6.0509e-02,  8.6725e-02,\n",
       "            -9.6233e-02, -2.2964e-02,  1.5063e-01, -1.4266e-01,  1.3724e-01,\n",
       "            -1.0900e-01,  2.8345e-02, -1.6152e-01, -3.7884e-02, -1.1900e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.0534e-02,  2.9950e-02,  1.3320e-01, -4.5285e-02, -1.6877e-01,\n",
       "             1.3510e-01,  9.9265e-02,  1.5513e-01,  1.6840e-01, -1.3517e-01,\n",
       "             1.1096e-01, -7.2387e-02,  1.6738e-01,  1.8378e-01,  5.5744e-03,\n",
       "             3.6739e-02,  6.3382e-02, -8.5875e-02,  1.1119e-01,  8.1932e-02,\n",
       "            -2.3630e-02, -1.9881e-01,  1.4224e-01, -1.0410e-01, -1.2573e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.8888e-02,  6.6175e-02,  8.8262e-02, -6.3101e-02, -2.6395e-03,\n",
       "             1.7285e-01, -7.2920e-02,  1.9188e-01, -4.8377e-02, -1.8616e-01,\n",
       "            -1.4945e-01, -1.6044e-01,  1.2780e-01, -6.6762e-02,  1.1495e-01,\n",
       "            -1.6526e-02, -1.3401e-01,  1.0673e-01,  1.2481e-01, -6.0008e-02,\n",
       "             1.5437e-01,  1.5906e-01, -9.3764e-02,  2.7870e-02, -9.3184e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5505e-01, -1.2223e-01,  6.7605e-02,  1.0686e-01, -7.0818e-03,\n",
       "             5.2678e-02, -8.8776e-02,  1.2266e-01, -1.6038e-01, -1.2121e-01,\n",
       "             8.2288e-02, -1.0133e-01, -6.0867e-02, -1.4497e-01, -1.0528e-01,\n",
       "            -1.3716e-01,  9.3479e-02,  6.5714e-02,  1.4969e-01,  3.2631e-02,\n",
       "            -2.6450e-02,  1.7944e-01, -5.1376e-02,  1.6087e-02, -6.8469e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.7105e-02,  9.6019e-02,  2.1281e-01,  5.6128e-02, -1.4126e-01,\n",
       "             1.2811e-01, -1.1693e-01,  7.5529e-02,  8.5194e-02, -1.6636e-02,\n",
       "            -8.8052e-02, -1.1048e-01, -1.2617e-01, -1.5134e-01,  1.3699e-01,\n",
       "            -2.7990e-02, -1.2108e-01,  1.0627e-01, -1.1948e-01, -9.7587e-02,\n",
       "            -6.5757e-02,  1.3003e-01,  1.6743e-02,  2.2084e-02,  2.0263e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.3318e-01,  1.1472e-01,  7.2389e-02,  4.4851e-02,  9.1440e-02,\n",
       "             1.3005e-01,  1.6201e-01,  2.3908e-02,  3.2592e-02,  1.7286e-01,\n",
       "             2.5460e-02,  1.2199e-01,  1.4577e-01, -8.7216e-02, -1.0398e-02,\n",
       "             1.5743e-01, -1.3025e-01, -2.0918e-01, -8.4928e-03, -9.6463e-04,\n",
       "             8.9158e-02, -5.3301e-03, -1.2452e-01, -1.5540e-02, -5.2554e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.1111e-02,  1.3272e-01,  6.6358e-03, -2.4203e-02, -1.8291e-01,\n",
       "             1.3705e-01,  8.5437e-02, -1.4018e-01, -4.9247e-05,  5.0602e-02,\n",
       "            -1.8915e-01,  1.9510e-01,  1.1295e-01,  1.6437e-01, -1.5511e-01,\n",
       "             1.2261e-02,  1.3379e-02, -3.4107e-02, -1.0814e-01, -1.4771e-01,\n",
       "            -9.8258e-02,  8.8828e-02,  1.1794e-01, -9.8345e-02,  1.3076e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 4.2493e-03,  1.7957e-01,  4.1977e-02, -1.2372e-01, -1.9632e-01,\n",
       "             3.5720e-02,  1.0413e-01, -6.5914e-02,  4.1894e-02,  1.3136e-01,\n",
       "             1.3543e-01, -2.0251e-01, -5.3628e-02,  1.4963e-01,  6.5476e-02,\n",
       "             4.9260e-02, -1.0943e-01, -2.9543e-02,  5.2843e-02,  3.8085e-02,\n",
       "             1.5673e-01,  1.4990e-01,  1.8516e-01,  1.3869e-01, -1.5852e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.2897e-02, -8.6027e-02, -3.2563e-02,  2.1925e-01,  5.4456e-02,\n",
       "             4.4422e-02, -1.2788e-01, -1.6339e-01, -8.5403e-02, -4.7979e-02,\n",
       "            -7.1123e-02, -1.3156e-01, -1.6404e-01, -1.2498e-01,  9.4555e-02,\n",
       "             1.7509e-01,  9.0511e-02,  9.7761e-02,  1.3664e-01,  3.3179e-03,\n",
       "            -6.2065e-02, -1.8915e-01,  1.6739e-01,  9.0086e-02,  4.2168e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.3649e-02,  1.2158e-01, -1.8349e-01, -5.5751e-02,  6.4179e-02,\n",
       "             1.3394e-01,  1.3419e-01,  1.9985e-01,  1.1483e-01,  5.1361e-02,\n",
       "            -1.3342e-01, -1.9432e-01, -1.6367e-01,  4.3455e-02,  1.5330e-02,\n",
       "            -3.3625e-02, -1.3902e-01,  6.6650e-02, -1.7982e-01,  1.4215e-01,\n",
       "             3.5745e-03,  1.3093e-01, -1.2946e-01,  7.1449e-02,  1.4267e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 3.1598e-02,  8.8697e-02,  3.6528e-02,  4.6243e-02,  7.1558e-02,\n",
       "            -1.0748e-01,  6.6539e-03, -9.5116e-02, -1.1314e-01, -8.3542e-02,\n",
       "            -1.4045e-01, -9.0676e-02,  1.0755e-01,  1.8607e-01, -5.6978e-02,\n",
       "             4.7865e-02,  1.3556e-01,  2.0082e-01, -2.9227e-03, -1.2238e-01,\n",
       "            -8.4767e-02, -1.2380e-01,  4.8311e-02, -1.0666e-01,  9.0666e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 8.4351e-02, -1.7395e-01,  1.6508e-01,  5.9626e-02,  1.2794e-01,\n",
       "            -1.7594e-01,  1.4662e-01, -5.8145e-03,  1.7134e-01, -1.2768e-01,\n",
       "            -1.4183e-01,  1.1304e-01, -1.8772e-01,  2.7074e-02,  1.9778e-01,\n",
       "            -1.3355e-01, -1.5831e-01, -9.6934e-02, -2.7511e-02, -1.1803e-01,\n",
       "            -7.9972e-02,  4.0755e-03,  1.0904e-01,  1.4502e-01,  1.5450e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2234e-01, -1.7615e-01, -8.0468e-02,  9.1382e-02,  1.5715e-01,\n",
       "             1.9091e-01,  1.4751e-01, -2.1419e-02, -1.8722e-01, -3.5145e-02,\n",
       "            -1.8165e-01, -5.7538e-02, -8.9133e-02, -8.2213e-02,  3.8579e-02,\n",
       "             1.3325e-01, -1.1322e-01, -2.3587e-02,  1.1238e-01,  1.9074e-01,\n",
       "             7.2927e-02, -1.7492e-01, -7.4148e-02,  7.8538e-02,  1.5142e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.0192e-02,  2.5462e-02,  1.1329e-01,  1.5242e-01, -5.3824e-02,\n",
       "            -1.7800e-01,  6.0513e-02, -1.9780e-01,  9.3233e-02, -1.8320e-01,\n",
       "             1.1456e-01, -7.6250e-02, -2.0002e-01,  1.2232e-01,  1.9007e-01,\n",
       "             3.4268e-02,  5.3059e-02,  6.7072e-02, -1.8481e-01,  8.5384e-02,\n",
       "             9.5458e-02,  7.8427e-02,  5.0748e-02, -1.2688e-01, -9.8160e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1695e-01, -1.4130e-01, -1.2119e-02,  1.9389e-01,  2.4563e-02,\n",
       "             1.3987e-01, -1.1511e-01,  3.8697e-02,  1.6849e-01,  1.2076e-01,\n",
       "             6.4472e-02,  8.0095e-03,  5.1621e-02, -8.0526e-02, -8.2756e-02,\n",
       "            -1.4108e-01, -8.2388e-03,  9.3399e-02,  1.8866e-02, -1.8240e-01,\n",
       "            -1.7640e-01, -2.5849e-02, -1.5689e-01,  3.4952e-03,  8.6470e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.7660e-01,  6.8624e-02,  7.0136e-02, -4.8656e-03, -3.6550e-02,\n",
       "            -3.8519e-02,  1.7762e-01,  1.4415e-01, -2.0894e-02, -8.0573e-03,\n",
       "            -4.7963e-02, -1.5150e-01,  7.0246e-02, -8.9926e-02,  3.4262e-02,\n",
       "            -1.3712e-01, -4.9967e-02,  1.7243e-01, -9.9519e-02,  9.7563e-02,\n",
       "             1.9734e-02,  2.0553e-02, -1.5169e-01,  1.0948e-01, -5.4348e-02]]],\n",
       " \n",
       " \n",
       "         [[[-6.1564e-02,  1.1552e-01,  1.6910e-01,  1.5130e-01, -1.7706e-01,\n",
       "            -1.7603e-01,  5.9087e-02, -4.2751e-02, -2.0819e-01,  1.0313e-01,\n",
       "            -7.1803e-02,  1.8646e-01,  1.5680e-01,  9.2472e-02, -2.4708e-03,\n",
       "             1.5179e-01,  1.8987e-01, -1.6487e-02,  1.9092e-01,  1.6323e-01,\n",
       "             7.0338e-02, -1.1626e-02,  1.4901e-02,  1.3792e-01, -1.7950e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.7492e-02, -6.7853e-02, -4.7263e-02,  1.3606e-01,  1.0011e-01,\n",
       "             6.9891e-02,  1.6983e-01,  1.5294e-01,  6.9800e-02, -1.1944e-01,\n",
       "             1.3257e-01, -4.6736e-02, -1.4550e-01,  2.9188e-02, -1.5837e-01,\n",
       "            -6.8644e-02,  1.3677e-01, -6.9348e-02, -8.0350e-03,  1.5792e-01,\n",
       "             1.9738e-01, -1.5674e-01, -1.2884e-02, -1.6923e-01,  5.5059e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3499e-01,  5.8813e-03,  1.3042e-01, -8.6879e-02, -8.4530e-02,\n",
       "            -1.6185e-01, -2.7816e-03,  3.0058e-03,  9.1952e-02,  1.8747e-01,\n",
       "            -1.1166e-01, -1.5431e-01,  9.1694e-02,  1.5393e-01,  1.5291e-01,\n",
       "            -1.1896e-01, -1.2015e-01,  1.4129e-01, -1.0044e-01,  9.5274e-02,\n",
       "             1.4829e-01, -4.7881e-02,  1.3488e-01, -2.2649e-01,  1.1239e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.9783e-01, -1.8223e-01,  1.7939e-02,  1.0130e-01,  8.1546e-04,\n",
       "            -1.2187e-01, -1.0317e-01, -1.3422e-01, -1.4433e-02,  1.2414e-01,\n",
       "            -1.3458e-01, -2.5813e-02,  1.9542e-01, -3.3892e-02,  6.5267e-02,\n",
       "            -1.1737e-01, -1.1077e-02, -1.5978e-01,  4.6762e-02,  7.6837e-02,\n",
       "            -8.0780e-02,  1.6645e-02, -3.1089e-04, -1.0536e-01,  1.3477e-01]]],\n",
       " \n",
       " \n",
       "         [[[-7.7200e-02,  1.2631e-01,  6.8364e-02, -1.1517e-01,  4.9582e-02,\n",
       "             1.1400e-01, -1.1423e-01, -1.5006e-01,  1.2956e-01, -1.0663e-01,\n",
       "             3.6352e-02,  2.2114e-02,  1.1891e-01,  4.3210e-02, -5.9651e-03,\n",
       "             1.3329e-01,  1.7191e-01, -1.8603e-01, -9.8932e-02, -1.6167e-01,\n",
       "            -3.6313e-02, -4.3284e-02,  1.9378e-02, -3.1593e-02,  7.0430e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.7355e-01, -1.5829e-01, -1.6026e-01,  1.1110e-01,  1.3003e-01,\n",
       "            -1.7214e-01, -4.4351e-02,  1.1965e-01,  1.9925e-01,  8.1358e-02,\n",
       "             1.2591e-01, -8.5278e-03, -7.4061e-02, -1.2801e-01,  1.0635e-02,\n",
       "             1.5914e-02,  9.4734e-03, -1.5847e-01,  1.7301e-01,  9.3965e-02,\n",
       "            -1.0918e-01,  1.5992e-01,  7.8426e-02,  1.1745e-01, -2.2622e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.0744e-01,  1.5696e-02, -5.2276e-02,  1.0795e-01, -1.4398e-01,\n",
       "             1.1026e-01,  7.8261e-02,  8.6156e-02,  8.2274e-02,  2.3313e-03,\n",
       "            -6.4816e-02,  7.3903e-02,  1.4390e-01, -1.8455e-02, -6.4957e-02,\n",
       "            -4.0957e-02,  3.8055e-02,  1.5616e-01,  4.1847e-02, -1.3104e-01,\n",
       "             5.9801e-02, -1.1546e-01,  1.2967e-01, -1.1094e-01, -1.2180e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 2.9376e-02, -3.1156e-02, -1.8101e-01,  2.5937e-02, -8.4939e-02,\n",
       "            -1.1877e-01,  1.4853e-01,  1.8678e-01, -7.1750e-02,  1.7996e-01,\n",
       "             1.5878e-01, -1.3938e-02, -2.1261e-01,  1.6548e-01,  7.3291e-02,\n",
       "             5.9998e-03, -2.0113e-01,  4.3496e-02,  2.9834e-02, -1.5115e-01,\n",
       "             1.1718e-01, -4.8059e-02, -6.1588e-02, -1.0159e-02,  7.8103e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2126e-01,  2.6449e-02, -1.7194e-01, -1.3630e-01,  1.1706e-01,\n",
       "             1.9540e-01,  1.9867e-01,  2.1374e-02, -1.9336e-01, -5.6847e-02,\n",
       "            -4.7936e-02, -1.7637e-01,  1.4530e-01, -1.3757e-02, -9.3455e-02,\n",
       "            -4.0017e-02, -1.0315e-01, -1.4694e-01,  1.0469e-01,  1.4897e-01,\n",
       "             1.4867e-02,  5.8232e-02,  1.4816e-01,  1.4174e-01, -2.1187e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 5.8184e-02, -4.3889e-02, -5.8502e-02, -1.4879e-02, -1.1419e-01,\n",
       "             1.3885e-01, -2.3089e-02,  1.2475e-01,  7.6605e-02,  1.1027e-01,\n",
       "            -1.4251e-01,  2.8158e-02,  1.0059e-01, -1.5438e-01, -2.4578e-03,\n",
       "            -1.5826e-01,  5.9344e-02, -1.0653e-01, -2.8812e-02,  5.7018e-02,\n",
       "             1.3597e-01, -1.2422e-01,  1.2459e-01, -1.8732e-01,  1.6310e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.6151e-01, -1.3493e-01, -1.0576e-01, -5.2387e-02, -1.8560e-01,\n",
       "            -2.3524e-03, -1.8350e-01,  1.8422e-01, -5.7567e-02,  1.3702e-01,\n",
       "            -1.7132e-01,  3.7597e-02,  7.4492e-02, -1.8044e-01, -1.8443e-01,\n",
       "             9.3770e-02, -7.1352e-02, -8.6462e-02,  1.2204e-01, -8.3345e-02,\n",
       "            -5.1076e-03,  5.3757e-02,  5.8724e-02,  1.0557e-01, -2.3838e-02]]],\n",
       " \n",
       " \n",
       "         [[[-9.1593e-02, -1.3859e-01,  7.7405e-02,  1.9678e-02, -4.0640e-03,\n",
       "             1.8287e-01,  1.0001e-01, -1.8819e-01,  2.3328e-02, -2.1305e-02,\n",
       "             4.8252e-02, -1.8132e-01,  1.0211e-02,  1.7884e-01, -7.8668e-02,\n",
       "             1.9966e-01,  4.2847e-02, -1.3525e-01,  4.2036e-03, -2.8037e-02,\n",
       "            -4.8861e-02, -8.5375e-02,  1.5711e-02, -5.0748e-02, -1.2104e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1411e-01, -1.5738e-01, -1.7296e-01,  8.9631e-02, -1.5525e-01,\n",
       "            -5.8451e-02,  6.6728e-02,  8.3063e-02,  1.3507e-01,  1.6896e-01,\n",
       "            -4.7921e-02,  1.5991e-01,  5.0068e-02, -3.6818e-02, -2.9684e-02,\n",
       "            -7.2825e-02, -2.0503e-01, -1.1587e-01, -7.8385e-02,  1.6520e-01,\n",
       "             1.1211e-01, -7.7243e-02,  1.6936e-01,  5.8801e-02, -1.7735e-01]]],\n",
       " \n",
       " \n",
       "         [[[-7.0907e-02,  3.6779e-02,  1.4817e-02, -1.6439e-01, -9.5979e-02,\n",
       "             1.2631e-02, -1.0037e-01, -1.6613e-01, -2.0991e-02,  1.3402e-01,\n",
       "            -4.8186e-02, -9.2750e-02,  1.4489e-01,  1.9852e-03,  1.8050e-01,\n",
       "            -8.4565e-02, -6.2043e-02, -8.4845e-02,  1.2901e-01,  1.5723e-01,\n",
       "            -1.8514e-01, -2.3930e-02,  1.4074e-01,  8.7612e-02,  1.7257e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.0042e-01,  1.3753e-01,  1.2772e-01, -2.1618e-02,  5.8436e-02,\n",
       "            -1.5472e-01,  1.0256e-01,  1.5687e-02,  3.9349e-02,  1.1562e-01,\n",
       "             3.2317e-02, -7.3228e-02,  9.4772e-02, -7.6743e-02, -1.2017e-01,\n",
       "            -1.8167e-01, -4.2715e-02,  7.6691e-02, -1.7051e-01, -9.5569e-02,\n",
       "            -1.6059e-01,  1.6117e-01,  1.0645e-01,  6.1797e-02,  3.7296e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1149e-01,  6.9805e-02,  1.3643e-01, -1.5899e-01, -1.4828e-01,\n",
       "            -4.8315e-03, -1.4716e-01,  3.5954e-02, -1.7807e-01, -6.4607e-03,\n",
       "             1.8094e-01,  9.7983e-02, -9.2759e-02,  5.5865e-02,  2.0647e-02,\n",
       "             1.8053e-01,  1.5094e-01, -1.4635e-01, -1.5629e-01, -1.0286e-01,\n",
       "            -4.6548e-02,  1.9613e-01, -1.3775e-01, -5.3696e-02,  1.1009e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1429e-01, -1.8921e-01, -4.4866e-02,  8.0197e-02, -5.4585e-02,\n",
       "             1.4731e-01,  7.1514e-02,  4.6515e-02, -1.5231e-01,  1.9376e-01,\n",
       "             3.7203e-02, -9.4470e-02, -1.9050e-01, -1.4857e-01, -1.2870e-01,\n",
       "             1.1415e-01,  8.6047e-02, -1.3535e-01,  1.8658e-01,  7.1357e-02,\n",
       "             2.0625e-01,  9.0069e-02, -1.8334e-01, -1.2364e-01, -2.2658e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3475e-01, -1.5594e-02,  1.6905e-01, -3.2230e-02,  3.7394e-02,\n",
       "            -5.4058e-02, -1.0170e-01, -1.3816e-01,  1.4148e-01,  4.6846e-02,\n",
       "            -6.4689e-02, -1.5867e-01, -2.3093e-02, -1.8421e-01, -6.4325e-02,\n",
       "            -5.9037e-03, -1.7445e-01,  4.1187e-02, -1.9639e-01, -9.6844e-02,\n",
       "            -3.7654e-02, -1.0731e-01, -7.8902e-03,  9.6052e-02, -1.8259e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.3674e-01,  1.9785e-02,  8.5333e-02, -1.8947e-01,  4.5273e-02,\n",
       "             9.2001e-02, -5.8476e-02, -7.7495e-02,  1.6787e-01,  1.2762e-01,\n",
       "            -1.7044e-01,  6.5230e-02,  1.5914e-01,  3.0840e-02,  1.6267e-01,\n",
       "             1.3047e-01,  8.6295e-02, -1.6759e-01, -1.9943e-02,  3.4047e-02,\n",
       "            -9.2979e-03,  7.6317e-02,  1.1398e-01,  2.8938e-02, -1.7153e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.6624e-01, -1.2814e-01,  1.4616e-01, -1.3041e-03, -1.5902e-01,\n",
       "            -6.6271e-02, -1.2874e-01,  1.6002e-01,  1.2094e-01,  8.1615e-02,\n",
       "            -1.2699e-01, -8.6070e-03, -1.2695e-01, -1.4766e-01, -1.3020e-01,\n",
       "             1.6566e-01,  7.6561e-02,  6.1284e-02,  9.5736e-02,  1.2247e-01,\n",
       "             1.9648e-02, -4.0746e-02, -7.6142e-02, -1.2859e-01,  7.3572e-02]]],\n",
       " \n",
       " \n",
       "         [[[-7.5242e-02,  9.8512e-02,  7.3517e-02,  1.3228e-01,  1.3301e-01,\n",
       "             1.3613e-01,  1.6832e-01,  7.8554e-02, -6.9357e-02, -1.0200e-01,\n",
       "            -1.1853e-02, -1.5316e-01,  1.0831e-01, -1.1956e-01, -1.3358e-01,\n",
       "            -9.4634e-02, -9.0494e-02, -9.5662e-02, -2.2366e-02,  4.0547e-02,\n",
       "            -7.2064e-02, -2.3090e-02, -2.4250e-02,  5.2135e-02,  3.6179e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.8946e-01,  1.3481e-01, -1.5476e-01,  1.6331e-01,  1.7823e-01,\n",
       "            -1.1135e-01, -1.1432e-01, -1.7271e-01, -1.0585e-01,  1.8863e-01,\n",
       "            -1.1614e-02, -1.9411e-01, -1.0243e-01, -7.8089e-02, -3.6804e-02,\n",
       "            -1.5092e-02,  7.8262e-02, -5.3195e-02,  1.4222e-01,  8.8999e-02,\n",
       "             7.8123e-03,  8.4789e-03,  4.8985e-02, -1.4424e-01,  1.0681e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3801e-01, -1.2476e-01,  1.9230e-01,  9.7435e-02, -2.0762e-01,\n",
       "             6.9069e-02, -1.7584e-01, -1.8907e-02,  9.4917e-02,  3.9865e-02,\n",
       "            -1.1549e-01, -1.9597e-01, -1.8330e-01,  1.6458e-01, -2.1560e-02,\n",
       "            -2.2137e-01,  1.3825e-01,  1.6103e-01,  1.1733e-01,  1.7367e-01,\n",
       "             3.4953e-02,  1.3783e-01, -1.3801e-01,  8.1467e-02,  7.7329e-02]]]],\n",
       "        device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.0.bias': tensor([-0.1997,  0.1531, -0.1967, -0.1800, -0.1221, -0.1604, -0.0976,  0.2088,\n",
       "         -0.1305, -0.1242, -0.1567,  0.1529, -0.0377, -0.1489, -0.0349,  0.0010,\n",
       "          0.0299,  0.0484, -0.0662,  0.1388, -0.0861,  0.0150, -0.0958,  0.1700,\n",
       "         -0.0850,  0.2002,  0.1456,  0.1357,  0.0239, -0.1770,  0.1289,  0.1490,\n",
       "          0.1741,  0.0929, -0.0587, -0.1385,  0.1281, -0.1225, -0.1746, -0.1353],\n",
       "        device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.2.weight': tensor([1.0132, 0.9735, 0.9460, 0.9276, 0.9775, 1.0578, 0.9446, 0.9713, 0.9254,\n",
       "         1.0356, 0.9535, 1.0526, 1.1186, 1.1685, 1.1563, 0.9579, 0.9520, 0.9280,\n",
       "         0.9386, 0.9506, 0.9468, 0.9613, 0.9843, 0.9847, 0.9769, 1.0644, 1.1590,\n",
       "         0.9610, 0.9604, 1.1352, 0.9858, 1.0274, 1.0323, 1.1683, 0.9567, 0.9344,\n",
       "         1.1135, 1.0083, 1.1118, 0.9392], device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.2.bias': tensor([-0.0806, -0.1179, -0.1338, -0.1224, -0.0601, -0.0061, -0.1205, -0.0730,\n",
       "         -0.1429, -0.0864, -0.0768,  0.0097,  0.0952,  0.1257,  0.1201, -0.1172,\n",
       "         -0.1201, -0.1301, -0.1442, -0.1404, -0.1528, -0.1274, -0.1021, -0.0648,\n",
       "         -0.0555,  0.0537,  0.1125, -0.1534, -0.1446,  0.0729, -0.1185, -0.0704,\n",
       "         -0.0088,  0.1593, -0.1796, -0.1351,  0.1000, -0.0879,  0.0943, -0.1301],\n",
       "        device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.2.running_mean': tensor([-0.2007,  0.1512, -0.1813, -0.1718, -0.1235, -0.1619, -0.0847,  0.2116,\n",
       "         -0.1114, -0.1268, -0.1531,  0.1517, -0.0366, -0.1484, -0.0344, -0.0047,\n",
       "          0.0277,  0.0708, -0.0565,  0.1398, -0.0926,  0.0138, -0.0951,  0.1721,\n",
       "         -0.0833,  0.2014,  0.1460,  0.1159,  0.0210, -0.1765,  0.1273,  0.1479,\n",
       "          0.1735,  0.0931, -0.0801, -0.1282,  0.1276, -0.1227, -0.1738, -0.1291],\n",
       "        device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.2.running_var': tensor([0.0013, 0.0025, 0.0297, 0.0062, 0.0022, 0.0021, 0.0244, 0.0011, 0.0423,\n",
       "         0.0056, 0.0024, 0.0011, 0.0018, 0.0012, 0.0007, 0.0102, 0.0007, 0.0617,\n",
       "         0.0126, 0.0034, 0.0042, 0.0018, 0.0035, 0.0021, 0.0012, 0.0011, 0.0004,\n",
       "         0.0448, 0.0013, 0.0011, 0.0099, 0.0025, 0.0008, 0.0008, 0.0634, 0.0147,\n",
       "         0.0006, 0.0095, 0.0020, 0.0085], device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.2.num_batches_tracked': tensor(2730, device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.4.weight': tensor([[[[-1.0289e-02],\n",
       "           [ 2.1453e-02],\n",
       "           [-2.6389e-02],\n",
       "           ...,\n",
       "           [-1.9665e-02],\n",
       "           [-1.1008e-02],\n",
       "           [-2.0238e-02]],\n",
       " \n",
       "          [[ 1.1895e-02],\n",
       "           [ 4.8769e-03],\n",
       "           [ 6.3424e-03],\n",
       "           ...,\n",
       "           [-1.8052e-02],\n",
       "           [-1.2324e-02],\n",
       "           [-1.1524e-02]],\n",
       " \n",
       "          [[ 1.2713e-02],\n",
       "           [-3.8944e-03],\n",
       "           [-1.5521e-02],\n",
       "           ...,\n",
       "           [ 2.9572e-03],\n",
       "           [ 2.5102e-03],\n",
       "           [-8.1739e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5717e-02],\n",
       "           [ 2.9981e-03],\n",
       "           [ 1.3174e-02],\n",
       "           ...,\n",
       "           [-1.9370e-02],\n",
       "           [ 2.0739e-02],\n",
       "           [-9.1810e-03]],\n",
       " \n",
       "          [[ 3.2832e-03],\n",
       "           [ 2.2642e-02],\n",
       "           [-1.0478e-02],\n",
       "           ...,\n",
       "           [ 2.2879e-02],\n",
       "           [ 2.2087e-02],\n",
       "           [ 1.9321e-02]],\n",
       " \n",
       "          [[-5.5132e-03],\n",
       "           [-6.2529e-03],\n",
       "           [ 4.7627e-03],\n",
       "           ...,\n",
       "           [ 8.0127e-03],\n",
       "           [-1.9751e-02],\n",
       "           [-1.4507e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.6497e-02],\n",
       "           [ 7.6355e-03],\n",
       "           [ 7.2539e-03],\n",
       "           ...,\n",
       "           [-1.9707e-02],\n",
       "           [-2.4208e-03],\n",
       "           [ 2.6415e-02]],\n",
       " \n",
       "          [[ 4.7896e-03],\n",
       "           [ 8.2546e-03],\n",
       "           [ 1.8427e-02],\n",
       "           ...,\n",
       "           [ 3.4794e-02],\n",
       "           [-1.2420e-02],\n",
       "           [-2.7504e-02]],\n",
       " \n",
       "          [[ 1.0113e-03],\n",
       "           [-4.5573e-03],\n",
       "           [ 1.7429e-04],\n",
       "           ...,\n",
       "           [ 1.5887e-02],\n",
       "           [-1.9011e-02],\n",
       "           [ 3.3085e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.7288e-03],\n",
       "           [ 2.1986e-02],\n",
       "           [-4.6112e-03],\n",
       "           ...,\n",
       "           [ 2.2185e-02],\n",
       "           [ 5.0218e-03],\n",
       "           [-4.4063e-02]],\n",
       " \n",
       "          [[-4.1474e-03],\n",
       "           [-9.7464e-03],\n",
       "           [-1.1969e-02],\n",
       "           ...,\n",
       "           [ 6.5158e-03],\n",
       "           [ 8.7594e-03],\n",
       "           [ 2.5434e-04]],\n",
       " \n",
       "          [[-1.1061e-02],\n",
       "           [-7.4425e-03],\n",
       "           [-2.5564e-02],\n",
       "           ...,\n",
       "           [-2.5972e-02],\n",
       "           [ 7.0361e-03],\n",
       "           [ 2.1878e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.8720e-03],\n",
       "           [-1.9108e-02],\n",
       "           [ 5.7029e-03],\n",
       "           ...,\n",
       "           [-1.9042e-03],\n",
       "           [-4.3975e-03],\n",
       "           [ 1.1480e-03]],\n",
       " \n",
       "          [[ 1.3296e-02],\n",
       "           [ 9.6840e-03],\n",
       "           [-6.2027e-04],\n",
       "           ...,\n",
       "           [ 9.3466e-03],\n",
       "           [-1.6607e-02],\n",
       "           [-8.4818e-03]],\n",
       " \n",
       "          [[-1.8458e-02],\n",
       "           [ 2.1004e-02],\n",
       "           [ 1.1206e-03],\n",
       "           ...,\n",
       "           [ 4.3447e-03],\n",
       "           [ 2.6849e-02],\n",
       "           [-1.7356e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.6445e-02],\n",
       "           [ 3.2500e-03],\n",
       "           [ 1.0378e-02],\n",
       "           ...,\n",
       "           [-1.2564e-02],\n",
       "           [-1.3630e-02],\n",
       "           [-4.1277e-02]],\n",
       " \n",
       "          [[ 1.3051e-02],\n",
       "           [-1.6876e-02],\n",
       "           [ 1.3016e-02],\n",
       "           ...,\n",
       "           [ 1.9183e-02],\n",
       "           [-2.4360e-02],\n",
       "           [-1.9412e-02]],\n",
       " \n",
       "          [[-2.0861e-02],\n",
       "           [ 1.1562e-02],\n",
       "           [ 1.4472e-02],\n",
       "           ...,\n",
       "           [ 3.9629e-02],\n",
       "           [ 6.0314e-03],\n",
       "           [-1.9246e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 3.6993e-03],\n",
       "           [ 2.9075e-03],\n",
       "           [-1.1150e-02],\n",
       "           ...,\n",
       "           [-2.9644e-02],\n",
       "           [-1.3909e-02],\n",
       "           [ 1.0129e-02]],\n",
       " \n",
       "          [[ 1.0111e-02],\n",
       "           [ 3.2282e-02],\n",
       "           [-2.9388e-02],\n",
       "           ...,\n",
       "           [ 2.1678e-02],\n",
       "           [-2.0870e-02],\n",
       "           [-1.1333e-02]],\n",
       " \n",
       "          [[-2.9409e-03],\n",
       "           [-7.4329e-04],\n",
       "           [ 1.6535e-02],\n",
       "           ...,\n",
       "           [ 8.1829e-03],\n",
       "           [ 3.9984e-03],\n",
       "           [-6.7047e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.4460e-02],\n",
       "           [-7.3774e-03],\n",
       "           [ 3.5021e-03],\n",
       "           ...,\n",
       "           [ 9.7555e-03],\n",
       "           [-2.1162e-02],\n",
       "           [-3.4967e-02]],\n",
       " \n",
       "          [[ 2.1788e-03],\n",
       "           [ 2.4258e-02],\n",
       "           [ 1.4336e-02],\n",
       "           ...,\n",
       "           [-2.3057e-02],\n",
       "           [ 2.1572e-02],\n",
       "           [-1.0647e-02]],\n",
       " \n",
       "          [[ 1.3570e-02],\n",
       "           [-2.1529e-02],\n",
       "           [ 4.4914e-02],\n",
       "           ...,\n",
       "           [-1.3583e-02],\n",
       "           [ 1.4330e-02],\n",
       "           [ 9.4466e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 4.5912e-03],\n",
       "           [-2.0301e-02],\n",
       "           [-8.6490e-03],\n",
       "           ...,\n",
       "           [-7.7141e-03],\n",
       "           [ 2.1407e-02],\n",
       "           [ 1.9845e-02]],\n",
       " \n",
       "          [[-1.7991e-02],\n",
       "           [-7.1373e-03],\n",
       "           [-1.2622e-02],\n",
       "           ...,\n",
       "           [ 3.4376e-02],\n",
       "           [-1.1240e-02],\n",
       "           [ 9.9071e-05]],\n",
       " \n",
       "          [[-9.9463e-03],\n",
       "           [ 1.8296e-02],\n",
       "           [ 5.7080e-03],\n",
       "           ...,\n",
       "           [-2.9674e-02],\n",
       "           [-2.5045e-02],\n",
       "           [-2.2157e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0388e-02],\n",
       "           [ 1.4408e-02],\n",
       "           [ 1.7057e-02],\n",
       "           ...,\n",
       "           [ 4.2915e-02],\n",
       "           [ 4.6954e-03],\n",
       "           [ 1.0159e-02]],\n",
       " \n",
       "          [[-2.8267e-04],\n",
       "           [ 2.5725e-02],\n",
       "           [ 6.4035e-03],\n",
       "           ...,\n",
       "           [-1.5298e-02],\n",
       "           [ 4.7887e-03],\n",
       "           [-6.4137e-03]],\n",
       " \n",
       "          [[ 1.4657e-02],\n",
       "           [ 1.4264e-02],\n",
       "           [-1.3806e-02],\n",
       "           ...,\n",
       "           [-1.5834e-02],\n",
       "           [ 1.2979e-02],\n",
       "           [ 7.2340e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.4741e-02],\n",
       "           [-1.4047e-02],\n",
       "           [ 4.8144e-03],\n",
       "           ...,\n",
       "           [-1.0479e-02],\n",
       "           [-2.0491e-02],\n",
       "           [-9.8800e-03]],\n",
       " \n",
       "          [[-1.3188e-02],\n",
       "           [-2.6331e-02],\n",
       "           [ 1.5871e-02],\n",
       "           ...,\n",
       "           [ 1.0117e-02],\n",
       "           [ 1.4491e-02],\n",
       "           [-1.5865e-03]],\n",
       " \n",
       "          [[-3.2909e-05],\n",
       "           [ 4.5641e-03],\n",
       "           [ 1.8340e-03],\n",
       "           ...,\n",
       "           [ 1.7877e-02],\n",
       "           [ 1.0258e-02],\n",
       "           [-1.1566e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.4726e-02],\n",
       "           [ 8.6255e-03],\n",
       "           [ 3.1546e-03],\n",
       "           ...,\n",
       "           [-3.2454e-02],\n",
       "           [ 3.0396e-03],\n",
       "           [-6.8177e-03]],\n",
       " \n",
       "          [[-8.8564e-03],\n",
       "           [-1.4970e-02],\n",
       "           [ 4.2156e-02],\n",
       "           ...,\n",
       "           [ 4.1371e-02],\n",
       "           [ 3.0111e-02],\n",
       "           [ 8.6406e-03]],\n",
       " \n",
       "          [[ 1.1879e-02],\n",
       "           [ 2.1836e-03],\n",
       "           [ 1.1618e-02],\n",
       "           ...,\n",
       "           [ 2.2845e-02],\n",
       "           [-6.3067e-03],\n",
       "           [ 8.1791e-03]]]], device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.4.bias': tensor([ 0.0002,  0.0193, -0.0149, -0.0069,  0.0051, -0.0079, -0.0052, -0.0118,\n",
       "          0.0115,  0.0196, -0.0065, -0.0036,  0.0039, -0.0012,  0.0003, -0.0088,\n",
       "         -0.0161,  0.0014, -0.0124,  0.0021,  0.0104, -0.0083, -0.0008,  0.0122,\n",
       "         -0.0146,  0.0226, -0.0042, -0.0263, -0.0051,  0.0081,  0.0142,  0.0080,\n",
       "         -0.0015,  0.0037,  0.0006,  0.0076, -0.0197, -0.0006, -0.0184,  0.0185],\n",
       "        device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.5.weight': tensor([1.0014, 1.0034, 0.9996, 0.9950, 1.0370, 0.9472, 1.0130, 0.9761, 0.9972,\n",
       "         0.9809, 1.0029, 1.0303, 1.0245, 1.0025, 1.0009, 0.9792, 1.0004, 1.0000,\n",
       "         0.9791, 0.9829, 1.0123, 0.9911, 1.0352, 0.9642, 0.9860, 0.9939, 0.9798,\n",
       "         1.0269, 1.0072, 0.9786, 0.9981, 0.9863, 1.0112, 0.9942, 0.9905, 1.0110,\n",
       "         1.0080, 1.0389, 0.9127, 0.9860], device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.5.bias': tensor([-0.0506, -0.0728, -0.0452, -0.0513, -0.0672, -0.0953, -0.1035, -0.0931,\n",
       "         -0.0758, -0.0643, -0.0670, -0.1109, -0.0659, -0.0708, -0.0961, -0.0943,\n",
       "         -0.0651, -0.0886, -0.0793, -0.0738, -0.0755, -0.0887, -0.0729, -0.0847,\n",
       "         -0.0738, -0.0727, -0.0904, -0.0448, -0.0899, -0.0660, -0.1069, -0.0988,\n",
       "         -0.0743, -0.0796, -0.0917, -0.0616, -0.0967, -0.0741, -0.1003, -0.0597],\n",
       "        device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.5.running_mean': tensor([ 0.0778, -0.0097,  0.0628, -0.2747,  0.2218, -0.0296,  0.1533, -0.0055,\n",
       "          0.0508,  0.6059,  0.1839,  0.1774,  0.0251, -0.1059, -0.0656, -0.2031,\n",
       "         -0.1988, -0.0916, -0.2480, -0.0266, -0.0346,  0.1560, -0.0878,  0.1377,\n",
       "         -0.1656,  0.0942,  0.2932,  0.1545,  0.3836, -0.1319,  0.2030,  0.1385,\n",
       "          0.4281, -0.2263, -0.3434,  0.3758,  0.1754,  0.2614,  0.1187,  0.0337],\n",
       "        device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.5.running_var': tensor([1.2653, 1.3729, 1.3545, 1.2453, 1.4462, 1.2323, 1.3094, 1.2621, 1.4782,\n",
       "         1.2452, 1.1818, 1.5339, 1.2116, 1.2304, 1.2822, 1.3605, 1.1596, 1.4487,\n",
       "         1.5264, 1.5215, 1.8238, 1.5868, 1.0935, 1.4397, 1.4623, 1.2291, 1.2865,\n",
       "         1.6004, 1.3126, 1.0434, 1.5149, 1.4125, 1.3661, 1.4290, 1.1778, 1.3851,\n",
       "         1.2741, 1.2835, 1.2901, 1.2983], device='cuda:0'),\n",
       " 'enc_eeg.0.tsconv.5.num_batches_tracked': tensor(2730, device='cuda:0'),\n",
       " 'enc_eeg.0.projection.0.weight': tensor([[[[-0.1086]],\n",
       " \n",
       "          [[-0.1535]],\n",
       " \n",
       "          [[ 0.0392]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0238]],\n",
       " \n",
       "          [[ 0.1248]],\n",
       " \n",
       "          [[ 0.0590]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1496]],\n",
       " \n",
       "          [[-0.1347]],\n",
       " \n",
       "          [[-0.1591]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0647]],\n",
       " \n",
       "          [[-0.1451]],\n",
       " \n",
       "          [[ 0.1318]]],\n",
       " \n",
       " \n",
       "         [[[-0.0168]],\n",
       " \n",
       "          [[-0.0103]],\n",
       " \n",
       "          [[ 0.0951]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1199]],\n",
       " \n",
       "          [[-0.0472]],\n",
       " \n",
       "          [[ 0.1041]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.1061]],\n",
       " \n",
       "          [[ 0.0595]],\n",
       " \n",
       "          [[ 0.1448]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1085]],\n",
       " \n",
       "          [[ 0.0297]],\n",
       " \n",
       "          [[-0.1311]]],\n",
       " \n",
       " \n",
       "         [[[-0.1052]],\n",
       " \n",
       "          [[-0.1417]],\n",
       " \n",
       "          [[ 0.0149]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0534]],\n",
       " \n",
       "          [[-0.0966]],\n",
       " \n",
       "          [[-0.1124]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0751]],\n",
       " \n",
       "          [[ 0.1182]],\n",
       " \n",
       "          [[-0.0388]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1231]],\n",
       " \n",
       "          [[-0.1318]],\n",
       " \n",
       "          [[-0.0296]]]], device='cuda:0'),\n",
       " 'enc_eeg.0.projection.0.bias': tensor([-0.1288,  0.1080,  0.1031, -0.1633,  0.0480,  0.1352,  0.1088, -0.2188,\n",
       "         -0.1608,  0.0298,  0.1012,  0.2040,  0.1742,  0.0979, -0.0703,  0.1397,\n",
       "          0.1102,  0.0840,  0.0893,  0.1523, -0.0207,  0.1812, -0.0521,  0.1505,\n",
       "          0.1603,  0.1248,  0.0260, -0.1216,  0.0791, -0.1908,  0.0377, -0.0863,\n",
       "          0.1334, -0.2509, -0.1909,  0.1340, -0.1096, -0.0734, -0.1253,  0.1330],\n",
       "        device='cuda:0'),\n",
       " 'proj_eeg.0.weight': tensor([[-2.6032e-02, -1.3644e-03, -7.6904e-03,  ...,  3.4773e-02,\n",
       "          -2.0939e-02,  2.6169e-03],\n",
       "         [ 9.0865e-03,  2.9723e-02,  2.2985e-03,  ...,  3.0933e-03,\n",
       "          -1.4981e-02, -5.6626e-03],\n",
       "         [-1.1103e-02, -2.2416e-02,  1.1807e-02,  ...,  4.2835e-03,\n",
       "           6.8362e-04,  2.8005e-02],\n",
       "         ...,\n",
       "         [ 1.0349e-02,  1.4645e-02, -1.2135e-03,  ..., -8.5243e-03,\n",
       "          -3.4417e-02,  1.8628e-02],\n",
       "         [ 6.9034e-03, -8.0863e-05, -2.9720e-03,  ...,  1.5001e-02,\n",
       "          -1.2573e-02, -8.5280e-03],\n",
       "         [-9.4238e-03, -3.0734e-02, -2.5018e-02,  ...,  5.8793e-04,\n",
       "          -1.6463e-02,  1.4613e-02]], device='cuda:0'),\n",
       " 'proj_eeg.0.bias': tensor([-0.0361, -0.0203, -0.0081,  ..., -0.0150, -0.0297, -0.0041],\n",
       "        device='cuda:0'),\n",
       " 'proj_eeg.1.fn.1.weight': tensor([[-0.0322, -0.0010,  0.0028,  ...,  0.0338, -0.0309,  0.0062],\n",
       "         [ 0.0352,  0.0099, -0.0222,  ...,  0.0052, -0.0072,  0.0219],\n",
       "         [-0.0049,  0.0287,  0.0153,  ...,  0.0097,  0.0212,  0.0112],\n",
       "         ...,\n",
       "         [ 0.0105,  0.0042,  0.0022,  ..., -0.0120,  0.0282,  0.0087],\n",
       "         [-0.0251,  0.0051,  0.0011,  ...,  0.0173, -0.0145,  0.0567],\n",
       "         [-0.0107, -0.0058, -0.0180,  ..., -0.0123, -0.0213, -0.0427]],\n",
       "        device='cuda:0'),\n",
       " 'proj_eeg.1.fn.1.bias': tensor([-0.0206,  0.0111, -0.0145,  ..., -0.0095, -0.0180,  0.0026],\n",
       "        device='cuda:0'),\n",
       " 'proj_eeg.2.weight': tensor([1.0163, 1.0376, 1.0220,  ..., 1.0180, 1.0006, 1.0156], device='cuda:0'),\n",
       " 'proj_eeg.2.bias': tensor([ 0.0194,  0.0361,  0.0216,  ...,  0.0104, -0.0040,  0.0543],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cp_path = \"tmp/train_eeg-epoch=20-VAL__loss=1.8497.ckpt\"\n",
    "cp = torch.load(cp_path)\n",
    "state_dict = cp[\"state_dict\"]\n",
    "filtered_state_dict = {k[len(\"eeg_encoder.\"):]:v for k, v in state_dict.items() if k.startswith(\"eeg_encoder.\")}\n",
    "filtered_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 cuda devices. Using cuda:0 device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gasparyanartur/miniconda3/envs/BCI/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 3202413\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "os.environ[\"WANDB_API_KEY\"] = \"KEY\"\n",
    "os.environ[\"WANDB_MODE\"] = 'offline'\n",
    "from itertools import combinations\n",
    "\n",
    "import clip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import tqdm\n",
    "from eegdatasets_leaveone import EEGDataset\n",
    "\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "from util import wandb_logger\n",
    "from braindecode.models import EEGNetv4, ATCNet, EEGConformer, EEGITNet, ShallowFBCSPNet\n",
    "import csv\n",
    "from torch import Tensor\n",
    "import itertools\n",
    "import math\n",
    "import re\n",
    "from subject_layers.Transformer_EncDec import Encoder, EncoderLayer\n",
    "from subject_layers.SelfAttention_Family import FullAttention, AttentionLayer\n",
    "from subject_layers.Embed import DataEmbedding\n",
    "import numpy as np\n",
    "from loss import ClipLoss\n",
    "import argparse\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.task_name = 'classification'  # Example task name\n",
    "        self.seq_len = 250                 # Sequence length\n",
    "        self.pred_len = 250                # Prediction length\n",
    "        self.output_attention = False      # Whether to output attention weights\n",
    "        self.d_model = 250                 # Model dimension\n",
    "        self.embed = 'timeF'               # Time encoding method\n",
    "        self.freq = 'h'                    # Time frequency\n",
    "        self.dropout = 0.25                # Dropout rate\n",
    "        self.factor = 1                    # Attention scaling factor\n",
    "        self.n_heads = 4                   # Number of attention heads\n",
    "        self.e_layers = 1                  # Number of encoder layers\n",
    "        self.d_ff = 256                    # Dimension of the feedforward network\n",
    "        self.activation = 'gelu'           # Activation function\n",
    "        self.enc_in = 63                   # Encoder input dimension (example value)\n",
    "\n",
    "class iTransformer(nn.Module):\n",
    "    def __init__(self, configs, joint_train=False,  num_subjects=10):\n",
    "        super(iTransformer, self).__init__()\n",
    "        self.task_name = configs.task_name\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.output_attention = configs.output_attention\n",
    "        # Embedding\n",
    "        self.enc_embedding = DataEmbedding(configs.seq_len, configs.d_model, configs.embed, configs.freq, configs.dropout, joint_train=False, num_subjects=num_subjects)\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        FullAttention(False, configs.factor, attention_dropout=configs.dropout, output_attention=configs.output_attention),\n",
    "                        configs.d_model, configs.n_heads\n",
    "                    ),\n",
    "                    configs.d_model,\n",
    "                    configs.d_ff,\n",
    "                    dropout=configs.dropout,\n",
    "                    activation=configs.activation\n",
    "                ) for l in range(configs.e_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(configs.d_model)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_enc, x_mark_enc, subject_ids=None):\n",
    "        # Embedding\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc, subject_ids)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=None)\n",
    "        enc_out = enc_out[:, :63, :]      \n",
    "        # print(\"enc_out\", enc_out.shape)\n",
    "        return enc_out\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, emb_size=40):\n",
    "        super().__init__()\n",
    "        # Revised from ShallowNet\n",
    "        self.tsconv = nn.Sequential(\n",
    "            nn.Conv2d(1, 40, (1, 25), stride=(1, 1)),\n",
    "            nn.AvgPool2d((1, 51), (1, 5)),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ELU(),\n",
    "            nn.Conv2d(40, 40, (63, 1), stride=(1, 1)),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv2d(40, emb_size, (1, 1), stride=(1, 1)),  \n",
    "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # b, _, _, _ = x.shape\n",
    "        x = x.unsqueeze(1)     \n",
    "        # print(\"x\", x.shape)   \n",
    "        x = self.tsconv(x)\n",
    "        # print(\"tsconv\", x.shape)   \n",
    "        x = self.projection(x)\n",
    "        # print(\"projection\", x.shape)  \n",
    "        return x\n",
    "\n",
    "class ResidualAdd(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        res = x\n",
    "        x = self.fn(x, **kwargs)\n",
    "        x += res\n",
    "        return x\n",
    "\n",
    "class FlattenHead(nn.Sequential):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class Enc_eeg(nn.Sequential):\n",
    "    def __init__(self, emb_size=40, **kwargs):\n",
    "        super().__init__(\n",
    "            PatchEmbedding(emb_size),\n",
    "            FlattenHead()\n",
    "        )\n",
    "\n",
    "class Proj_eeg(nn.Sequential):\n",
    "    def __init__(self, embedding_dim=1440, proj_dim=1024, drop_proj=0.5):\n",
    "        super().__init__(\n",
    "            nn.Linear(embedding_dim, proj_dim),\n",
    "            ResidualAdd(nn.Sequential(\n",
    "                nn.GELU(),\n",
    "                nn.Linear(proj_dim, proj_dim),\n",
    "                nn.Dropout(drop_proj),\n",
    "            )),\n",
    "            nn.LayerNorm(proj_dim),\n",
    "        )\n",
    "\n",
    "class ATMS(nn.Module):    \n",
    "    def __init__(self, num_channels=63, sequence_length=250, num_subjects=2, num_features=64, num_latents=1024, num_blocks=1):\n",
    "        super(ATMS, self).__init__()\n",
    "        default_config = Config()\n",
    "        self.encoder = iTransformer(default_config)   \n",
    "        self.subject_wise_linear = nn.ModuleList([nn.Linear(default_config.d_model, sequence_length) for _ in range(num_subjects)])\n",
    "        self.enc_eeg = Enc_eeg()\n",
    "        self.proj_eeg = Proj_eeg()        \n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
    "        self.loss_func = ClipLoss()       \n",
    "         \n",
    "    def forward(self, x, subject_ids):\n",
    "        x = self.encoder(x, None, subject_ids)\n",
    "        # print(f'After attention shape: {x.shape}')\n",
    "        # print(\"x\", x.shape)\n",
    "        # x = self.subject_wise_linear[0](x)\n",
    "        # print(f'After subject-specific linear transformation shape: {x.shape}')\n",
    "        eeg_embedding = self.enc_eeg(x)\n",
    "        out = self.proj_eeg(eeg_embedding)\n",
    "        return out  \n",
    "\n",
    "\n",
    "def extract_id_from_string(s):\n",
    "    match = re.search(r'\\d+$', s)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def get_eegfeatures(sub, eegmodel, dataloader, device, text_features_all, img_features_all, k, train):\n",
    "    eegmodel.eval()\n",
    "    text_features_all = text_features_all.to(device).float()\n",
    "    img_features_all = img_features_all.to(device).float()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    alpha =0.9\n",
    "    top5_correct = 0\n",
    "    top5_correct_count = 0\n",
    "\n",
    "    all_labels = set(range(text_features_all.size(0)))\n",
    "    top5_acc = 0\n",
    "    mse_loss_fn = nn.MSELoss()\n",
    "    ridge_lambda = 0.1\n",
    "    save_features = True\n",
    "    features_list = []  # List to store features    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (eeg_data, labels, text, text_features, img, img_features) in enumerate(dataloader):\n",
    "            eeg_data = eeg_data.to(device)\n",
    "            text_features = text_features.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "            img_features = img_features.to(device).float()\n",
    "            \n",
    "            batch_size = eeg_data.size(0)  # Assume the first element is the data tensor\n",
    "            subject_id = extract_id_from_string(sub)\n",
    "            # eeg_data = eeg_data.permute(0, 2, 1)\n",
    "            subject_ids = torch.full((batch_size,), subject_id, dtype=torch.long).to(device)\n",
    "            # if not config.insubject:\n",
    "            #     subject_ids = torch.full((batch_size,), -1, dtype=torch.long).to(device)          \n",
    "            eeg_features = eeg_model(eeg_data, subject_ids)\n",
    "            features_list.append(eeg_features.detach().cpu())\n",
    "\n",
    "        \n",
    "            logit_scale = eeg_model.logit_scale \n",
    "                   \n",
    "            regress_loss =  mse_loss_fn(eeg_features, img_features)\n",
    "            # print(\"eeg_features\", eeg_features.shape)\n",
    "            # print(torch.std(eeg_features, dim=-1))\n",
    "            # print(torch.std(img_features, dim=-1))\n",
    "            # l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "            # loss = (regress_loss + ridge_lambda * l2_norm)       \n",
    "            img_loss = eegmodel.loss_func(eeg_features, img_features, logit_scale)\n",
    "            text_loss = eegmodel.loss_func(eeg_features, text_features, logit_scale)\n",
    "            contrastive_loss = img_loss\n",
    "            # loss = img_loss + text_loss\n",
    "\n",
    "            regress_loss =  mse_loss_fn(eeg_features, img_features)\n",
    "            # print(\"text_loss\", text_loss)\n",
    "            # print(\"img_loss\", img_loss)\n",
    "            # print(\"regress_loss\", regress_loss)            \n",
    "            # l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "            # loss = (regress_loss + ridge_lambda * l2_norm)       \n",
    "            loss = alpha * regress_loss *10 + (1 - alpha) * contrastive_loss*10\n",
    "            # print(\"loss\", loss)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            for idx, label in enumerate(labels):\n",
    "\n",
    "                possible_classes = list(all_labels - {label.item()})\n",
    "                selected_classes = random.sample(possible_classes, k-1) + [label.item()]\n",
    "                selected_img_features = img_features_all[selected_classes]\n",
    "                \n",
    "\n",
    "                logits_img = logit_scale * eeg_features[idx] @ selected_img_features.T\n",
    "                # logits_text = logit_scale * eeg_features[idx] @ selected_text_features.T\n",
    "                # logits_single = (logits_text + logits_img) / 2.0\n",
    "                logits_single = logits_img\n",
    "                # print(\"logits_single\", logits_single.shape)\n",
    "\n",
    "                # predicted_label = selected_classes[torch.argmax(logits_single).item()]\n",
    "                predicted_label = selected_classes[torch.argmax(logits_single).item()] # (n_batch, ) \\in {0, 1, ..., n_cls-1}\n",
    "                if predicted_label == label.item():\n",
    "                    correct += 1        \n",
    "                total += 1\n",
    "\n",
    "        features_tensor = torch.cat(features_list, dim=0)\n",
    "        if save_features:\n",
    "            print(\"features_tensor\", features_tensor.shape)\n",
    "            torch.save(features_tensor.cpu(), f\"models/generated_mine_2/ATM_S_eeg_features_{sub}-train.pt\" if train else f\"models/generated_mine_2/ATM_S_eeg_features_{sub}-test.pt\")  # Save features as .pt file\n",
    "    average_loss = total_loss / (batch_idx+1)\n",
    "    accuracy = correct / total\n",
    "    return average_loss, accuracy, labels, features_tensor.cpu()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "config = {\n",
    "    \"data_path\": os.path.join(data_dir, \"Preprocessed_data_250Hz\"),\n",
    "    \"project\": \"atms_reconstruction\",\n",
    "    \"entity\": \"gasparyanartur\",\n",
    "    \"name\": \"lr=3e-4_img_pos_pro_eeg\",\n",
    "    \"lr\": 3e-4,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 1024,\n",
    "    \"logger\": True,\n",
    "    \"encoder_type\":'ATMS',\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data_path = config['data_path']\n",
    "features_dir = os.path.join(data_dir, \"features\")\n",
    "emb_img_test = torch.load(os.path.join(features_dir, 'ViT-H-14_features_test.pt'))\n",
    "emb_img_train = torch.load(os.path.join(features_dir, 'ViT-H-14_features_train.pt'))\n",
    "\n",
    "eeg_model = ATMS()\n",
    "print('number of parameters:', sum([p.numel() for p in eeg_model.parameters()]))\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "# eeg_model.load_state_dict(torch.load(\"/home/ldy/Workspace/Reconstruction/models/contrast/sub-08/01-30_00-44/40.pth\"))\n",
    "#cp = torch.load(\"models/contrast/ATMS/sub-08/09-29_10-36/40.pth\")\n",
    "#\n",
    "#eeg_model.load_state_dict(cp)\n",
    "\n",
    "\n",
    "eeg_model.load_state_dict(filtered_state_dict)\n",
    "eeg_model = eeg_model.to(device)\n",
    "sub = 'sub-08'\n",
    "#####################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.subjects ['sub-08']\n",
      "exclude_subject None\n",
      "data_tensor torch.Size([66160, 63, 250])\n",
      "Data tensor shape: torch.Size([66160, 63, 250]), label tensor shape: torch.Size([66160]), text length: 1654, image length: 16540\n",
      "Finished loading features\n",
      "features_tensor torch.Size([66160, 1024])\n",
      " - Train Loss: 13.9527, Train Accuracy: 0.0045\n",
      "self.subjects ['sub-08']\n",
      "exclude_subject None\n",
      "Data tensor shape: torch.Size([200, 63, 250]), label tensor shape: torch.Size([200]), text length: 200, image length: 200\n",
      "Finished loading features\n",
      "features_tensor torch.Size([200, 1024])\n",
      " - Test Loss: 10.9291, Test Accuracy: 0.5200\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "train_dataset = EEGDataset(data_path, subjects= [sub], train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=0)\n",
    "text_features_test_all = train_dataset.text_features\n",
    "img_features_test_all = train_dataset.img_features\n",
    "\n",
    "train_loss, train_accuracy, labels, eeg_features_train = get_eegfeatures(sub, eeg_model, train_loader, device, text_features_test_all, img_features_test_all,k=200, train=True)\n",
    "print(f\" - Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "test_dataset = EEGDataset(data_path, subjects= [sub], train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=0)\n",
    "text_features_test_all = test_dataset.text_features\n",
    "img_features_test_all = test_dataset.img_features\n",
    "test_loss, test_accuracy,labels, eeg_features_test = get_eegfeatures(sub, eeg_model, test_loader, device, text_features_test_all, img_features_test_all,k=200, train=False)\n",
    "print(f\" - Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import open_clip\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "import sys\n",
    "from diffusion_prior import *\n",
    "from custom_pipeline import *\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\" \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"models/generated_mine_2\"\n",
    "\n",
    "emb_img_train_4 = emb_img_train[\"img_features\"].view(1654,10,1,1024).repeat(1,1,4,1).view(-1,1024)\n",
    "emb_eeg = torch.load(os.path.join(models_dir, 'ATM_S_eeg_features_sub-08-train.pt'))\n",
    "emb_eeg_test = torch.load(os.path.join(models_dir, 'ATM_S_eeg_features_sub-08-test.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9675648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gasparyanartur/miniconda3/envs/BCI/lib/python3.10/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 64 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.1385870438355665\n",
      "epoch: 1, loss: 0.8879161623808054\n",
      "epoch: 2, loss: 0.6533835484431341\n",
      "epoch: 3, loss: 0.4864240233714764\n",
      "epoch: 4, loss: 0.3616069041765653\n",
      "epoch: 5, loss: 0.2686834990978241\n",
      "epoch: 6, loss: 0.2122892065690114\n",
      "epoch: 7, loss: 0.1805946517449159\n",
      "epoch: 8, loss: 0.15962580809226404\n",
      "epoch: 9, loss: 0.1423263056920125\n",
      "epoch: 10, loss: 0.12653853652568964\n",
      "epoch: 11, loss: 0.11255428561797509\n",
      "epoch: 12, loss: 0.10002006854002292\n",
      "epoch: 13, loss: 0.0890115322975012\n",
      "epoch: 14, loss: 0.07955897049261973\n",
      "epoch: 15, loss: 0.07100760615788973\n",
      "epoch: 16, loss: 0.06407074263462653\n",
      "epoch: 17, loss: 0.058054979202839044\n",
      "epoch: 18, loss: 0.052686737707028024\n",
      "epoch: 19, loss: 0.04835003786362135\n",
      "epoch: 20, loss: 0.044963942353542036\n",
      "epoch: 21, loss: 0.04144980259812795\n",
      "epoch: 22, loss: 0.03895826907112048\n",
      "epoch: 23, loss: 0.03638199871549239\n",
      "epoch: 24, loss: 0.03444103724681414\n",
      "epoch: 25, loss: 0.03267107256329976\n",
      "epoch: 26, loss: 0.031021901965141298\n",
      "epoch: 27, loss: 0.029997590470772523\n",
      "epoch: 28, loss: 0.028741749032185626\n",
      "epoch: 29, loss: 0.027304603474644515\n",
      "epoch: 30, loss: 0.026763901372368518\n",
      "epoch: 31, loss: 0.025706476173721828\n",
      "epoch: 32, loss: 0.024995574068564636\n",
      "epoch: 33, loss: 0.02396431717161949\n",
      "epoch: 34, loss: 0.02358294026209758\n",
      "epoch: 35, loss: 0.022928994091657492\n",
      "epoch: 36, loss: 0.022472479882148597\n",
      "epoch: 37, loss: 0.02250267221377446\n",
      "epoch: 38, loss: 0.021383391635922285\n",
      "epoch: 39, loss: 0.02136204128081982\n",
      "epoch: 40, loss: 0.020277376243701347\n",
      "epoch: 41, loss: 0.020489304627363498\n",
      "epoch: 42, loss: 0.019730351578730803\n",
      "epoch: 43, loss: 0.01952236945239397\n",
      "epoch: 44, loss: 0.01962107282418471\n",
      "epoch: 45, loss: 0.01929223623413306\n",
      "epoch: 46, loss: 0.018686223975740945\n",
      "epoch: 47, loss: 0.018982358678029134\n",
      "epoch: 48, loss: 0.01853717645773521\n",
      "epoch: 49, loss: 0.01834061604279738\n",
      "epoch: 50, loss: 0.018219027610925528\n",
      "epoch: 51, loss: 0.017694062166489086\n",
      "epoch: 52, loss: 0.017160640843212605\n",
      "epoch: 53, loss: 0.01688269406843644\n",
      "epoch: 54, loss: 0.01696593168263252\n",
      "epoch: 55, loss: 0.016801867304513086\n",
      "epoch: 56, loss: 0.016751732190067953\n",
      "epoch: 57, loss: 0.016753608991320317\n",
      "epoch: 58, loss: 0.016639669655034175\n",
      "epoch: 59, loss: 0.016307445300313143\n",
      "epoch: 60, loss: 0.016001099075835485\n",
      "epoch: 61, loss: 0.01573616532752147\n",
      "epoch: 62, loss: 0.01596955181314395\n",
      "epoch: 63, loss: 0.015583961557310361\n",
      "epoch: 64, loss: 0.015657248634558456\n",
      "epoch: 65, loss: 0.015118195202488166\n",
      "epoch: 66, loss: 0.01526543813256117\n",
      "epoch: 67, loss: 0.015431641257153107\n",
      "epoch: 68, loss: 0.014742324888133086\n",
      "epoch: 69, loss: 0.014740743631353746\n",
      "epoch: 70, loss: 0.015187153607033765\n",
      "epoch: 71, loss: 0.015338357939169957\n",
      "epoch: 72, loss: 0.01473602055070492\n",
      "epoch: 73, loss: 0.014320420215909298\n",
      "epoch: 74, loss: 0.014611196174071386\n",
      "epoch: 75, loss: 0.014171521007441557\n",
      "epoch: 76, loss: 0.01434861903007214\n",
      "epoch: 77, loss: 0.014213719390905821\n",
      "epoch: 78, loss: 0.014053232752932953\n",
      "epoch: 79, loss: 0.01376995351165533\n",
      "epoch: 80, loss: 0.013970027949947577\n",
      "epoch: 81, loss: 0.014019145243442976\n",
      "epoch: 82, loss: 0.013331988582817408\n",
      "epoch: 83, loss: 0.013731667012549364\n",
      "epoch: 84, loss: 0.013544438292200749\n",
      "epoch: 85, loss: 0.01351794212196882\n",
      "epoch: 86, loss: 0.01371330194748365\n",
      "epoch: 87, loss: 0.013034320880587284\n",
      "epoch: 88, loss: 0.013219902349206118\n",
      "epoch: 89, loss: 0.013139909921357265\n",
      "epoch: 90, loss: 0.013342432505809344\n",
      "epoch: 91, loss: 0.013370329356537416\n",
      "epoch: 92, loss: 0.012744967137964872\n",
      "epoch: 93, loss: 0.013132912006515724\n",
      "epoch: 94, loss: 0.012761912122368813\n",
      "epoch: 95, loss: 0.012869281192811636\n",
      "epoch: 96, loss: 0.012757800648418756\n",
      "epoch: 97, loss: 0.012878477888611647\n",
      "epoch: 98, loss: 0.012630230532242702\n",
      "epoch: 99, loss: 0.012881831079721451\n",
      "epoch: 100, loss: 0.012554629132724725\n",
      "epoch: 101, loss: 0.012411447141606075\n",
      "epoch: 102, loss: 0.012324568543296594\n",
      "epoch: 103, loss: 0.012941549345850945\n",
      "epoch: 104, loss: 0.012112500418264132\n",
      "epoch: 105, loss: 0.012429778664731063\n",
      "epoch: 106, loss: 0.01203063763678074\n",
      "epoch: 107, loss: 0.011942745429965165\n",
      "epoch: 108, loss: 0.012214673195893947\n",
      "epoch: 109, loss: 0.012073224396086657\n",
      "epoch: 110, loss: 0.012395237085337822\n",
      "epoch: 111, loss: 0.012123380773342574\n",
      "epoch: 112, loss: 0.011772388993547513\n",
      "epoch: 113, loss: 0.011827778543990392\n",
      "epoch: 114, loss: 0.012011593881134803\n",
      "epoch: 115, loss: 0.011578895782048886\n",
      "epoch: 116, loss: 0.011676124282754385\n",
      "epoch: 117, loss: 0.011919309628697541\n",
      "epoch: 118, loss: 0.011847907648636745\n",
      "epoch: 119, loss: 0.01155097335577011\n",
      "epoch: 120, loss: 0.011545633667936692\n",
      "epoch: 121, loss: 0.011537784008452526\n",
      "epoch: 122, loss: 0.011524490424646781\n",
      "epoch: 123, loss: 0.011759654647455766\n",
      "epoch: 124, loss: 0.011388505851993193\n",
      "epoch: 125, loss: 0.01174078954813572\n",
      "epoch: 126, loss: 0.011556154145644261\n",
      "epoch: 127, loss: 0.011181430318034612\n",
      "epoch: 128, loss: 0.011723657554158797\n",
      "epoch: 129, loss: 0.011301224148617341\n",
      "epoch: 130, loss: 0.011419697306477107\n",
      "epoch: 131, loss: 0.011394394418367973\n",
      "epoch: 132, loss: 0.011469252636799446\n",
      "epoch: 133, loss: 0.011276523367716717\n",
      "epoch: 134, loss: 0.011195476911962033\n",
      "epoch: 135, loss: 0.011168409482790874\n",
      "epoch: 136, loss: 0.011511834223683064\n",
      "epoch: 137, loss: 0.011430578564222043\n",
      "epoch: 138, loss: 0.011521178440978894\n",
      "epoch: 139, loss: 0.011560962564097001\n",
      "epoch: 140, loss: 0.011085736027990397\n",
      "epoch: 141, loss: 0.010928555090840047\n",
      "epoch: 142, loss: 0.011082420641413102\n",
      "epoch: 143, loss: 0.01115184214252692\n",
      "epoch: 144, loss: 0.011007508549552698\n",
      "epoch: 145, loss: 0.01100620931157699\n",
      "epoch: 146, loss: 0.011001401853102903\n",
      "epoch: 147, loss: 0.011349576167189158\n",
      "epoch: 148, loss: 0.010973489957933243\n",
      "epoch: 149, loss: 0.01130448396389301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiffusionPriorUNet(\n",
       "  (time_proj): Timesteps()\n",
       "  (input_layer): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): SiLU()\n",
       "  )\n",
       "  (encode_time_embedding): ModuleList(\n",
       "    (0): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (1): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "    (2): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (3): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encode_cond_embedding): ModuleList(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (3): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (encode_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decode_time_embedding): ModuleList(\n",
       "    (0): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=512, out_features=64, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (1): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=512, out_features=128, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (2): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (3): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decode_cond_embedding): ModuleList(\n",
       "    (0): Linear(in_features=1024, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (decode_layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): SiLU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DIFFUSION_PRIOR = True\n",
    "if TRAIN_DIFFUSION_PRIOR:\n",
    "    assert \"original\" not in models_dir\n",
    "\n",
    "model_name = 'diffusion_prior' # 'diffusion_prior_vice_pre_imagenet' or 'diffusion_prior_vice_pre'\n",
    "save_path = os.path.join(models_dir, f'{config[\"encoder_type\"]}/{sub}/{model_name}.pt')\n",
    "\n",
    "dataset = EmbeddingDataset(\n",
    "    c_embeddings=eeg_features_train, h_embeddings=emb_img_train_4, \n",
    "    # h_embeds_uncond=h_embeds_imgnet\n",
    ")\n",
    "dl = DataLoader(dataset, batch_size=1024, shuffle=True, num_workers=64)\n",
    "diffusion_prior = DiffusionPriorUNet(cond_dim=1024, dropout=0.1)\n",
    "# number of parameters\n",
    "print(sum(p.numel() for p in diffusion_prior.parameters() if p.requires_grad))\n",
    "pipe = Pipe(diffusion_prior, device=device)\n",
    "\n",
    "if TRAIN_DIFFUSION_PRIOR:\n",
    "    pipe.train(dl, num_epochs=150, learning_rate=1e-3) # to 0.142 \n",
    "\n",
    "\n",
    "    directory = os.path.dirname(save_path)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    torch.save(pipe.diffusion_prior.state_dict(), save_path)\n",
    "\n",
    "else:\n",
    "    pipe.diffusion_prior.load_state_dict(torch.load(save_path, map_location=device))\n",
    "\n",
    "pipe.diffusion_prior.eval()\n",
    "pipe.diffusion_prior.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:00, 168.06it/s]gs...:   0%|          | 0/200 [00:00<?, ?it/s]\n",
      "50it [00:00, 181.37it/s]gs...:   0%|          | 1/200 [00:00<00:59,  3.33it/s]\n",
      "50it [00:00, 188.79it/s]gs...:   1%|          | 2/200 [00:00<00:56,  3.48it/s]\n",
      "50it [00:00, 199.61it/s]gs...:   2%|▏         | 3/200 [00:00<00:54,  3.59it/s]\n",
      "50it [00:00, 185.86it/s]gs...:   2%|▏         | 4/200 [00:01<00:52,  3.72it/s]\n",
      "50it [00:00, 189.58it/s]gs...:   2%|▎         | 5/200 [00:01<00:52,  3.71it/s]\n",
      "50it [00:00, 202.13it/s]gs...:   3%|▎         | 6/200 [00:01<00:52,  3.72it/s]\n",
      "50it [00:00, 200.70it/s]gs...:   4%|▎         | 7/200 [00:01<00:50,  3.81it/s]\n",
      "50it [00:00, 204.83it/s]gs...:   4%|▍         | 8/200 [00:02<00:49,  3.86it/s]\n",
      "50it [00:00, 199.65it/s]gs...:   4%|▍         | 9/200 [00:02<00:48,  3.91it/s]\n",
      "50it [00:00, 202.57it/s]gs...:   5%|▌         | 10/200 [00:02<00:48,  3.92it/s]\n",
      "50it [00:00, 202.39it/s]gs...:   6%|▌         | 11/200 [00:02<00:47,  3.95it/s]\n",
      "50it [00:00, 197.95it/s]gs...:   6%|▌         | 12/200 [00:03<00:47,  3.96it/s]\n",
      "50it [00:00, 195.47it/s]gs...:   6%|▋         | 13/200 [00:03<00:47,  3.95it/s]\n",
      "50it [00:00, 192.65it/s]gs...:   7%|▋         | 14/200 [00:03<00:47,  3.92it/s]\n",
      "50it [00:00, 198.91it/s]gs...:   8%|▊         | 15/200 [00:03<00:47,  3.89it/s]\n",
      "50it [00:00, 196.82it/s]gs...:   8%|▊         | 16/200 [00:04<00:47,  3.90it/s]\n",
      "50it [00:00, 198.92it/s]gs...:   8%|▊         | 17/200 [00:04<00:46,  3.90it/s]\n",
      "50it [00:00, 195.31it/s]gs...:   9%|▉         | 18/200 [00:04<00:46,  3.91it/s]\n",
      "50it [00:00, 199.39it/s]gs...:  10%|▉         | 19/200 [00:04<00:46,  3.90it/s]\n",
      "50it [00:00, 198.13it/s]gs...:  10%|█         | 20/200 [00:05<00:46,  3.91it/s]\n",
      "50it [00:00, 195.06it/s]gs...:  10%|█         | 21/200 [00:05<00:45,  3.91it/s]\n",
      "50it [00:00, 208.41it/s]gs...:  11%|█         | 22/200 [00:05<00:45,  3.90it/s]\n",
      "50it [00:00, 211.62it/s]gs...:  12%|█▏        | 23/200 [00:05<00:44,  3.96it/s]\n",
      "50it [00:00, 207.82it/s]gs...:  12%|█▏        | 24/200 [00:06<00:43,  4.03it/s]\n",
      "50it [00:00, 206.03it/s]gs...:  12%|█▎        | 25/200 [00:06<00:43,  4.05it/s]\n",
      "50it [00:00, 205.06it/s]gs...:  13%|█▎        | 26/200 [00:06<00:42,  4.06it/s]\n",
      "50it [00:00, 207.72it/s]gs...:  14%|█▎        | 27/200 [00:06<00:42,  4.06it/s]\n",
      "50it [00:00, 208.82it/s]gs...:  14%|█▍        | 28/200 [00:07<00:42,  4.07it/s]\n",
      "50it [00:00, 207.34it/s]gs...:  14%|█▍        | 29/200 [00:07<00:41,  4.09it/s]\n",
      "50it [00:00, 195.87it/s]gs...:  15%|█▌        | 30/200 [00:07<00:41,  4.09it/s]\n",
      "50it [00:00, 193.24it/s]gs...:  16%|█▌        | 31/200 [00:07<00:41,  4.03it/s]\n",
      "50it [00:00, 195.86it/s]gs...:  16%|█▌        | 32/200 [00:08<00:42,  3.96it/s]\n",
      "50it [00:00, 198.74it/s]gs...:  16%|█▋        | 33/200 [00:08<00:42,  3.93it/s]\n",
      "50it [00:00, 192.60it/s]gs...:  17%|█▋        | 34/200 [00:08<00:42,  3.93it/s]\n",
      "50it [00:00, 205.64it/s]gs...:  18%|█▊        | 35/200 [00:08<00:42,  3.90it/s]\n",
      "50it [00:00, 202.59it/s]gs...:  18%|█▊        | 36/200 [00:09<00:41,  3.94it/s]\n",
      "50it [00:00, 207.65it/s]gs...:  18%|█▊        | 37/200 [00:09<00:41,  3.96it/s]\n",
      "50it [00:00, 208.19it/s]gs...:  19%|█▉        | 38/200 [00:09<00:40,  4.01it/s]\n",
      "50it [00:00, 204.34it/s]gs...:  20%|█▉        | 39/200 [00:09<00:39,  4.04it/s]\n",
      "50it [00:00, 204.60it/s]gs...:  20%|██        | 40/200 [00:10<00:39,  4.04it/s]\n",
      "50it [00:00, 212.67it/s]gs...:  20%|██        | 41/200 [00:10<00:39,  4.04it/s]\n",
      "50it [00:00, 209.88it/s]gs...:  21%|██        | 42/200 [00:10<00:38,  4.09it/s]\n",
      "50it [00:00, 195.80it/s]gs...:  22%|██▏       | 43/200 [00:10<00:38,  4.11it/s]\n",
      "50it [00:00, 196.05it/s]gs...:  22%|██▏       | 44/200 [00:11<00:38,  4.03it/s]\n",
      "50it [00:00, 191.00it/s]gs...:  22%|██▎       | 45/200 [00:11<00:38,  3.99it/s]\n",
      "50it [00:00, 195.46it/s]gs...:  23%|██▎       | 46/200 [00:11<00:39,  3.92it/s]\n",
      "50it [00:00, 200.00it/s]gs...:  24%|██▎       | 47/200 [00:11<00:39,  3.91it/s]\n",
      "50it [00:00, 200.39it/s]gs...:  24%|██▍       | 48/200 [00:12<00:38,  3.92it/s]\n",
      "50it [00:00, 200.48it/s]gs...:  24%|██▍       | 49/200 [00:12<00:38,  3.93it/s]\n",
      "50it [00:00, 197.84it/s]gs...:  25%|██▌       | 50/200 [00:12<00:38,  3.94it/s]\n",
      "50it [00:00, 200.34it/s]gs...:  26%|██▌       | 51/200 [00:12<00:37,  3.93it/s]\n",
      "50it [00:00, 210.52it/s]gs...:  26%|██▌       | 52/200 [00:13<00:37,  3.94it/s]\n",
      "50it [00:00, 207.14it/s]gs...:  26%|██▋       | 53/200 [00:13<00:36,  4.01it/s]\n",
      "50it [00:00, 209.11it/s]gs...:  27%|██▋       | 54/200 [00:13<00:36,  4.03it/s]\n",
      "50it [00:00, 199.79it/s]gs...:  28%|██▊       | 55/200 [00:13<00:35,  4.06it/s]\n",
      "50it [00:00, 204.67it/s]gs...:  28%|██▊       | 56/200 [00:14<00:35,  4.03it/s]\n",
      "50it [00:00, 202.08it/s]gs...:  28%|██▊       | 57/200 [00:14<00:35,  4.03it/s]\n",
      "50it [00:00, 195.17it/s]gs...:  29%|██▉       | 58/200 [00:14<00:35,  4.02it/s]\n",
      "50it [00:00, 190.80it/s]gs...:  30%|██▉       | 59/200 [00:14<00:35,  3.97it/s]\n",
      "50it [00:00, 197.88it/s]gs...:  30%|███       | 60/200 [00:15<00:35,  3.91it/s]\n",
      "50it [00:00, 192.64it/s]gs...:  30%|███       | 61/200 [00:15<00:35,  3.91it/s]\n",
      "50it [00:00, 192.97it/s]gs...:  31%|███       | 62/200 [00:15<00:35,  3.88it/s]\n",
      "50it [00:00, 193.22it/s]gs...:  32%|███▏      | 63/200 [00:15<00:35,  3.86it/s]\n",
      "50it [00:00, 191.50it/s]gs...:  32%|███▏      | 64/200 [00:16<00:35,  3.85it/s]\n",
      "50it [00:00, 197.87it/s]gs...:  32%|███▎      | 65/200 [00:16<00:35,  3.83it/s]\n",
      "50it [00:00, 198.92it/s]gs...:  33%|███▎      | 66/200 [00:16<00:34,  3.85it/s]\n",
      "50it [00:00, 197.51it/s]gs...:  34%|███▎      | 67/200 [00:17<00:34,  3.88it/s]\n",
      "50it [00:00, 197.15it/s]gs...:  34%|███▍      | 68/200 [00:17<00:33,  3.89it/s]\n",
      "50it [00:00, 200.25it/s]gs...:  34%|███▍      | 69/200 [00:17<00:33,  3.89it/s]\n",
      "50it [00:00, 200.48it/s]gs...:  35%|███▌      | 70/200 [00:17<00:33,  3.91it/s]\n",
      "50it [00:00, 205.25it/s]gs...:  36%|███▌      | 71/200 [00:18<00:32,  3.93it/s]\n",
      "50it [00:00, 202.54it/s]gs...:  36%|███▌      | 72/200 [00:18<00:32,  3.96it/s]\n",
      "50it [00:00, 196.32it/s]gs...:  36%|███▋      | 73/200 [00:18<00:31,  3.98it/s]\n",
      "50it [00:00, 200.50it/s]gs...:  37%|███▋      | 74/200 [00:18<00:31,  3.95it/s]\n",
      "50it [00:00, 194.44it/s]gs...:  38%|███▊      | 75/200 [00:19<00:31,  3.95it/s]\n",
      "50it [00:00, 182.45it/s]gs...:  38%|███▊      | 76/200 [00:19<00:31,  3.92it/s]\n",
      "50it [00:00, 168.22it/s]gs...:  38%|███▊      | 77/200 [00:19<00:32,  3.82it/s]\n",
      "50it [00:00, 197.67it/s]gs...:  39%|███▉      | 78/200 [00:19<00:33,  3.66it/s]\n",
      "50it [00:00, 194.38it/s]gs...:  40%|███▉      | 79/200 [00:20<00:32,  3.73it/s]\n",
      "50it [00:00, 196.52it/s]gs...:  40%|████      | 80/200 [00:20<00:31,  3.76it/s]\n",
      "50it [00:00, 198.73it/s]gs...:  40%|████      | 81/200 [00:20<00:31,  3.80it/s]\n",
      "50it [00:00, 198.61it/s]gs...:  41%|████      | 82/200 [00:20<00:30,  3.84it/s]\n",
      "50it [00:00, 198.63it/s]gs...:  42%|████▏     | 83/200 [00:21<00:30,  3.86it/s]\n",
      "50it [00:00, 196.13it/s]gs...:  42%|████▏     | 84/200 [00:21<00:29,  3.88it/s]\n",
      "50it [00:00, 194.07it/s]gs...:  42%|████▎     | 85/200 [00:21<00:29,  3.87it/s]\n",
      "50it [00:00, 197.99it/s]gs...:  43%|████▎     | 86/200 [00:21<00:29,  3.86it/s]\n",
      "50it [00:00, 200.12it/s]gs...:  44%|████▎     | 87/200 [00:22<00:29,  3.88it/s]\n",
      "50it [00:00, 198.87it/s]gs...:  44%|████▍     | 88/200 [00:22<00:28,  3.90it/s]\n",
      "50it [00:00, 198.16it/s]gs...:  44%|████▍     | 89/200 [00:22<00:28,  3.91it/s]\n",
      "50it [00:00, 196.27it/s]gs...:  45%|████▌     | 90/200 [00:22<00:28,  3.91it/s]\n",
      "50it [00:00, 196.75it/s]gs...:  46%|████▌     | 91/200 [00:23<00:27,  3.90it/s]\n",
      "50it [00:00, 198.08it/s]gs...:  46%|████▌     | 92/200 [00:23<00:27,  3.90it/s]\n",
      "50it [00:00, 198.17it/s]gs...:  46%|████▋     | 93/200 [00:23<00:27,  3.90it/s]\n",
      "50it [00:00, 196.71it/s]gs...:  47%|████▋     | 94/200 [00:23<00:27,  3.91it/s]\n",
      "50it [00:00, 198.75it/s]gs...:  48%|████▊     | 95/200 [00:24<00:26,  3.90it/s]\n",
      "50it [00:00, 192.64it/s]gs...:  48%|████▊     | 96/200 [00:24<00:26,  3.91it/s]\n",
      "50it [00:00, 187.46it/s]gs...:  48%|████▊     | 97/200 [00:24<00:26,  3.88it/s]\n",
      "50it [00:00, 175.63it/s]gs...:  49%|████▉     | 98/200 [00:25<00:26,  3.83it/s]\n",
      "50it [00:00, 185.07it/s]gs...:  50%|████▉     | 99/200 [00:25<00:27,  3.72it/s]\n",
      "50it [00:00, 199.12it/s]gs...:  50%|█████     | 100/200 [00:25<00:27,  3.70it/s]\n",
      "50it [00:00, 203.01it/s]gs...:  50%|█████     | 101/200 [00:25<00:26,  3.77it/s]\n",
      "50it [00:00, 187.22it/s]gs...:  51%|█████     | 102/200 [00:26<00:25,  3.84it/s]\n",
      "50it [00:00, 210.55it/s]gs...:  52%|█████▏    | 103/200 [00:26<00:25,  3.80it/s]\n",
      "50it [00:00, 209.09it/s]gs...:  52%|█████▏    | 104/200 [00:26<00:24,  3.90it/s]\n",
      "50it [00:00, 205.08it/s]gs...:  52%|█████▎    | 105/200 [00:26<00:23,  3.97it/s]\n",
      "50it [00:00, 206.38it/s]gs...:  53%|█████▎    | 106/200 [00:27<00:23,  3.99it/s]\n",
      "50it [00:00, 209.57it/s]gs...:  54%|█████▎    | 107/200 [00:27<00:23,  4.02it/s]\n",
      "50it [00:00, 208.11it/s]gs...:  54%|█████▍    | 108/200 [00:27<00:22,  4.05it/s]\n",
      "50it [00:00, 206.63it/s]gs...:  55%|█████▍    | 109/200 [00:27<00:22,  4.07it/s]\n",
      "50it [00:00, 196.00it/s]gs...:  55%|█████▌    | 110/200 [00:28<00:22,  4.07it/s]\n",
      "50it [00:00, 206.68it/s]gs...:  56%|█████▌    | 111/200 [00:28<00:22,  4.01it/s]\n",
      "50it [00:00, 186.25it/s]gs...:  56%|█████▌    | 112/200 [00:28<00:21,  4.04it/s]\n",
      "50it [00:00, 200.89it/s]gs...:  56%|█████▋    | 113/200 [00:28<00:22,  3.92it/s]\n",
      "50it [00:00, 195.65it/s]gs...:  57%|█████▋    | 114/200 [00:29<00:21,  3.94it/s]\n",
      "50it [00:00, 194.09it/s]gs...:  57%|█████▊    | 115/200 [00:29<00:21,  3.92it/s]\n",
      "50it [00:00, 191.42it/s]gs...:  58%|█████▊    | 116/200 [00:29<00:21,  3.89it/s]\n",
      "50it [00:00, 177.26it/s]gs...:  58%|█████▊    | 117/200 [00:29<00:21,  3.86it/s]\n",
      "50it [00:00, 190.30it/s]gs...:  59%|█████▉    | 118/200 [00:30<00:21,  3.75it/s]\n",
      "50it [00:00, 184.16it/s]gs...:  60%|█████▉    | 119/200 [00:30<00:21,  3.75it/s]\n",
      "50it [00:00, 182.30it/s]gs...:  60%|██████    | 120/200 [00:30<00:21,  3.72it/s]\n",
      "50it [00:00, 180.21it/s]gs...:  60%|██████    | 121/200 [00:30<00:21,  3.69it/s]\n",
      "50it [00:00, 183.59it/s]gs...:  61%|██████    | 122/200 [00:31<00:21,  3.65it/s]\n",
      "50it [00:00, 192.45it/s]gs...:  62%|██████▏   | 123/200 [00:31<00:21,  3.64it/s]\n",
      "50it [00:00, 184.41it/s]gs...:  62%|██████▏   | 124/200 [00:31<00:20,  3.69it/s]\n",
      "50it [00:00, 190.46it/s]gs...:  62%|██████▎   | 125/200 [00:32<00:20,  3.68it/s]\n",
      "50it [00:00, 200.84it/s]gs...:  63%|██████▎   | 126/200 [00:32<00:19,  3.71it/s]\n",
      "50it [00:00, 201.25it/s]gs...:  64%|██████▎   | 127/200 [00:32<00:19,  3.78it/s]\n",
      "50it [00:00, 199.47it/s]gs...:  64%|██████▍   | 128/200 [00:32<00:18,  3.84it/s]\n",
      "50it [00:00, 203.02it/s]gs...:  64%|██████▍   | 129/200 [00:33<00:18,  3.87it/s]\n",
      "50it [00:00, 203.31it/s]gs...:  65%|██████▌   | 130/200 [00:33<00:17,  3.91it/s]\n",
      "50it [00:00, 202.71it/s]gs...:  66%|██████▌   | 131/200 [00:33<00:17,  3.95it/s]\n",
      "50it [00:00, 183.70it/s]gs...:  66%|██████▌   | 132/200 [00:33<00:17,  3.97it/s]\n",
      "50it [00:00, 193.23it/s]gs...:  66%|██████▋   | 133/200 [00:34<00:17,  3.86it/s]\n",
      "50it [00:00, 191.84it/s]gs...:  67%|██████▋   | 134/200 [00:34<00:17,  3.85it/s]\n",
      "50it [00:00, 197.22it/s]gs...:  68%|██████▊   | 135/200 [00:34<00:16,  3.83it/s]\n",
      "50it [00:00, 195.02it/s]gs...:  68%|██████▊   | 136/200 [00:34<00:16,  3.85it/s]\n",
      "50it [00:00, 194.54it/s]gs...:  68%|██████▊   | 137/200 [00:35<00:16,  3.85it/s]\n",
      "50it [00:00, 196.01it/s]gs...:  69%|██████▉   | 138/200 [00:35<00:16,  3.85it/s]\n",
      "50it [00:00, 193.24it/s]gs...:  70%|██████▉   | 139/200 [00:35<00:15,  3.86it/s]\n",
      "50it [00:00, 193.85it/s]gs...:  70%|███████   | 140/200 [00:35<00:15,  3.85it/s]\n",
      "50it [00:00, 195.78it/s]gs...:  70%|███████   | 141/200 [00:36<00:15,  3.85it/s]\n",
      "50it [00:00, 198.03it/s]gs...:  71%|███████   | 142/200 [00:36<00:15,  3.85it/s]\n",
      "50it [00:00, 198.36it/s]gs...:  72%|███████▏  | 143/200 [00:36<00:14,  3.87it/s]\n",
      "50it [00:00, 194.64it/s]gs...:  72%|███████▏  | 144/200 [00:36<00:14,  3.89it/s]\n",
      "50it [00:00, 191.50it/s]gs...:  72%|███████▎  | 145/200 [00:37<00:14,  3.87it/s]\n",
      "50it [00:00, 197.65it/s]gs...:  73%|███████▎  | 146/200 [00:37<00:14,  3.85it/s]\n",
      "50it [00:00, 178.82it/s]gs...:  74%|███████▎  | 147/200 [00:37<00:13,  3.87it/s]\n",
      "50it [00:00, 181.78it/s]gs...:  74%|███████▍  | 148/200 [00:38<00:13,  3.76it/s]\n",
      "50it [00:00, 192.37it/s]gs...:  74%|███████▍  | 149/200 [00:38<00:13,  3.71it/s]\n",
      "50it [00:00, 197.63it/s]gs...:  75%|███████▌  | 150/200 [00:38<00:13,  3.74it/s]\n",
      "50it [00:00, 197.96it/s]gs...:  76%|███████▌  | 151/200 [00:38<00:12,  3.79it/s]\n",
      "50it [00:00, 200.62it/s]gs...:  76%|███████▌  | 152/200 [00:39<00:12,  3.83it/s]\n",
      "50it [00:00, 196.42it/s]gs...:  76%|███████▋  | 153/200 [00:39<00:12,  3.87it/s]\n",
      "50it [00:00, 195.78it/s]gs...:  77%|███████▋  | 154/200 [00:39<00:11,  3.87it/s]\n",
      "50it [00:00, 188.66it/s]gs...:  78%|███████▊  | 155/200 [00:39<00:11,  3.87it/s]\n",
      "50it [00:00, 192.18it/s]gs...:  78%|███████▊  | 156/200 [00:40<00:11,  3.83it/s]\n",
      "50it [00:00, 191.18it/s]gs...:  78%|███████▊  | 157/200 [00:40<00:11,  3.82it/s]\n",
      "50it [00:00, 196.72it/s]gs...:  79%|███████▉  | 158/200 [00:40<00:11,  3.81it/s]\n",
      "50it [00:00, 191.45it/s]gs...:  80%|███████▉  | 159/200 [00:40<00:10,  3.83it/s]\n",
      "50it [00:00, 197.44it/s]gs...:  80%|████████  | 160/200 [00:41<00:10,  3.82it/s]\n",
      "50it [00:00, 195.94it/s]gs...:  80%|████████  | 161/200 [00:41<00:10,  3.84it/s]\n",
      "50it [00:00, 196.96it/s]gs...:  81%|████████  | 162/200 [00:41<00:09,  3.85it/s]\n",
      "50it [00:00, 196.71it/s]gs...:  82%|████████▏ | 163/200 [00:41<00:09,  3.87it/s]\n",
      "50it [00:00, 187.23it/s]gs...:  82%|████████▏ | 164/200 [00:42<00:09,  3.88it/s]\n",
      "50it [00:00, 186.81it/s]gs...:  82%|████████▎ | 165/200 [00:42<00:09,  3.82it/s]\n",
      "50it [00:00, 190.14it/s]gs...:  83%|████████▎ | 166/200 [00:42<00:08,  3.78it/s]\n",
      "50it [00:00, 194.49it/s]gs...:  84%|████████▎ | 167/200 [00:42<00:08,  3.78it/s]\n",
      "50it [00:00, 196.58it/s]gs...:  84%|████████▍ | 168/200 [00:43<00:08,  3.80it/s]\n",
      "50it [00:00, 206.36it/s]gs...:  84%|████████▍ | 169/200 [00:43<00:08,  3.83it/s]\n",
      "50it [00:00, 207.63it/s]gs...:  85%|████████▌ | 170/200 [00:43<00:07,  3.90it/s]\n",
      "50it [00:00, 183.63it/s]gs...:  86%|████████▌ | 171/200 [00:44<00:07,  3.96it/s]\n",
      "50it [00:00, 195.61it/s]gs...:  86%|████████▌ | 172/200 [00:44<00:07,  3.86it/s]\n",
      "50it [00:00, 190.56it/s]gs...:  86%|████████▋ | 173/200 [00:44<00:06,  3.86it/s]\n",
      "50it [00:00, 184.01it/s]gs...:  87%|████████▋ | 174/200 [00:44<00:06,  3.83it/s]\n",
      "50it [00:00, 181.80it/s]gs...:  88%|████████▊ | 175/200 [00:45<00:06,  3.77it/s]\n",
      "50it [00:00, 193.47it/s]gs...:  88%|████████▊ | 176/200 [00:45<00:06,  3.72it/s]\n",
      "50it [00:00, 208.02it/s]gs...:  88%|████████▊ | 177/200 [00:45<00:06,  3.75it/s]\n",
      "50it [00:00, 205.71it/s]gs...:  89%|████████▉ | 178/200 [00:45<00:05,  3.85it/s]\n",
      "50it [00:00, 194.15it/s]gs...:  90%|████████▉ | 179/200 [00:46<00:05,  3.91it/s]\n",
      "50it [00:00, 192.90it/s]gs...:  90%|█████████ | 180/200 [00:46<00:05,  3.89it/s]\n",
      "50it [00:00, 198.27it/s]gs...:  90%|█████████ | 181/200 [00:46<00:04,  3.87it/s]\n",
      "50it [00:00, 198.74it/s]gs...:  91%|█████████ | 182/200 [00:46<00:04,  3.89it/s]\n",
      "50it [00:00, 187.63it/s]gs...:  92%|█████████▏| 183/200 [00:47<00:04,  3.90it/s]\n",
      "50it [00:00, 177.78it/s]gs...:  92%|█████████▏| 184/200 [00:47<00:04,  3.84it/s]\n",
      "50it [00:00, 191.27it/s]gs...:  92%|█████████▎| 185/200 [00:47<00:04,  3.74it/s]\n",
      "50it [00:00, 189.53it/s]gs...:  93%|█████████▎| 186/200 [00:47<00:03,  3.75it/s]\n",
      "50it [00:00, 190.28it/s]gs...:  94%|█████████▎| 187/200 [00:48<00:03,  3.75it/s]\n",
      "50it [00:00, 186.11it/s]gs...:  94%|█████████▍| 188/200 [00:48<00:03,  3.76it/s]\n",
      "50it [00:00, 170.58it/s]gs...:  94%|█████████▍| 189/200 [00:48<00:02,  3.73it/s]\n",
      "50it [00:00, 197.27it/s]gs...:  95%|█████████▌| 190/200 [00:49<00:02,  3.62it/s]\n",
      "50it [00:00, 182.99it/s]gs...:  96%|█████████▌| 191/200 [00:49<00:02,  3.70it/s]\n",
      "50it [00:00, 206.64it/s]gs...:  96%|█████████▌| 192/200 [00:49<00:02,  3.67it/s]\n",
      "50it [00:00, 203.70it/s]gs...:  96%|█████████▋| 193/200 [00:49<00:01,  3.79it/s]\n",
      "50it [00:00, 204.54it/s]gs...:  97%|█████████▋| 194/200 [00:50<00:01,  3.86it/s]\n",
      "50it [00:00, 206.81it/s]gs...:  98%|█████████▊| 195/200 [00:50<00:01,  3.91it/s]\n",
      "50it [00:00, 207.05it/s]gs...:  98%|█████████▊| 196/200 [00:50<00:01,  3.96it/s]\n",
      "50it [00:00, 206.29it/s]gs...:  98%|█████████▊| 197/200 [00:50<00:00,  4.00it/s]\n",
      "50it [00:00, 210.76it/s]gs...:  99%|█████████▉| 198/200 [00:51<00:00,  4.02it/s]\n",
      "50it [00:00, 206.88it/s]gs...: 100%|█████████▉| 199/200 [00:51<00:00,  4.07it/s]\n",
      "Generating test embeddings...: 100%|██████████| 200/200 [00:51<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate test embeddings\n",
    "\n",
    "test_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for k in tqdm(list(range(200)), desc=\"Generating test embeddings...\"):\n",
    "        eeg_embeds = emb_eeg_test[k:k+1]\n",
    "        h = pipe.generate(c_embeds=eeg_embeds, num_inference_steps=50, guidance_scale=5.0)\n",
    "        test_embeddings.append(h.detach().cpu())\n",
    "    test_embeddings = torch.cat(test_embeddings)\n",
    "print(test_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tensors and modules:\n",
      "_\n",
      "eeg_model\n",
      "text_features_test_all\n",
      "img_features_test_all\n",
      "labels\n",
      "eeg_features_train\n",
      "eeg_features_test\n",
      "emb_img_train_4\n",
      "emb_eeg\n",
      "emb_eeg_test\n",
      "diffusion_prior\n",
      "_8\n",
      "test_embeddings\n",
      "eeg_embeds\n",
      "h\n"
     ]
    }
   ],
   "source": [
    "print(\"All tensors and modules:\")\n",
    "import itertools as it\n",
    "to_delete = []\n",
    "for k, v in locals().items():\n",
    "    if isinstance(v, (torch.Tensor, torch.nn.Module)):\n",
    "        v.to(\"cpu\")\n",
    "        print(k.replace('\\n', ''))\n",
    "    if k.startswith(\"_\"):\n",
    "        to_delete.append((k, v))\n",
    "        \n",
    "for (k, v) in to_delete:\n",
    "    try:\n",
    "        del v\n",
    "    except NameError:\n",
    "        pass\n",
    "\n",
    "import gc\n",
    "try:\n",
    "    del eeg_model\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    del generator\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del pipe\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    del diffusion_prior\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading generator...\n",
      "Loading pipe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe loaded\n",
      "\tLoading ip adapter...\n",
      "\tIP adapter loaded\n",
      "Finished loading generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating images...:   0%|          | 0/200 [00:00<?, ?it/s]/home/gasparyanartur/miniconda3/envs/BCI/lib/python3.10/site-packages/diffusers/models/embeddings.py:2587: FutureWarning: You have passed a tensor as `image_embeds`.This is deprecated and will be removed in a future release. Please make sure to update your script to pass `image_embeds` as a list of tensors to suppress this warning.\n",
      "  deprecate(\"image_embeds not a list\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "100%|██████████| 4/4 [00:00<00:00,  6.90it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.21it/s][00:02<07:33,  2.28s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.51it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s][00:04<06:30,  1.97s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.91it/s][00:05<06:10,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.80it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s][00:07<06:12,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.05it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.94it/s][00:09<06:12,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s][00:11<06:04,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.07it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.23it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.79it/s][00:13<05:57,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.85it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.38it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.00it/s][00:15<05:56,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.24it/s][00:17<05:56,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.46it/s] [00:18<05:56,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.07it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.84it/s] [00:20<05:50,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.74it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s] [00:22<05:43,  1.83s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.05it/s] [00:24<05:46,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s] [00:26<05:48,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.51it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.64it/s] [00:28<05:38,  1.83s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.55it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.04it/s] [00:29<05:37,  1.83s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.53it/s] [00:31<05:38,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.62it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s] [00:33<05:31,  1.82s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s] [00:35<05:27,  1.81s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.15it/s] [00:37<05:33,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.80it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.46it/s] [00:39<05:29,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.20it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.38it/s] [00:40<05:29,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.46it/s] [00:42<05:29,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.40it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.05it/s] [00:44<05:22,  1.83s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.44it/s] [00:46<05:13,  1.79s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.42it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s] [00:48<05:16,  1.82s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.98it/s] [00:50<05:17,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.88it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.24it/s] [00:51<05:13,  1.82s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.67it/s] [00:53<05:16,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.32it/s] [00:55<05:11,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.08it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.99it/s] [00:57<05:11,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.68it/s] [00:59<05:14,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s] [01:01<05:10,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.04it/s] [01:03<05:12,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.80it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.08it/s] [01:05<05:11,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.69it/s] [01:06<05:06,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.53it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.58it/s] [01:08<05:08,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.60it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.24it/s] [01:10<05:06,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s] [01:12<05:07,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.82it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s] [01:14<05:09,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.38it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.59it/s] [01:16<04:59,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.16it/s] [01:18<04:55,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.23it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.16it/s] [01:20<04:49,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.18it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s] [01:21<04:45,  1.83s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.85it/s] [01:23<04:49,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.18it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.95it/s] [01:25<04:45,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.40it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s] [01:27<04:43,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.58it/s] [01:29<04:38,  1.83s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.07it/s] [01:31<04:43,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.98it/s] [01:33<04:39,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.85it/s] [01:35<04:41,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.57it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.09it/s] [01:37<04:44,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.13it/s] [01:38<04:41,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.16it/s] [01:40<04:32,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.13it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.40it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.17it/s] [01:42<04:33,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.65it/s] [01:44<04:33,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.51it/s] [01:46<04:27,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.82it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.38it/s] [01:48<04:21,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.39it/s] [01:49<04:20,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.56it/s] [01:51<04:22,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.43it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.07it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.98it/s] [01:53<04:23,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s] [01:55<04:22,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.80it/s] [01:57<04:13,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.38it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.40it/s] [01:59<04:10,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.61it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.19it/s] [02:01<04:15,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.07it/s] [02:03<04:09,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.28it/s] [02:04<04:06,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s] [02:06<04:06,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.78it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.15it/s] [02:08<04:04,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.93it/s] [02:10<04:07,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.97it/s] [02:12<04:03,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.68it/s] [02:14<04:04,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.15it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s] [02:16<04:05,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s] [02:18<04:00,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.08it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s] [02:20<04:01,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.17it/s] [02:22<03:59,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.51it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.20it/s] [02:24<03:52,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.32it/s] [02:26<03:54,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.07it/s] [02:27<03:49,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.88it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.72it/s] [02:29<03:44,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.55it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.23it/s] [02:31<03:43,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.62it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s] [02:33<03:40,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.55it/s] [02:35<03:39,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.45it/s] [02:37<03:36,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.62it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.40it/s] [02:39<03:35,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.66it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.59it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.98it/s] [02:40<03:30,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.66it/s] [02:42<03:32,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.68it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.82it/s] [02:44<03:25,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.69it/s] [02:46<03:22,  1.83s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.66it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.71it/s] [02:48<03:22,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.60it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.55it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.71it/s] [02:50<03:20,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.09it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.79it/s] [02:52<03:22,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.62it/s] [02:54<03:26,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.38it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.97it/s] [02:55<03:22,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.25it/s] [02:57<03:19,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.94it/s] [02:59<03:20,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.54it/s] [03:01<03:19,  1.94s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.31it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.31it/s] [03:03<03:13,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.07it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.51it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.90it/s] [03:05<03:08,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.49it/s]0 [03:07<03:09,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.23it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.04it/s]0 [03:09<03:05,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.88it/s]0 [03:11<03:06,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.59it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.16it/s]0 [03:13<03:09,  1.95s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.57it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.85it/s]0 [03:15<03:09,  1.98s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s]0 [03:17<03:04,  1.94s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.21it/s]0 [03:18<02:58,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.82it/s]0 [03:20<02:58,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]0 [03:22<02:53,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.42it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.56it/s]0 [03:24<02:52,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.05it/s]0 [03:26<02:47,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.42it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s]0 [03:28<02:46,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.59it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.49it/s]0 [03:30<02:42,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.38it/s]0 [03:31<02:40,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.44it/s]0 [03:33<02:40,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.38it/s]0 [03:35<02:40,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.09it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]0 [03:37<02:39,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.85it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.36it/s]0 [03:39<02:39,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.56it/s]0 [03:41<02:37,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.50it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]0 [03:43<02:31,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.97it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.72it/s]0 [03:45<02:29,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.08it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.55it/s]0 [03:47<02:30,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.24it/s]0 [03:48<02:26,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.88it/s]0 [03:50<02:24,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.61it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.10it/s]0 [03:52<02:21,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.43it/s]0 [03:54<02:21,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]0 [03:56<02:17,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.34it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]0 [03:58<02:14,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.97it/s]0 [04:00<02:12,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.85it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.11it/s]0 [04:02<02:15,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.97it/s]0 [04:04<02:15,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]0 [04:06<02:14,  1.94s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.13it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.94it/s]0 [04:07<02:08,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.04it/s]0 [04:09<02:04,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.01it/s]0 [04:11<02:05,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s]0 [04:13<02:03,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.69it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.81it/s]0 [04:15<02:03,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.49it/s]0 [04:17<02:01,  1.94s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.13it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.04it/s]0 [04:19<01:57,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.06it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]0 [04:21<01:56,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.95it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.05it/s]0 [04:23<01:52,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.81it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.75it/s]0 [04:24<01:49,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.97it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.77it/s]0 [04:26<01:48,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.62it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.25it/s]0 [04:28<01:49,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.61it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.71it/s]0 [04:30<01:48,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.46it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.36it/s]0 [04:32<01:45,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.15it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.16it/s]0 [04:34<01:44,  1.94s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.28it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]0 [04:36<01:41,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.97it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]0 [04:38<01:38,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.16it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.19it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.13it/s]0 [04:40<01:37,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.43it/s]0 [04:42<01:36,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.60it/s]0 [04:43<01:32,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.81it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.23it/s]0 [04:45<01:31,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.11it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.11it/s]0 [04:47<01:28,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.13it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.28it/s]0 [04:49<01:26,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.09it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.21it/s]0 [04:51<01:23,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s]0 [04:53<01:20,  1.84s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.95it/s]0 [04:55<01:20,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.13it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.19it/s]0 [04:57<01:19,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.12it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  9.69it/s]0 [04:59<01:18,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.73it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]0 [05:01<01:18,  1.97s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s]0 [05:03<01:17,  1.98s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.60it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.79it/s]0 [05:05<01:14,  1.96s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.18it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s]0 [05:06<01:11,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.38it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.15it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.01it/s]0 [05:08<01:09,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.56it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.15it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s]0 [05:10<01:06,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.38it/s]0 [05:12<01:03,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.63it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.26it/s]0 [05:14<01:00,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]0 [05:16<01:00,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s]0 [05:18<00:57,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.15it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.49it/s]0 [05:19<00:56,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.09it/s]0 [05:21<00:54,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.29it/s]0 [05:23<00:52,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.80it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.23it/s]0 [05:25<00:50,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.13it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.49it/s]0 [05:27<00:48,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.06it/s]0 [05:29<00:46,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]0 [05:31<00:44,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.23it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.19it/s]0 [05:33<00:43,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.70it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.52it/s]0 [05:35<00:41,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s]0 [05:37<00:40,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]0 [05:38<00:38,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]0 [05:40<00:35,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.47it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]0 [05:42<00:33,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.90it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.51it/s]0 [05:44<00:31,  1.86s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]0 [05:46<00:30,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.90it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.53it/s]0 [05:48<00:28,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.09it/s]0 [05:50<00:27,  1.94s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.99it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.85it/s]0 [05:52<00:24,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.75it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]0 [05:54<00:23,  1.92s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.65it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.14it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.03it/s]0 [05:55<00:20,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.09it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.33it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.32it/s]0 [05:57<00:19,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.02it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.06it/s]0 [05:59<00:16,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.09it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.67it/s]0 [06:01<00:14,  1.87s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.74it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.18it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.83it/s]0 [06:03<00:12,  1.85s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.87it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.96it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.41it/s]0 [06:05<00:11,  1.88s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.25it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.26it/s]0 [06:07<00:09,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.91it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.77it/s]0 [06:09<00:07,  1.89s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.97it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.07it/s]0 [06:11<00:05,  1.91s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.78it/s]0 [06:12<00:03,  1.90s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.00it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.76it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.81it/s]0 [06:14<00:01,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:00<00:00, 10.98it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 11.25it/s]\n",
      "Generating images...: 100%|██████████| 200/200 [06:16<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import diffusers \n",
    "\n",
    "# Not sure why they've added this, but it makes the model fail\n",
    "if \"http_proxy\" in os.environ:\n",
    "    os.environ.pop(\"http_proxy\")\n",
    "if \"https_proxy\" in os.environ:\n",
    "    os.environ.pop(\"https_proxy\")\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"False\"\n",
    "\n",
    "\n",
    "# Assuming generator.generate returns a PIL Image\n",
    "generator = Generator4Embeds(num_inference_steps=4, device=device)\n",
    "\n",
    "diffusers.utils.logging.disable_progress_bar()\n",
    "\n",
    "directory = f\"generated_imgs/mine2/{sub}\"\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "NUM_GEN_PER_IMG = 3\n",
    "for k in tqdm(list(range(200)), desc=\"Generating images...\"):\n",
    "    h = test_embeddings[k:k+1].to(dtype=torch.float16)\n",
    "    text_dir = os.path.join(directory, texts[k])\n",
    "    os.makedirs(text_dir, exist_ok=True)\n",
    "    for j in range(NUM_GEN_PER_IMG):\n",
    "        image = generator.generate(h)\n",
    "        image.save(os.path.join(text_dir, f'{j}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(h.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
